id,title,desc,thumbnail,service,job,summary,keywords
5,AWS를 이용한 머신 러닝 파이프라인: 구축부터 서빙까지,"## 개요

AWS API Gateway, Lambda, 그리고 SageMaker를 통합 사용하여 데이터를 처리하고 머신 러닝 모델을 서빙하는 동시에, 모델 업데이트와 안전한 접근을 관리합니다.

## 서비스 소개

### **AWS API Gateway**

API Gateway는 AWS에서 제공하는 완전 관리형 서비스로, 개발자들이 HTTP, HTTPS 프로토콜 기반의 API를 쉽게 생성, 배포, 유지 관리할 수 있게 해 줍니다. API Gateway는 고가용성을 보장하며, 사용자가 만든 API를 통해 데이터를 받고, 처리하며, 다른 서비스로 전송하는 역할을 합니다.

### **AWS Lambda**

AWS Lambda는 서버를 구성할 필요 없이 코드를 실행할 수 있게 해주는 서비스입니다. 이벤트에 반응하여 자동으로 코드를 실행하고, 사용한 컴퓨팅 시간에 따라 요금을 지불하게 됩니다. Lambda 함수는 다양한 AWS 서비스와 연동하여 사용될 수 있으며, 이벤트 기반의 로직이나 데이터 처리 작업을 수행합니다.

### **Amazon SageMaker**

Amazon SageMaker는 머신 러닝 모델을 빠르게 구축하고, 훈련시키고, 배포할 수 있는 완전 관리형 플랫폼입니다. SageMaker는 데이터 과학자와 개발자가 기계 학습 모델을 쉽게 실험하고, 훈련하고, 튜닝하며, 배포할 수 있도록 도와줍니다.

### **통합 사용 시나리오**

1. **데이터 처리 및 머신 러닝 모델 서빙**:
    - 사용자가 API Gateway를 통해 HTTP 요청을 보내면, 이 요청은 Lambda 함수를 트리거합니다.
    - Lambda 함수는 필요한 데이터 처리 작업을 수행하거나, 추가적인 데이터를 다른 출처에서 가져올 수 있습니다.
    - 데이터가 준비되면, Lambda 함수는 SageMaker에서 호스팅되고 있는 머신 러닝 모델에 접근하여 데이터를 입력으로 사용하고, 예측 결과를 받습니다.
    - 예측 결과를 사용자에게 응답으로 반환합니다.
2. **동적인 머신 러닝 모델 업데이트**:
    - 시스템이 새로운 데이터를 수집하고 분석할 수 있게 Lambda 함수를 사용할 수 있으며, 이를 통해 모델을 주기적으로 업데이트하거나 재학습할 수 있습니다.
    - API Gateway를 통해 특정 엔드포인트를 통해 모델 업데이트 명령을 보낼 수 있습니다.
3. **안전한 모델 접근**:
    - API Gateway에서 API 키 또는 AWS IAM 롤을 사용하여 엔드포인트를 보호함으로써, 머신 러닝 모델에 대한 접근을 안전하게 관리할 수 있습니다.

???Visit the?[GitHub repo for this pattern](https://github.com/aws-samples/serverless-patterns/tree/main/apigw-lambda-sagemaker-jumpstartendpoint-cdk-python).

### 예제 다운로드

```bash
git clone https://github.com/aws-samples/serverless-patterns/ 
cd serverless-patterns/apigw-lambda-sagemaker-jumpstartendpoint-cdk-python
```

### 배포

```bash
cdk deploy
```

### 인프라 생성 코드

```bash
from aws_cdk import (
    Stack, Duration,
    aws_iam as iam,
    aws_ssm as ssm,
    aws_lambda as _lambda,
    aws_apigateway as apigateway,
)

from constructs import Construct
from util.sagemaker_endpoint_construct import SageMakerEndpointConstruct
from datetime import datetime

class ApigwLambdaSagemakerJumpstartendpointStack(Stack):

    def __init__(self, scope: Construct, construct_id: str, model_info, **kwargs) -> None:
        super().__init__(scope, construct_id, **kwargs)

        # Get the instance count parameter from the context or use a default value
        instance_count_param = self.node.try_get_context(""instance_count_param"")
        instance_count = int(instance_count_param) if instance_count_param else 1

        role = iam.Role(self, ""SageMaker-Policy"", assumed_by=iam.ServicePrincipal(""sagemaker.amazonaws.com""))
        role.add_managed_policy(iam.ManagedPolicy.from_aws_managed_policy_name(""AmazonS3FullAccess""))

        sts_policy = iam.Policy(self, ""sm-deploy-policy-sts"",
                                statements=[iam.PolicyStatement(
                                    effect=iam.Effect.ALLOW,
                                    actions=[
                                        ""sts:AssumeRole""
                                    ],
                                    resources=[""*""]
                                )]
                                )

        logs_policy = iam.Policy(self, ""sm-deploy-policy-logs"",
                                 statements=[iam.PolicyStatement(
                                     effect=iam.Effect.ALLOW,
                                     actions=[
                                         ""cloudwatch:PutMetricData"",
                                         ""logs:CreateLogStream"",
                                         ""logs:PutLogEvents"",
                                         ""logs:CreateLogGroup"",
                                         ""logs:DescribeLogStreams"",
                                         ""ecr:GetAuthorizationToken""
                                     ],
                                     resources=[""*""]
                                 )]
                                 )

        ecr_policy = iam.Policy(self, ""sm-deploy-policy-ecr"",
                                statements=[iam.PolicyStatement(
                                    effect=iam.Effect.ALLOW,
                                    actions=[
                                        ""ecr:*"",
                                    ],
                                    resources=[""*""]
                                )]
                                )

        role.attach_inline_policy(sts_policy)
        role.attach_inline_policy(logs_policy)
        role.attach_inline_policy(ecr_policy)

        # Generate a unique model name
        model_name = f""JumpstartModel-{datetime.now().strftime('%Y%m%d%H%M%S')}""

        # Create a SageMaker endpoint that can be used to generate images from text
        endpoint = SageMakerEndpointConstruct(self, ""Jumpstart"",
                                              project_prefix=f""Jumpstart-{instance_count}"",
                                              role_arn=role.role_arn,
                                              model_name=model_name,
                                              model_bucket_name=model_info[""model_bucket_name""],
                                              model_bucket_key=model_info[""model_bucket_key""],
                                              model_docker_image=model_info[""model_docker_image""],
                                              variant_name=""AllTraffic"",
                                              variant_weight=1,
                                              instance_count=instance_count,
                                              instance_type=model_info[""instance_type""],
                                              environment={
                                                  ""MMS_MAX_RESPONSE_SIZE"": ""20000000"",
                                                  ""SAGEMAKER_CONTAINER_LOG_LEVEL"": ""20"",
                                                  ""SAGEMAKER_PROGRAM"": ""inference.py"",
                                                  ""SAGEMAKER_REGION"": model_info[""region_name""],
                                                  ""SAGEMAKER_SUBMIT_DIRECTORY"": ""/opt/ml/model/code"",
                                              },

                                              deploy_enable=True
                                              )

        endpoint.node.add_dependency(sts_policy)
        endpoint.node.add_dependency(logs_policy)
        endpoint.node.add_dependency(ecr_policy)

        ssm.StringParameter(self, ""Jumpstart_endpoint"", parameter_name=""Jumpstart_endpoint"",
                            string_value=endpoint.endpoint_name)

        # Create a Lambda function to invoke the SageMaker endpoint
        lambda_function = _lambda.Function( 
        self,
        ""InvokeSagemakerEndpointLambda"",
        function_name=""InvokeSagemakerEndpointLambda"",
        runtime=_lambda.Runtime.PYTHON_3_9,
        handler=""InvokeSagemakerEndpointLambda.lambda_handler"",
        code=_lambda.Code.from_asset(""lambda""),
        environment={
            ""SAGEMAKER_ENDPOINT_NAME"": endpoint.endpoint_name,
        },
        timeout=Duration.seconds(500)
        )

        # Add the necessary IAM permissions to the Lambda function to invoke the SageMaker endpoint
        lambda_function.add_to_role_policy(iam.PolicyStatement(
        effect=iam.Effect.ALLOW,
        actions=[""sagemaker:InvokeEndpoint""],
        resources=[endpoint.endpoint_arn]
        ))

        # Add the SageMaker endpoint as a dependency of the Lambda function
        lambda_function.node.add_dependency(endpoint)

        # Create the REST API Gateway
        api = apigateway.RestApi(
            self,
            ""APIForSagemakerEndpoint"",
            rest_api_name=""APIForSagemakerEndpoint""
        )

        # Store the API Gateway URL in an SSM Parameter
        ssm.StringParameter(
            self,
            ""api_gateway_url"",
            parameter_name=""/SagemakerAPI/URL"",
            string_value=api.url,
        )

        # Add the usage plan
        usage_plan = api.add_usage_plan(
            ""APIForSagemakerUsagePlan"",
            name=""APIForSagemakerUsagePlan"",
            throttle=apigateway.ThrottleSettings(
                rate_limit=1000,
                burst_limit=2000
            )
        )
        # Create the API key
        api_key = api.add_api_key(""SagemakerAPIKey"")

        # Associate the API key with the usage plan
        usage_plan.add_api_key(api_key)

        # Store the API key in an SSM Parameter
        ssm.StringParameter(
            self,
            ""api_gateway_key"",
            parameter_name=""/SagemakerAPI/APIKey"",
            string_value=api_key.key_id,  # Store the API key value
        )

        # Create the API Gateway integration with the Lambda function
        integration = apigateway.LambdaIntegration(
            lambda_function,
            proxy=True,
        )

        # Create a resource and attach the integration
        resource = api.root.add_resource(""generateimage"")
        method = resource.add_method(
            http_method=""POST"",
            integration=integration,
            api_key_required=True
        )
        # Add the API stage and associate it with the usage plan
        stage = api.deployment_stage
        usage_plan.add_api_stage(
            api=api,
            stage=api.deployment_stage
        )

        # Add dependency between Lambda function and API Gateway
        api.node.add_dependency(lambda_function)

```",https://rattle-stock-d32.notion.site/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2Fe7472e42-7118-406f-8758-f9c76b1cf86a%2F6bc11634-be31-4f14-a12b-0cd0194c73a0%2FUntitled.png?table=block&id=0239d5fa-0dea-4c7f-b949-0d2762d41495&spaceId=e7472e42-7118-406f-8758-f9c76b1cf86a&width=1300&userId=&cache=v2,Machine Learning,Data Scientist,"API Gateway, Lambda, SageMaker를 활용해 데이터를 처리하고 머신 러닝 모델을 서빙하는 동시에, 모델 업데이트와 안전한 접근을 관리합니다.","API Gateway, Lambda, SageMaker, CloudWatch, serverless, machine learning, REST API, infrastructure as code"
6,클라우드에서의 지능형 문서 관리: 실시간 문서 데이터 추출과 처리,"## 개요

Amazon S3, AWS Lambda, 그리고 Amazon Textract를 함께 사용하면, 서버리스 아키텍처를 활용하여 문서 분석 및 데이터 추출을 자동화하는 효율적인 시스템을 구축할 수 있습니다. 각 서비스의 역할과 이들을 통합하여 할 수 있는 일들을 아래와 같이 설명드릴게요.

## 서비스 소개

### **Amazon S3 (Simple Storage Service)**

Amazon S3는 AWS에서 제공하는 객체 스토리지 서비스로, 웹에서 어떤 규모의 데이터라도 저장하고 검색할 수 있습니다. 이 서비스는 높은 내구성과 가용성을 제공하며, 데이터 백업, 아카이브, 복구와 같은 다양한 용도로 널리 사용됩니다.

### **AWS Lambda**

AWS Lambda는 서버를 직접 관리할 필요 없이 코드를 실행할 수 있는 서비스입니다. Lambda는 이벤트에 반응하여 자동으로 코드를 실행하고, 실행된 컴퓨팅 시간에 따라 비용이 청구됩니다. 이를 통해 스케일링과 서버 관리의 복잡성 없이 애플리케이션을 구동할 수 있습니다.

### **Amazon Textract**

Amazon Textract는 기계 학습을 활용하여 이미지나 PDF 파일 형태의 문서에서 텍스트와 데이터를 추출할 수 있는 서비스입니다. Textract는 형식을 유지한 채로 데이터를 추출할 수 있으며, 표, 폼, 그리고 일반 텍스트 처리에 유용합니다.

### **통합 사용 시나리오**

1. **문서 저장 및 자동 처리**:
    - 사용자가 S3 버킷에 다양한 형식의 문서를 업로드합니다.
    - 문서 업로드는 Lambda 함수를 트리거하며, 이 함수는 업로드된 문서를 Textract로 보내 텍스트 추출 작업을 시작합니다.
2. **데이터 추출 및 활용**:
    - Textract는 문서에서 텍스트와 데이터를 추출한 후, 이를 다시 Lambda 함수로 전송합니다.
    - Lambda 함수는 추출된 데이터를 다양한 형식으로 가공하여 필요에 따라 데이터베이스에 저장하거나 다른 시스템으로 전송할 수 있습니다.
3. **자동화된 워크플로우 구성**:
    - 이 프로세스 전체를 자동화하여, 문서 처리와 데이터 추출 작업을 실시간으로 처리할 수 있습니다. 이는 비즈니스 프로세스를 신속하게 만들고, 운영 효율성을 높이는 데 도움이 됩니다.

???Visit the?[GitHub repo for this pattern](https://github.com/aws-samples/serverless-patterns/tree/main/textract-lambda-cdk-dotnet).

### 예제 다운로드

```bash
git clone https://github.com/aws-samples/serverless-patterns/ 
cd serverless-patterns/textract-lambda-cdk-dotnet
```

### 배포 명령어

```bash
cdk deploy
```

### 인프라 생성 코드

```bash
using Amazon.CDK;
using Amazon.CDK.AWS.IAM;
using Amazon.CDK.AWS.Lambda;
using Amazon.CDK.AWS.Lambda.EventSources;
using Amazon.CDK.AWS.Logs;
using Amazon.CDK.AWS.S3;
using Constructs;

namespace Cdk
{
    public class CdkStack : Stack
    {
        readonly string lambdaFunctionName = ""textractLambdaFunction"";
        internal CdkStack(Construct scope, string id, IStackProps props = null) : base(scope, id, props)
        {
            var bucket = new Bucket(this, ""textract-bucket"", new BucketProps
            {
                BucketName = $""{this.Account}-textract-bucket""
            });

            var detectDocumentPolicy = new ManagedPolicy(this, ""DetectDocumentPolicy"", new ManagedPolicyProps
            {
                ManagedPolicyName = ""DetectDocumentPolicy"",
                Statements = new[]
                {
                    new PolicyStatement(new PolicyStatementProps
                    {
                        Effect = Effect.ALLOW,
                        Actions = new[] { ""textract:DetectDocumentText"" },
                        Resources = new[] { ""*"" }
                    })
                }
            });

            var lambdaIAMRole = new Role(this, ""TextractLambdaRole"", new RoleProps
            {
                AssumedBy = new ServicePrincipal(""lambda.amazonaws.com""),
                Description = ""IAM Role for the Lambda function"",
                ManagedPolicies = new[]
                {
                        ManagedPolicy.FromAwsManagedPolicyName(""service-role/AWSLambdaBasicExecutionRole""),
                        detectDocumentPolicy
                }
            });

            bucket.GrantReadWrite(lambdaIAMRole);

            _ = new LogGroup(this, ""CloudWatchLogs"", new LogGroupProps
            {
                LogGroupName = $""/aws/lambda/{lambdaFunctionName}"",
                RemovalPolicy = RemovalPolicy.DESTROY,
                Retention = RetentionDays.ONE_DAY
            });

            var buildOption = new BundlingOptions()
            {
                Image = Runtime.DOTNET_8.BundlingImage,
                User = ""root"",
                OutputType = BundlingOutput.ARCHIVED,
                Command = new string[]{
               ""/bin/sh"",
                ""-c"",
                "" dotnet tool install -g Amazon.Lambda.Tools""+
                "" && dotnet build""+
                "" && dotnet lambda package --output-package /asset-output/function.zip""
                }
            };

            _ = new Function(this, ""LambdaFunction"", new FunctionProps
            {
                FunctionName = lambdaFunctionName,
                MemorySize = 512,
                Timeout = Duration.Seconds(30),
                Runtime = Runtime.DOTNET_8,
                Handler = ""TextractLambda::TextractLambda.Function::FunctionHandler"",
                Role = lambdaIAMRole,
                Code = Code.FromAsset(""../TextractLambda/"", new Amazon.CDK.AWS.S3.Assets.AssetOptions
                {
                    Bundling = buildOption
                }),
                Events = new[] {new S3EventSource(bucket, new S3EventSourceProps
                {
                    Events = new[] { EventType.OBJECT_CREATED },
                    Filters = new[] { new NotificationKeyFilter { Prefix = ""input/"" } }
                })}
            });

        }
    }
}

```",https://rattle-stock-d32.notion.site/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2Fe7472e42-7118-406f-8758-f9c76b1cf86a%2F995f065d-bb63-4beb-9b9b-5e15bd2f0e41%2FUntitled.png?table=block&id=5e12cecc-c81f-493c-a841-778c84a35529&spaceId=e7472e42-7118-406f-8758-f9c76b1cf86a&width=1280&userId=&cache=v2,SaaS,Developer,"S3, Lambda, Textract를 활용해 문서를 자동으로 저장, 처리하고 데이터를 추출합니다."," S3, Lambda, Textract, CloudWatchLogs, 객체 스토리지, 서버리스, 기계 학습, 자동화"
7,데이터 분석을 위한 AWS 서비스 통합: 실시간 데이터 스트리밍 및 처리,"## 개요

Amazon MQ for ActiveMQ, Amazon Redshift, 그리고 Amazon EventBridge Pipes를 함께 사용하면, 실시간 데이터 처리 및 분석 시스템을 효율적으로 구축할 수 있습니다. 각 서비스의 역할과 이들을 통합하여 할 수 있는 일들을 아래와 같이 설명드릴게요.

## 서비스 소개

### **Amazon MQ for ActiveMQ**

Amazon MQ는 AWS에서 제공하는 메시징 서비스로, ActiveMQ를 사용하여 메시지 기반의 통신을 쉽게 구현할 수 있습니다. 이 서비스는 높은 내구성과 가용성을 제공하며, 다양한 시스템 및 컴포넌트 간 메시지를 안정적으로 전송합니다.

### **Amazon Redshift**

Amazon Redshift는 대규모 데이터웨어하우스 서비스로, 복잡한 쿼리와 대용량 데이터 처리를 빠르고 비용 효율적으로 수행할 수 있습니다. Redshift는 데이터 분석과 비즈니스 인텔리전스(BI) 애플리케이션의 백엔드로 널리 사용됩니다.

### **Amazon EventBridge Pipes**

Amazon EventBridge Pipes는 이벤트를 다양한 AWS 서비스 및 사용자 지정 애플리케이션에 쉽게 라우팅할 수 있는 서비스입니다. 이를 통해, 개발자는 복잡한 이벤트 핸들링 로직 없이 이벤트 기반 아키텍처를 빠르게 구성할 수 있습니다.

## 통합 사용 시나리오

1. **실시간 데이터 통합 및 분석**:
    - Amazon MQ for ActiveMQ를 통해 다양한 소스로부터 메시지를 수집하고, 이 메시지를 EventBridge Pipes를 사용하여 Redshift 클러스터로 안전하게 전송합니다.
    - 이 과정에서 메시지는 실시간으로 분석되며, 필요한 데이터 변환을 거쳐 데이터웨어하우스에 저장됩니다.
2. **비즈니스 인텔리전스 및 보고**:
    - Redshift에 저장된 데이터는 다양한 BI 툴을 통해 시각화 및 분석이 이루어집니다. 이를 통해 실시간 인사이트를 제공하고, 데이터 기반 의사결정을 지원합니다.
3. **자동화된 데이터 파이프라인 구성**:
    - 전체 데이터 파이프라인은 완전 자동화되어 있으며, 새로운 데이터가 시스템에 흐를 때마다 자동으로 처리 및 분석됩니다. 이는 데이터 관리 및 활용의 효율성을 대폭 향상시킵니다.

## 예제

### git

???Visit the?[GitHub repo for this pattern](https://github.com/aws-samples/serverless-patterns/tree/main/eventbridge-pipes-amq-to-redshift-cdk-python).

```bash
git clone https://github.com/aws-samples/serverless-patterns/ 
cd serverless-patterns/eventbridge-pipes-amq-to-redshift-cdk-python
```

### 배포

```bash
cdk deploy
```

### 인프라 생성 코드

```bash
from aws_cdk import (
    ArnFormat,
    CfnOutput,
    Stack,
    aws_amazonmq as amazonmq,
    aws_sqs as sqs,
    aws_redshift_alpha as redshift,
    aws_ec2 as ec2,
    aws_iam as iam,
    aws_pipes as pipes,
    aws_secretsmanager as sm,
    RemovalPolicy as RP,
    
)

import os
from constructs import Construct

class AmazonmqToRedshift(Stack):
    def __init__(self, scope: Construct, construct_id: str, **kwargs) -> None:
        super().__init__(scope, construct_id, **kwargs)

        # VPC with subnets
        app_vpc = ec2.Vpc(
            self,
            ""vpc"",
            max_azs=1,
            enable_dns_support=True,
            enable_dns_hostnames=True,
            subnet_configuration=[
                ec2.SubnetConfiguration(
                    name=""private_subnet"",
                    subnet_type=ec2.SubnetType.PRIVATE_WITH_EGRESS,
                ),
                ec2.SubnetConfiguration(
                    name=""public_subnet"", subnet_type=ec2.SubnetType.PUBLIC
                ),
            ],
        )

        # Redshift Cluster
        cluster = redshift.Cluster(
            self,
            ""Redshift"",
            node_type=redshift.NodeType.DC2_LARGE,
            master_user=redshift.Login(master_username=""awsuser""),
            cluster_type=redshift.ClusterType.SINGLE_NODE,
            subnet_group=redshift.ClusterSubnetGroup(
                self,
                ""ClusterSubnetGroup"",
                vpc_subnets=ec2.SubnetSelection(
                    subnet_type=ec2.SubnetType.PRIVATE_WITH_EGRESS
                ),
                description=""Cluster Private Subnets"",
                vpc=app_vpc,
            ),
            vpc=app_vpc,
            default_database_name=""private"",
            cluster_name=""pipestarget"",
            removal_policy=RP.DESTROY,
        )

        # Redshift Table
        redshift.Table(
            self,
            ""messages"",
            table_columns=[
                redshift.Column(name=""message"", data_type=""super""),
            ],
            cluster=cluster,
            database_name=""private"",
            table_name=""messages"",
        )

        # MQ Security Group
        mq_security_group = ec2.SecurityGroup(
            self,
            ""SecurityGroup"",
            vpc=app_vpc,
            description=""Allow MQ Access"",
            allow_all_outbound=True
        )
        # All IP and port access required for public broker
        # Network configuration - https://docs.aws.amazon.com/eventbridge/latest/userguide/eb-pipes-mq.html#pipes-mq-vpc-config

        mq_security_group.add_ingress_rule(
            ec2.Peer.any_ipv4(),
            ec2.Port.all_traffic()
        )

        public_subnets = [
            public_subnet.node.default_child.attr_subnet_id
            for public_subnet in app_vpc.public_subnets
        ]

        security_group = [mq_security_group.node.default_child.attr_group_id]

        mq_secret = sm.Secret(
            self,
            ""SecretAmazonMQ"",
            description=""This is the secret for my AmazonMQ instance"",
            generate_secret_string=sm.SecretStringGenerator(
                secret_string_template='{""username"": ""admin""}',
                generate_string_key=""password"",
                password_length=16,
                exclude_characters='""@/,\{}[]_:=',
            ),
        )

        amazonmqbroker = amazonmq.CfnBroker(
            self,
            ""PublicAmazonMQBroker"",
            auto_minor_version_upgrade=True,
            broker_name=""PipeSource"",
            deployment_mode=""SINGLE_INSTANCE"",
            engine_type=""ActiveMQ"",
            engine_version=""5.17.6"",
            host_instance_type=""mq.t3.micro"",
            publicly_accessible=True,
            storage_type=""efs"",
            authentication_strategy=""simple"",
            maintenance_window_start_time={
                ""dayOfWeek"": ""FRIDAY"",
                ""timeOfDay"": ""17:00"",
                ""timeZone"": ""UTC"",
            },
            logs={""audit"": False, ""general"": False},
            security_groups=security_group,
            subnet_ids=public_subnets,
            users=[
                amazonmq.CfnBroker.UserProperty(
                    username= """".join(
                        [
                            ""{{resolve:secretsmanager:"",
                            mq_secret.secret_full_arn,
                            "":SecretString:username}}"",
                        ]
                    ),
                    password= """".join(
                        [
                            ""{{resolve:secretsmanager:"",
                            mq_secret.secret_full_arn,
                            "":SecretString:password}}"",
                        ]
                    ),
                    console_access=True,
                )
            ],
            encryption_options={""useAwsOwnedKey"": True},
        )
        # SQS Queues
        transformed_message_sqs_queue = sqs.CfnQueue(
            self,
            ""SQSQueue"",
            delay_seconds=0,
            receive_message_wait_time_seconds=0,
            visibility_timeout=30,
        )
        
        cluster_arn = Stack.of(self).format_arn(
            service=""redshift"",
            resource_name=""pipestarget"",
            resource=""cluster"",
            arn_format=ArnFormat.COLON_RESOURCE_NAME
        )
        cluster_db_arn = Stack.of(self).format_arn(
            service=""redshift"",
            resource_name=""pipestarget/private"",
            resource=""dbname"",
            arn_format=ArnFormat.COLON_RESOURCE_NAME
        )
        cluster_user_arn = Stack.of(self).format_arn(
            service=""redshift"",
            resource_name=""pipestarget/awsuser"",
            resource=""dbuser"",
            arn_format=ArnFormat.COLON_RESOURCE_NAME
        )

        policy = iam.PolicyDocument(
            statements=[
                iam.PolicyStatement(
                    actions=[
                        ""sqs:ReceiveMessage"",
                        ""sqs:DeleteMessage"",
                        ""sqs:GetQueueAttributes"",
                        ""sqs:SendMessage"",
                    ],
                    effect=iam.Effect.ALLOW,
                    resources=[transformed_message_sqs_queue.attr_arn],
                ),
                iam.PolicyStatement(
                    actions=[""redshift-data:BatchExecuteStatement""],
                    effect=iam.Effect.ALLOW,
                    resources=[
                        cluster_arn
                    ],
                ),
                iam.PolicyStatement(
                    actions=[""redshift:GetClusterCredentials""],
                    effect=iam.Effect.ALLOW,
                    resources=[
                        cluster_db_arn,
                        cluster_user_arn,
                    ],
                ),
                iam.PolicyStatement(
                    actions=[""mq:DescribeBroker""],
                    effect=iam.Effect.ALLOW,
                    resources=[""*""],
                ),
                iam.PolicyStatement(
                    actions=[""secretsmanager:GetSecretValue""],
                    effect=iam.Effect.ALLOW,
                    resources=[mq_secret.secret_full_arn],
                ),
                iam.PolicyStatement(
                    actions=[
                        ""ec2:DescribeNetworkInterfaces"",
                        ""ec2:DescribeSubnets"",
                        ""ec2:DescribeSecurityGroups"",
                        ""ec2:DescribeVpcs"",
                        ""ec2:CreateNetworkInterface"",
                        ""ec2:DeleteNetworkInterface"",
                    ],
                    effect=iam.Effect.ALLOW,
                    resources=[""*""],
                ),
            ]
        )
        # Pipe Role
        pipe_role = iam.Role(
            self,
            ""PipeRole"",
            assumed_by=iam.ServicePrincipal(service=""pipes.amazonaws.com""),
            inline_policies={""pipe_policy"": policy},
        )
        pipe_source_queue = pipes.CfnPipe.PipeSourceParametersProperty(
            sqs_queue_parameters=pipes.CfnPipe.PipeSourceSqsQueueParametersProperty(
                batch_size=1
            )
        )

        pipe_target = pipes.CfnPipe.PipeTargetParametersProperty(
            redshift_data_parameters=pipes.CfnPipe.PipeTargetRedshiftDataParametersProperty(
                database=""private"", sqls=[""$.body""], db_user=""awsuser""
            )
        )

        cfn_pipe = pipes.CfnPipe(
            self,
            ""CfnPipeRedshiftTarget"",
            role_arn=pipe_role.role_arn,
            source=transformed_message_sqs_queue.attr_arn,
            target=cluster_arn,
            source_parameters=pipe_source_queue,
            target_parameters=pipe_target,
        )

        cfn_pipe.node.add_dependency(cluster)

        mq_transformer_pipe_source_properties = pipes.CfnPipe.PipeSourceParametersProperty(
            active_mq_broker_parameters=pipes.CfnPipe.PipeSourceActiveMQBrokerParametersProperty(
                credentials=pipes.CfnPipe.MQBrokerAccessCredentialsProperty(
                    basic_auth=mq_secret.secret_full_arn
                ),
                queue_name=""ActiveMQ.DLQ"",
            )
        )

        mq_transformer_pipe_target_properties = pipes.CfnPipe.PipeTargetParametersProperty(
            sqs_queue_parameters=pipes.CfnPipe.PipeTargetSqsQueueParametersProperty(),
            input_template='insert into messages(message) values(JSON_PARSE(\'{""body"":""<$.data>""}\'));',
        )

        mq_transformer_cfn_pipe = pipes.CfnPipe(
            self,
            ""CfnPipeMQSource"",
            role_arn=pipe_role.role_arn,
            source=amazonmqbroker.attr_arn,
            target=transformed_message_sqs_queue.attr_arn,
            source_parameters=mq_transformer_pipe_source_properties,
            target_parameters=mq_transformer_pipe_target_properties,
        )
        print(os.environ[""CDK_DEFAULT_REGION""])
        CfnOutput(self, ""AmazonMQ Console URL: "", value=f'https://{amazonmqbroker.ref}-1.mq.{os.environ[""CDK_DEFAULT_REGION""]}.amazonaws.com:8162')
        CfnOutput(self, ""AmazonMQ Secret ARN: "", value=mq_secret.secret_full_arn)

```",https://rattle-stock-d32.notion.site/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2Fe7472e42-7118-406f-8758-f9c76b1cf86a%2F9acb2d44-4aaa-45ed-8fc5-ce912d2075ba%2FUntitled.png?table=block&id=8b8b6e3f-4944-4960-aa61-e9a295d9eb02&spaceId=e7472e42-7118-406f-8758-f9c76b1cf86a&width=630&userId=&cache=v2,Data Analytics,Data Engineer,"Amazon MQ, EventBridge Pipes, 그리고 Redshift를 사용하여 실시간 데이터를 수집, 통합, 분석합니다."," MQ for ActiveMQ, Redshift, EventBridge Pipes, VPC, Data Warehousing, Data Pipeline, Data Analysis"
8,AWS를 활용한 IoT 데이터 수집 및 이벤트 처리,"## 개요

AWS API Gateway, Amazon SQS, AWS Lambda, 그리고 AWS IoT Core를 통합하여 사용하면, 복잡한 이벤트 기반의 IoT 애플리케이션을 구축할 수 있습니다. 각 서비스의 역할과 이들을 통합하여 수행할 수 있는 작업들을 아래와 같이 설명드릴게요.

## 서비스 소개

### **AWS API Gateway**

API Gateway는 AWS에서 제공하는 완전 관리형 서비스로, 개발자들이 HTTP, HTTPS 프로토콜 기반의 REST API를 쉽게 생성, 배포, 유지 관리할 수 있게 해 줍니다. API Gateway는 고가용성을 보장하며, 사용자가 만든 API를 통해 데이터를 받고, 처리하며, 다른 서비스로 전송하는 역할을 합니다.

### **Amazon SQS (Simple Queue Service)**

Amazon SQS는 완전 관리형 메시지 큐잉 서비스로, 메시지를 안전하게 저장하고, 서로 다른 시스템 간에 메시지를 전송하는 데 사용됩니다. SQS는 분산 시스템 간의 탈중앙화된 통신과 메시지 버퍼링을 제공하여 애플리케이션의 분리와 독립성을 증가시킵니다.

### **AWS Lambda**

AWS Lambda는 서버를 직접 관리할 필요 없이 코드를 실행할 수 있는 서비스입니다. Lambda는 이벤트에 반응하여 자동으로 코드를 실행하며, 다양한 AWS 서비스와 연동하여 사용될 수 있습니다.

### **AWS IoT Core**

AWS IoT Core는 인터넷 연결 장치들로부터 데이터를 안전하게 수집하고, 해당 데이터를 클라우드 서비스로 전송하여 처리할 수 있는 관리형 서비스입니다. 이 서비스는 대규모 IoT 애플리케이션에 필요한 보안 및 통신 기능을 제공합니다.

## 통합 사용 시나리오

1. **IoT 데이터 수집 및 처리**:
    - IoT 장치들은 데이터를 수집하여 AWS IoT Core를 통해 클라우드로 전송합니다.
    - IoT Core에서 수신된 데이터는 API Gateway를 통해 처리되고, 필요한 경우 SQS로 전송되어 처리 순서를 관리합니다.
2. **이벤트 기반 실행**:
    - SQS에 저장된 메시지는 Lambda 함수를 트리거합니다. Lambda 함수는 메시지를 처리하고 필요에 따라 데이터를 분석하거나 저장합니다.
3. **응답 및 액션 트리거**:
    - 처리된 데이터는 다시 IoT 장치로 전송될 수 있으며, 이를 통해 장치는 특정 행동을 취하거나 상태를 업데이트할 수 있습니다.
4. **모니터링 및 최적화**:
    - 전체 시스템은 API Gateway를 통해 모니터링되며, 데이터 흐름과 장치 상태를 실시간으로 추적하고 최적화할 수 있습니다.

## 예제

### git

??Visit the?[GitHub repo for this pattern](https://github.com/aws-samples/serverless-patterns/tree/main/apigw-sqs-lambda-iot).

```bash
git clone https://github.com/aws-samples/serverless-patterns/ 
cd serverless-patterns/apigw-sqs-lambda-iot
```

### 배포

```bash
sam build
sam deploy --guided
```

### 인프라 생성 코드

```bash
AWSTemplateFormatVersion: ""2010-09-09""
Transform: AWS::Serverless-2016-10-31
Description: Cognito to API Gateway to Lambda to IOT (uksb-1tthgi812) (tag:apigw-sqs-lambda-iot)

Parameters:
  IOTEndpoint:
    Type: String
  IOTTopic:
    Type: String

Resources:
  ##########################################################################
  #   API Gateway                                                    #
  ##########################################################################

  AppApi:
    Type: AWS::ApiGateway::RestApi
    Properties:
      Name: apigw-rest-api-http-integration
      Description: REST API Integration with SQS, Lamda, IOT

  # POST Method with HTTP integration
  RootMethodGet:
    Type: AWS::ApiGateway::Method
    Properties:
      RestApiId: !Ref AppApi
      ResourceId: !GetAtt AppApi.RootResourceId
      HttpMethod: POST
      AuthorizationType: NONE
      Integration:
        Credentials: !GetAtt APISQSGatewayRole.Arn
        IntegrationHttpMethod: POST
        IntegrationResponses:
          - StatusCode: ""200""
        PassthroughBehavior: NEVER
        RequestParameters:
          integration.request.header.Content-Type: ""'application/x-www-form-urlencoded'""
        RequestTemplates:
          application/json: Action=SendMessage&MessageBody=$input.body
        Type: AWS
        Uri: !Join
          - """"
          - - ""arn:aws:apigateway:""
            - !Ref ""AWS::Region""
            - :sqs:path/
            - !Ref ""AWS::AccountId""
            - /
            - !Sub ${MySqsQueue.QueueName}
      MethodResponses:
        - ResponseModels:
            application/json: Empty
          StatusCode: ""200""
  Deployment:
    Type: AWS::ApiGateway::Deployment
    DependsOn:
      - RootMethodGet
    Properties:
      RestApiId: !Ref AppApi

  Stage:
    Type: AWS::ApiGateway::Stage
    Properties:
      StageName: Prod
      RestApiId: !Ref AppApi
      DeploymentId: !Ref Deployment

  ##########################################################################
  #   SQS Queue                                                    #
  ##########################################################################

  MySqsQueue:
    Type: AWS::SQS::Queue

  OrderServiceQueuePolicy:
    Type: AWS::SQS::QueuePolicy
    Properties:
      Queues:
        - !Ref MySqsQueue
      PolicyDocument:
        Version: ""2012-10-17""
        Statement:
          - Sid: order-api-send-msg-sqs
            Effect: Allow
            Principal:
              Service: ""apigateway.amazonaws.com""
            Action:
              - SQS:SendMessage
              - logs:CreateLogGroup
              - logs:CreateLogStream
              - logs:DescribeLogGroups
              - logs:DescribeLogStreams
              - logs:PutLogEvents
              - logs:GetLogEvents
              - logs:FilterLogEvents
            Resource: !GetAtt MySqsQueue.Arn

  ##########################################################################
  #   Lambda publish                                                    #
  ##########################################################################
  iotpublish:
    Type: AWS::Serverless::Function
    Properties:
      CodeUri: src/
      Handler: app.lambda_handler
      FunctionName: iotpush
      Description: Lambda to push message to IOT topic
      Runtime: python3.9
      Timeout: 10
      MemorySize: 128
      Role: !GetAtt LambdaExecutionRole.Arn
      Environment:
        Variables:
          IOT_DATA_ENDPOINT: !Ref IOTEndpoint
          IOT_TOPIC: !Ref IOTTopic
      Events:
        MySQSEvent:
          Type: SQS
          Properties:
            Queue: !GetAtt MySqsQueue.Arn
            BatchSize: 10

  ##########################################################################
  #   Roles                                                                #
  ##########################################################################

  LambdaExecutionRole:
    Type: ""AWS::IAM::Role""
    Properties:
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Principal:
              Service:
                - lambda.amazonaws.com
            Action:
              - ""sts:AssumeRole""
      Policies:
        - PolicyName: CustomPolicy
          PolicyDocument:
            Version: 2012-10-17
            Statement:
              - Effect: Allow
                Action:
                  - ""logs:CreateLogGroup""
                  - ""logs:CreateLogStream""
                  - ""logs:PutLogEvents""
                Resource: ""*""
              - Effect: Allow
                Action:
                  - ""iot:*""
                  - ""iotjobsdata:*""
                Resource: ""*""
              - Effect: Allow
                Action:
                  - ""sqs:*""
                Resource: ""*""

  APISQSGatewayRole:
    Type: ""AWS::IAM::Role""
    Properties:
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Principal:
              Service:
                - apigateway.amazonaws.com
            Action:
              - ""sts:AssumeRole""
      Policies:
        - PolicyName: ApiGatewayLogsPolicy
          PolicyDocument:
            Version: 2012-10-17
            Statement:
              - Effect: Allow
                Action:
                  - logs:CreateLogGroup
                  - logs:CreateLogStream
                  - logs:DescribeLogGroups
                  - logs:DescribeLogStreams
                  - logs:PutLogEvents
                  - logs:GetLogEvents
                  - logs:FilterLogEvents
                Resource: ""*""
              - Effect: Allow
                Action:
                  - ""iot:*""
                  - ""iotjobsdata:*""
                Resource: ""*""
              - Effect: Allow
                Action:
                  - ""sqs:*""
                Resource: ""*""
              - Effect: Allow
                Action:
                  - ""kms:Decrypt""
                  - ""kms:GenerateDataKey""
                  - ""kms:Encrypt""
                Resource: ""*""

Outputs:
  # API Gateway endpoint to be used during tests
  AppApiEndpoint:
    Description: API Endpoint
    Value: !Sub ""https://${AppApi}.execute-api.${AWS::Region}.amazonaws.com/Prod""

```",https://rattle-stock-d32.notion.site/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2Fe7472e42-7118-406f-8758-f9c76b1cf86a%2F01dd8ede-21fc-48e6-a4a0-2f06046e620a%2FUntitled.png?table=block&id=f159289d-fd65-4a6f-a881-be80991485c4&spaceId=e7472e42-7118-406f-8758-f9c76b1cf86a&width=1280&userId=&cache=v2,Internet Of Things (IoT),Developer,"IoT 장치에서 데이터를 수집하고, API Gateway, SQS, Lambda를 통해 이벤트 기반으로 처리하며, 응답을 관리합니다","API Gateway, SQS, Lambda, IoT Core, HTTP, REST API, Message Queue, Serverless"
9,"실시간 IoT 데이터 파이프라인 구축: AWS Core, Firehose, S3 활용법","## 개요

AWS IoT Core, Amazon Kinesis Data Firehose, 그리고 Amazon S3를 함께 사용하면, 대량의 IoT 데이터를 효율적으로 수집, 처리 및 저장할 수 있는 강력한 데이터 파이프라인을 구축할 수 있습니다. 각 서비스의 역할과 이들을 통합하여 수행할 수 있는 작업들을 아래와 같이 설명드릴게요.

## 서비스 소개

### **AWS IoT Core**

AWS IoT Core는 인터넷에 연결된 장치에서 데이터를 안전하게 수집하고, 그 데이터를 AWS 클라우드로 전송하는 서비스입니다. 이 서비스는 수백만 개의 IoT 장치를 연결하고, 대규모 네트워크를 통한 메시지 교환을 관리할 수 있는 능력을 제공합니다.

### **Amazon Kinesis Data Firehose**

Amazon Kinesis Data Firehose는 실시간으로 데이터 스트림을 캡처하고, 변환하여 저장할 수 있는 서비스입니다. 이 서비스는 데이터를 자동으로 Amazon S3, Amazon Redshift, Amazon Elasticsearch Service 등에 로드할 수 있도록 지원합니다.

### **Amazon S3 (Simple Storage Service)**

Amazon S3는 객체 스토리지 서비스로, 데이터의 양과 관계없이 어떤 종류의 데이터든 저장하고 검색할 수 있습니다. S3는 업계를 선도하는 확장성, 데이터 가용성, 보안 및 성능을 제공합니다.

## 통합 사용 시나리오

## 예제

### git

??Visit the?[GitHub repo for this pattern](https://github.com/aws-samples/serverless-patterns/tree/main/iot-firehose-s3-cdk).

```bash
git clone https://github.com/aws-samples/serverless-patterns/
cd serverless-patterns/iot-firehose-s3-cdk
```

### 배포

```bash
cdk deploy
```

### 인프라 생성 코드

```bash
/*! Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.
 *  SPDX-License-Identifier: MIT-0
 */

import { RemovalPolicy, Stack, StackProps } from 'aws-cdk-lib';
import { Construct } from 'constructs';
import { S3Buckets } from './s3buckets';
import { LogStream, LogGroup, RetentionDays } from 'aws-cdk-lib/aws-logs'
import { Effect, Role, ServicePrincipal, Policy, PolicyDocument, PolicyStatement } from 'aws-cdk-lib/aws-iam';
import { CfnDeliveryStream } from 'aws-cdk-lib/aws-kinesisfirehose'
import { CfnTopicRule } from 'aws-cdk-lib/aws-iot'

export class IotKfhS3Stack extends Stack {
  s3buckets: S3Buckets

  constructor(scope: Construct, id: string, props?: StackProps) {
    super(scope, id, props);

    const stack = Stack.of(this)
    const iotArnPrefix = `arn:aws:iot:${stack.region}:${stack.account}`

    // Create the S3 Bucket to be used as a Firehose destination 
    // in a nested stack. If you have a pre-existing bucket, you
    // can modify the nested stack to lookup and return the bucket.
    this.s3buckets = new S3Buckets(this, 's3-bucket')
    const { kfh_bucket } = this.s3buckets

    // Create a log group
    const logGroup = new LogGroup(this, 'kfh-log-group', {
      logGroupName: 'iot-kfh-s3-logs',
      removalPolicy: RemovalPolicy.DESTROY,
      retention: RetentionDays.FIVE_DAYS,
    })

    // Create the Kinesis Firehose log stream.
    const firehoseLogStream = new LogStream(this, 'iot-kfh-s3-stream', {
        logGroup: logGroup,
        logStreamName: 'iot-kfh-s3-logstream',
        removalPolicy: RemovalPolicy.DESTROY,
    }) 

    // IAM Role for Kinesis Firehose
    const kfhDeliveryStreamRole = new Role(this,'KFHRawDeliveryStreamRole', {
        roleName: 'iot-kfh-s3-delivery-' + stack.region,
        assumedBy: new ServicePrincipal('firehose.amazonaws.com'),
        inlinePolicies: {
            cloudwatch: new PolicyDocument({
                statements: [
                    new PolicyStatement({
                        actions: ['logs:PutLogEvents'],
                        effect: Effect.ALLOW,
                        resources: [
                            logGroup.logGroupArn +
                                ':log-stream:' +
                                firehoseLogStream.logStreamName,
                        ],
                    }),
                ],
            }),
        },
        }
    )

    // Grant permissions to role for putting objects in S3
    kfh_bucket.grantPut(kfhDeliveryStreamRole)
    kfh_bucket.grantWrite(kfhDeliveryStreamRole)

    // Create a Kinesis Firehose data stream with dynamic partitioning
    // The messages should have the following fields - `deviceId` that
    // uniquely defined the IoT device sending data. For example this 
    // could be the MAC Address of the device.
    // Metadata extracted is from the field `timestamp` to give the following
    // folder structure""
    // S3Bucket/deviceId/year/month/day/hour

    const kfhDeliveryStream = new CfnDeliveryStream(this,'KFHDeliveryStream', {
          deliveryStreamName: 'iot-kfh-s3-DeliveryStream',
          deliveryStreamType: 'DirectPut',
          extendedS3DestinationConfiguration: {
              bucketArn: kfh_bucket.bucketArn as string,
              roleArn: kfhDeliveryStreamRole.roleArn,
              prefix: `!{partitionKeyFromQuery:deviceId}/!{partitionKeyFromQuery:year}/!{partitionKeyFromQuery:month}/!{partitionKeyFromQuery:day}/!{partitionKeyFromQuery:hour}/`,
              errorOutputPrefix: 'errors/!{firehose:error-output-type}',
              bufferingHints: {
                  // sizeInMBs: 1,
                  intervalInSeconds: 120,
              },
              dynamicPartitioningConfiguration: {
                  enabled: true,
              },
              processingConfiguration: {
                  enabled: true,
                  processors: [
                      {
                          type: 'MetadataExtraction',
                          parameters: [
                              {
                                  parameterName:'MetadataExtractionQuery',
                                  parameterValue: '{deviceId: .deviceId, year: .timestamp | strftime(\""%Y""\), month: .timestamp | strftime(\""%m""\), day: .timestamp | strftime(\""%d""\), hour: .timestamp | strftime(\""%H""\)}',
                              },
                              {
                                  parameterName: 'JsonParsingEngine',
                                  parameterValue: 'JQ-1.6',
                              },
                          ],
                      },

                      {
                          type: 'AppendDelimiterToRecord',
                          parameters: [
                              {
                                  parameterName: 'Delimiter',
                                  parameterValue: '\\n',
                              },
                          ],
                      },
                  ],
              },
              compressionFormat: 'UNCOMPRESSED',
              encryptionConfiguration: {
                  noEncryptionConfig: 'NoEncryption',
              },
              cloudWatchLoggingOptions: {
                  logGroupName: logGroup.logGroupName,
                  logStreamName: firehoseLogStream.logStreamName,
              },
          },
      }
    )

    const kfhActionIotRuleRole = new Role(this, 'kfhActionIoTRuleRole', {
      assumedBy: new ServicePrincipal('iot.amazonaws.com'),
    })

    const kfhIotActionsPolicy = new Policy(this, 'kfhIotActionsPolicy', {
          statements: [
              new PolicyStatement({
                  actions: ['firehose:PutRecord'],
                  resources: [kfhDeliveryStream.attrArn],
              }),
          ],
    })

    kfhIotActionsPolicy.attachToRole(kfhActionIotRuleRole)
    kfh_bucket.grantWrite(kfhActionIotRuleRole)

    const kfhDataStreamIotRule = new CfnTopicRule(this,'kfhDataStreamIotRule',{
        topicRulePayload: {
            ruleDisabled: false,
            awsIotSqlVersion: '2016-03-23',
            sql: ""SELECT * FROM '#'"",
            actions: [
              {
                  firehose: {
                      deliveryStreamName:'iot-kfh-s3-DeliveryStream',
                      roleArn: kfhActionIotRuleRole.roleArn,
                  }

              }
            ],
            errorAction: {
                s3: {
                    bucketName: kfh_bucket.bucketName as string,
                    key:
                        `errors/iot-rules/kfhDataStreamIotRule/` +
                        '${parse_time(""yyyy/MM/dd"", timestamp(), ""UTC"")}/' +
                        '${parse_time(""yyyy-MM-dd.HH-mm-ss"", timestamp(), ""UTC"")}.${newuuid()}.json',
                    roleArn: kfhActionIotRuleRole.roleArn,
                },
            },
        },
    })
  }
}

```",https://rattle-stock-d32.notion.site/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2Fe7472e42-7118-406f-8758-f9c76b1cf86a%2F0fa65b84-73fd-4168-9a65-901d24e3a676%2FUntitled.png?table=block&id=216eb59a-d69c-4914-a4db-09e5ca0a08e4&spaceId=e7472e42-7118-406f-8758-f9c76b1cf86a&width=1280&userId=&cache=v2,Internet Of Things (IoT),Developer,AWS IoT Core에서 수집한 IoT 데이터를 Kinesis Data Firehose를 통해 처리하고 Amazon S3에 안전하게 저장합니다.," IoT Core, Kinesis Data Firehose, S3, CloudWatch, IoT devices, Data streaming, Data storage, Data pipeline"
10,실시간 IoT 이벤트 처리 및 저장:AWS IoT로부터 DynamoDB까지,"## 개요

AWS IoT Core의 토픽 규칙과 Amazon DynamoDB를 사용하여 이벤트 데이터를 효율적으로 처리하고 저장할 수 있는 솔루션을 구축할 수 있습니다. 각 서비스의 역할과 이들을 통합하여 수행할 수 있는 작업들을 아래와 같이 설명드릴게요.

## 서비스 소개

### **AWS IoT Core**

AWS IoT Core는 인터넷에 연결된 장치들로부터 데이터를 안전하게 수집하고, 그 데이터를 클라우드로 전송하는 서비스입니다. IoT Core는 수백만 개의 연결을 관리하며, 강력한 보안 기능을 제공하여 장치 데이터의 안전한 처리를 보장합니다.

### **Amazon DynamoDB**

Amazon DynamoDB는 완전 관리형 NoSQL 데이터베이스 서비스로, 빠른 성능과 무한한 확장성을 제공합니다. DynamoDB는 소량의 데이터 읽기 및 쓰기 요청부터 수백만 건의 요청까지 처리할 수 있으며, 데이터의 지속적인 저장과 검색을 쉽게 만듭니다.

## 통합 사용 시나리오

1. **이벤트 데이터 수집 및 전송**:
    - IoT 장치는 센서 데이터나 기타 이벤트 정보를 수집합니다.
    - 이 데이터는 AWS IoT Core를 통해 특정 토픽으로 전송됩니다. IoT Core의 토픽 규칙은 이 데이터를 트리거로 사용합니다.
2. **DynamoDB로의 데이터 쓰기**:
    - 토픽 규칙에 의해 트리거된 액션으로, 데이터는 Amazon DynamoDB 테이블에 쓰여집니다.
    - 이 규칙은 데이터의 특정 속성을 기반으로 테이블에 적절한 항목으로 데이터를 포맷하여 저장합니다.
3. **데이터 관리 및 활용**:
    - DynamoDB에 저장된 데이터는 실시간으로 분석되거나, 다른 애플리케이션과 통합되어 사용될 수 있습니다.
    - 이 데이터는 또한 대시보드를 통해 시각화되어 운영 효율성을 높이거나, 장치 관리 결정을 내리는 데 사용될 수 있습니다.

## 예제

### git

???Visit the?[GitHub repo for this pattern](https://github.com/aws-samples/serverless-patterns/tree/main/iot-dynamodb).

```bash
git clone https://github.com/aws-samples/serverless-patterns/ 
cd serverless-patterns/iot-dynamodb
```

### 배포

```bash
sam deployAWSTemplateFormatVersion: '2010-09-09'

Transform: 'AWS::Serverless-2016-10-31'

Description: Different methods to put the IoT events to a DynamoDB table using AWS IoT Topic rules. (uksb-1tthgi812) (tag:iot-dynamodb)

Resources:

  # Define DynamoDB Table to save data for IoT Rule -> DynamoDB action
  IoTExampleTableOne:
    Type: 'AWS::DynamoDB::Table'
    Properties:
      TableName: IoTExampleTableOne
      AttributeDefinitions:
        - AttributeName: thingId
          AttributeType: S
        - AttributeName: timestamp
          AttributeType: N
      KeySchema:
        - AttributeName: thingId
          KeyType: HASH
        - AttributeName: timestamp
          KeyType: RANGE
      ProvisionedThroughput:
        ReadCapacityUnits: 5
        WriteCapacityUnits: 5

  # Define DynamoDB Table to save data for IoT Rule -> DynamoDv2 action
  IoTExampleTableTwo:
    Type: 'AWS::DynamoDB::Table'
    Properties:
      TableName: IoTExampleTableTwo
      AttributeDefinitions:
        - AttributeName: eventId
          AttributeType: S
      KeySchema:
        - AttributeName: eventId
          KeyType: HASH
      ProvisionedThroughput:
        ReadCapacityUnits: 5
        WriteCapacityUnits: 5

  # Define IAM Role to allow AWS IoT to put events to DynamoDB Tables
  IoTTableAccessRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
        - Effect: Allow
          Principal:
            Service: iot.amazonaws.com
          Action: sts:AssumeRole
      Policies:
      - PolicyName: IoTDynamoDBTablePutAccessPolicy
        PolicyDocument:
          Version: '2012-10-17'
          Statement:
          - Effect: Allow
            Action: dynamodb:PutItem
            Resource: !Sub arn:aws:dynamodb:${AWS::Region}:${AWS::AccountId}:table/${IoTExampleTableOne}
          - Effect: Allow
            Action: dynamodb:PutItem
            Resource: !Sub arn:aws:dynamodb:${AWS::Region}:${AWS::AccountId}:table/${IoTExampleTableTwo}

  # Define AWS IoT Topic Rule to put event to DynamoDB Table using 'DynamoDB' Action.
  IoTToDDBRule:
    Type: AWS::IoT::TopicRule
    Properties:
      TopicRulePayload:
        Actions:
        - DynamoDB:
            HashKeyField: thingId
            HashKeyValue: ${topic(3)}
            RangeKeyField: timestamp
            RangeKeyValue: ${timestamp()}
            RangeKeyType: NUMBER
            PayloadField: device_data
            TableName: !Ref IoTExampleTableOne
            RoleArn: !GetAtt IoTTableAccessRole.Arn
        RuleDisabled: false
        Sql: SELECT * FROM 'topics/ThingsGroupOne/+'

  # Define AWS IoT Topic Rule to put event to DynamoDB Table using 'DynamoDB2' Action.
  IoTToDDBv2Rule:
    Type: AWS::IoT::TopicRule
    Properties:
      TopicRulePayload:
        Actions:
        - DynamoDBv2:
            PutItem:
              TableName: !Ref IoTExampleTableTwo
            RoleArn: !GetAtt IoTTableAccessRole.Arn
        RuleDisabled: false
        Sql: SELECT * FROM 'topics/ThingsGroupTwo/TestThing'

```",https://rattle-stock-d32.notion.site/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2Fe7472e42-7118-406f-8758-f9c76b1cf86a%2F05987c82-f8da-4a5e-8206-329d9ce6389d%2FUntitled.png?table=block&id=afca6500-cd2a-4137-b9dc-9065eee35c24&spaceId=e7472e42-7118-406f-8758-f9c76b1cf86a&width=1290&userId=&cache=v2,Internet Of Things (IoT),Developer,IoT 장치에서 수집된 데이터를 AWS IoT Core를 통해 DynamoDB로 전송하여 실시간으로 저장 및 관리합니다.," IoT Core, DynamoDB, NoSQL, Serverless"
11,"IoT 데이터 처리를 위한 AWS 서비스 통합: IoT Core, SNS, SQS 활용","## 개요

AWS IoT Core, Amazon SNS (Simple Notification Service), 그리고 Amazon SQS (Simple Queue Service)를 함께 사용하면, IoT 장치에서 수집된 데이터를 효과적으로 처리하고 메시지를 안정적으로 전달할 수 있는 강력한 메시지 전달 시스템을 구축할 수 있습니다. 각 서비스의 역할과 이들을 통합하여 수행할 수 있는 작업들을 아래와 같이 설명드릴게요.

## 서비스 소개

### **AWS IoT Core**

AWS IoT Core는 인터넷에 연결된 장치들로부터 데이터를 안전하게 수집하고, 그 데이터를 AWS 클라우드로 전송하는 서비스입니다. 이 서비스는 수백만 개의 연결을 관리하며, 강력한 보안 기능을 제공하여 장치 데이터의 안전한 처리를 보장합니다.

### **Amazon SNS (Simple Notification Service)**

Amazon SNS는 완전 관리형 푸시 알림 서비스로, 애플리케이션에서 모바일 장치 또는 다른 서비스로 즉시 메시지를 보낼 수 있습니다. SNS는 빠르고 신뢰성 있는 메시지 전송을 제공하며, 여러 구독자에게 효과적으로 알림을 보낼 수 있습니다.

### **Amazon SQS (Simple Queue Service)**

Amazon SQS는 완전 관리형 메시지 큐잉 서비스로, 서로 다른 시스템 간에 메시지를 전송하는 데 사용됩니다. SQS는 메시지를 안전하게 저장하고, 메시지가 순서대로 처리되도록 보장하며, 다양한 시스템 및 컴포넌트 간의 탈중앙화된 통신을 가능하게 합니다.

## 통합 사용 시나리오

1. **IoT 이벤트 처리 및 메시지 전달**:
    - IoT 장치는 센서 데이터나 이벤트 정보를 수집하고, 이를 AWS IoT Core를 통해 특정 토픽으로 전송합니다.
    - IoT Core의 규칙 엔진은 이 데이터를 감지하고, SNS 주제로 전송하는 액션을 트리거합니다.
2. **SNS 알림 및 SQS 큐 연동**:
    - SNS는 수신된 메시지를 구독 중인 SQS 큐로 전달합니다. 이를 통해 메시지는 안전하게 관리되고 순차적으로 처리될 수 있습니다.
3. **메시지 처리 및 애플리케이션 통합**:
    - SQS에서 메시지는 최종적으로 소비되어, 필요한 비즈니스 로직이나 데이터 처리가 수행됩니다. 이 과정은 애플리케이션의 부하를 분산시키고 효율성을 높입니다.

## 예제

### git

??Visit the?[GitHub repo for this pattern](https://github.com/aws-samples/serverless-patterns/tree/main/iot-sns-sqs-terraform).

```bash
git clone https://github.com/aws-samples/serverless-patterns/ 
cd serverless-patterns/iot-sns-sqs-terraform
```

### 배포

```bash
terraform init
terraform apply
```

### 인프라 생성 코드

```bash
resource ""aws_sqs_queue"" ""iot_sns_sqs_tf_queue"" {
    name                       = ""IotSnsSqstfQueue""
    visibility_timeout_seconds = 300
  }
  
  
resource ""aws_sns_topic"" ""iot_sns_sqs_tf_topic"" {
    name = ""IotSnsSqstfTopic""
  }
  
resource ""aws_sns_topic_subscription"" ""iot_sns_sqs_tf_subscription"" {
    topic_arn = aws_sns_topic.iot_sns_sqs_tf_topic.arn
    protocol  = ""sqs""
    endpoint  = aws_sqs_queue.iot_sns_sqs_tf_queue.arn
  }

  
 resource ""aws_sqs_queue_policy"" ""example_policy"" {
    queue_url = aws_sqs_queue.iot_sns_sqs_tf_queue.id
  
    policy = jsonencode({
      ""Version""    : ""2012-10-17"",
      ""Id""         : ""ExampleQueuePolicy"",
      ""Statement"" : [
        {
          ""Sid""       : ""AllowSNSMessages"",
          ""Effect""    : ""Allow"",
          ""Principal"" : { ""AWS"" : ""*"" },
          ""Action""    : ""SQS:SendMessage"",
          ""Resource""  : aws_sqs_queue.iot_sns_sqs_tf_queue.arn,
          ""Condition"" : {
            ""ArnEquals"" : {
              ""aws:SourceArn"" : aws_sns_topic.iot_sns_sqs_tf_topic.arn
            }
          }
        }
      ]
    })
  }
  
resource ""aws_iot_topic_rule"" ""iot_sns_sqs_tf_rule"" {
    name         = ""IotSnsSqstfRule""
    sql          = ""SELECT * FROM 'device/data'""
    sql_version  = ""2016-03-23""
    enabled = true
  
    sns {
      message_format = ""RAW""
      role_arn       = aws_iam_role.role.arn
      target_arn     = aws_sns_topic.iot_sns_sqs_tf_topic.arn
    }
  }
  
  
data ""aws_iam_policy_document"" ""assume_role"" {
    statement {
      effect = ""Allow""
  
      principals {
        type        = ""Service""
        identifiers = [""iot.amazonaws.com""]
      }
  
      actions = [""sts:AssumeRole""]
    }
  }
  
resource ""aws_iam_role"" ""role"" {
    name               = ""myrole""
    assume_role_policy = data.aws_iam_policy_document.assume_role.json
  }
    
  
data ""aws_iam_policy_document"" ""iam_policy_for_lambda"" {
    statement {
      effect    = ""Allow""
      actions   = [""sns:Publish""]
      resources = [aws_sns_topic.iot_sns_sqs_tf_topic.arn]
    }
  }
  
resource ""aws_iam_role_policy"" ""iam_policy_for_lambda"" {
    name   = ""mypolicy""
    role   = aws_iam_role.role.id
    policy = data.aws_iam_policy_document.iam_policy_for_lambda.json
  }
  
```",https://rattle-stock-d32.notion.site/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2Fe7472e42-7118-406f-8758-f9c76b1cf86a%2F7263f6a0-f12d-4d69-a01b-8606a4a5da7e%2FUntitled.png?table=block&id=4da9b655-b0da-4bc2-a1e1-9d3f06d6c55e&spaceId=e7472e42-7118-406f-8758-f9c76b1cf86a&width=1280&userId=&cache=v2,Internet Of Things (IoT),Developer,AWS IoT Core로부터 수집된 데이터를 SNS를 통해 SQS로 전송하여 메시지를 안정적으로 관리하고 순차적으로 처리합니다.," IoT Core, SNS, SQS, Terraform, IoT event processing, Message delivery, Serverless architecture, Infrastructure as code"
12,AWS에서 소스 코드 자동 빌드 및 테스트 실행,"## 개요

AWS CodeCommit과 AWS CodeBuild를 통합하여 사용하면, 풀 리퀘스트(Pull Request)가 생성될 때마다 자동으로 코드 빌드를 실행하는 CI(Continuous Integration) 워크플로우를 구축할 수 있습니다. 각 서비스의 역할과 이들을 통합하여 수행할 수 있는 작업들을 아래와 같이 설명드릴게요.

## 서비스 소개

### **AWS CodeCommit**

AWS CodeCommit은 완전 관리형 소스 컨트롤 서비스로, Git 기반 리포지토리를 제공하여 안전하게 코드를 저장하고 버전 관리할 수 있습니다. 이 서비스는 기업 규모의 보안, 높은 확장성 및 빠른 성능을 제공합니다.

### **AWS CodeBuild**

AWS CodeBuild는 완전 관리형 빌드 서비스로, 소스 코드 컴파일, 테스트 실행 및 소프트웨어 패키지 생성을 자동으로 처리할 수 있습니다. CodeBuild는 프로비저닝이나 서버 관리 없이도 연속적인 통합 및 배포 작업을 지원하며, AWS CodePipeline과 같은 다른 서비스와 통합하여 사용될 수 있습니다.

## 통합 사용 시나리오

1. **자동 빌드 트리거**:
    - 개발자가 CodeCommit 리포지토리에 코드를 푸시하거나 풀 리퀘스트를 생성합니다.
    - CodeCommit은 이벤트를 감지하고 AWS CodeBuild 프로젝트를 자동으로 트리거합니다.
2. **빌드 및 테스트 실행**:
    - CodeBuild는 최신 코드를 가져와 빌드 및 테스트를 실행합니다. 이 과정에서 빌드 스크립트에 정의된 대로 다양한 작업이 수행됩니다.
    - 빌드 결과는 실패 또는 성공과 함께 상세한 로그와 함께 제공됩니다.
3. **결과 통보 및 후속 작업**:
    - 성공적인 빌드의 경우, 추가 배포 단계로 이동하거나 다음 단계의 자동화된 테스트를 실행할 수 있습니다.

## 예제

### git

???Visit the?[GitHub repo for this pattern](https://github.com/aws-samples/serverless-patterns/tree/main/cdk-codecommit-codebuild).

```bash
git clone https://github.com/aws-samples/serverless-patterns/ 
cd serverless-patterns/cdk-codecommit-codebuild
```

### 배포

```bash
cdk deploy
```

### 인프라 생성 코드

```bash
import * as codebuild from '@aws-cdk/aws-codebuild';
import * as codecommit from '@aws-cdk/aws-codecommit';
import * as events from ""@aws-cdk/aws-events"";
import * as targets from ""@aws-cdk/aws-events-targets"";
import * as lambda from ""@aws-cdk/aws-lambda"";
import * as nodeJSlambda from ""@aws-cdk/aws-lambda-nodejs"";
import * as iam from ""@aws-cdk/aws-iam"";
import * as cdk from ""@aws-cdk/core"";
import * as path from ""path"";

export interface PipelineProps extends cdk.StackProps {
    repositoryName: string
}

/**
 *  This Stack allow you to run codebuild on Pull Request to validate before merging to main branch
 *  It deploy a codebuildProject that will run the buildspec.yml build.
 *  Then a comment will be added the the PullRequest with a link to the logs.
 */
export class PipelineStack extends cdk.Stack {
    constructor(scope: cdk.Construct, name: string, props: PipelineProps) {
        super(scope, name, props);
        const {repositoryName} = props

        // Get the CodeCommit Repository reference from name.
        const repository = codecommit.Repository.fromRepositoryName(this, repositoryName, repositoryName)

        // Create CodeBuild project, you can configure your project as needed
        const codeBuildProject = new codebuild.Project(this, 'ExampleCodeBuild', {
            source: codebuild.Source.codeCommit({repository}),
            buildSpec: codebuild.BuildSpec.fromSourceFilename('buildspec.yml'),
        })

        repository.onPullRequestStateChange('onPRChanged', {
            // We don't want to have the CodeBuild running on closed Branches
            eventPattern: {
                detail: {
                    'pullRequestStatus': ['Open']
                }
            },
            target: new targets.CodeBuildProject(codeBuildProject, {
                event: events.RuleTargetInput.fromObject({
                    // This is to link the commit on the PR to the codebuild Project
                    sourceVersion: events.EventField.fromPath('$.detail.sourceReference'),
                    // Mapping to be able to post a comment to a PR.
                    // That way we don't use a temporary database for that.
                    environmentVariablesOverride: [
                        {
                            ""name"": ""pullRequestID"",
                            ""type"": ""PLAINTEXT"",
                            ""value"": events.EventField.fromPath('$.detail.pullRequestId')
                        },
                        {
                            ""name"": ""repositoryName"",
                            ""type"": ""PLAINTEXT"",
                            ""value"": repositoryName
                        },
                        {
                            ""name"": ""sourceCommit"",
                            ""type"": ""PLAINTEXT"",
                            ""value"": events.EventField.fromPath('$.detail.sourceCommit')
                        },
                        {
                            ""name"": ""destinationCommit"",
                            ""type"": ""PLAINTEXT"",
                            ""value"": events.EventField.fromPath('$.detail.destinationCommit')
                        }
                    ],
                }),
            })
        })

        // Lambda That will post the comment.
        const commentLambda = new nodeJSlambda.NodejsFunction(this, 'commentOnPRWithBuildStatus', {
            runtime: lambda.Runtime.NODEJS_14_X,
            handler: 'handler',
            bundling: {
                externalModules: ['aws-sdk', '@aws-sdk/client-codecommit']
            },
            entry: path.join(__dirname, `/../src/commentLambda.ts`),
            initialPolicy: [ new iam.PolicyStatement({
                actions: ['codecommit:PostCommentForPullRequest'],
                resources: [repository.repositoryArn],
            })],
        })

        const codeBuildHookOptions = {
            target: new targets.LambdaFunction(commentLambda, {
                event: events.RuleTargetInput.fromEventPath('$.detail')
            })
        }

        // Trigger Lambda on both Success and Failed
        codeBuildProject.onBuildSucceeded('onBuildSucceeded', codeBuildHookOptions)
        codeBuildProject.onBuildFailed('onBuildFailed', codeBuildHookOptions)

    }
}

```",https://rattle-stock-d32.notion.site/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2Fe7472e42-7118-406f-8758-f9c76b1cf86a%2Fdf04307e-7f75-4267-abdb-17341da68998%2FUntitled.png?table=block&id=2217408c-b178-4d38-bbbf-ff86fd257820&spaceId=e7472e42-7118-406f-8758-f9c76b1cf86a&width=1290&userId=&cache=v2,DevOps,DevOps Engineer,CodeCommit과 CodeBuild를 통합하여 풀 리퀘스트 시 자동으로 코드 빌드와 테스트를 수행합니다.,"CodeCommit, CodeBuild, CodePipeline, Lambda, Git, Continuous Integration, Source Control, Serverless"
13,AWS를 활용한 라이브 비디오 스트리밍 솔루션 개발,"## 개요

AWS Elemental MediaConnect, MediaLive, 그리고 MediaPackage를 함께 사용하여 라이브 스트리밍 서비스를 구축할 수 있습니다. 이 서비스들은 라이브 비디오 송출과 패키징을 효율적으로 처리하여 다양한 디바이스와 플랫폼에서 스트리밍할 수 있게 해 줍니다. 각 서비스의 역할과 이들을 통합하여 수행할 수 있는 작업들을 아래와 같이 설명드릴게요.

## 서비스 소개

### **AWS Elemental MediaConnect**

AWS Elemental MediaConnect는 신뢰성이 높고 보안이 강화된 라이브 비디오 전송 서비스입니다. 이 서비스는 라이브 비디오 소스를 안전하게 연결하고, 고품질로 콘텐츠를 전송할 수 있도록 지원합니다.

### **AWS Elemental MediaLive**

AWS Elemental MediaLive는 라이브 비디오 스트림을 처리하고 인코딩하는 서비스입니다. HD-1080p, HD-720p, SD-540p 등 다양한 인코딩 프로필을 제공하여, 콘텐츠를 다양한 품질로 송출할 수 있습니다.

### **AWS Elemental MediaPackage**

AWS Elemental MediaPackage는 MediaLive의 출력을 수신하여 라이브 스트림을 HLS, DASH, CMAF 등 여러 포맷으로 패키징합니다. 이는 스트림의 보호, 모니터링 및 호환성 확보를 돕습니다.

## 통합 사용 시나리오

1. **라이브 스트림 설정 및 송출**:
    - MediaConnect를 사용하여 라이브 비디오 소스를 안전하게 연결하고 MediaLive로 전송합니다.
    - MediaLive에서는 설정된 인코딩 프로필에 따라 비디오 스트림을 처리하고 인코딩합니다.
2. **스트림 패키징 및 배포**:
    - 인코딩된 스트림은 MediaPackage로 전송되며, 여기서 다양한 스트리밍 포맷으로 변환됩니다.
    - MediaPackage는 스트림을 보안적으로 관리하며, 다양한 디바이스와 플랫폼에서 접근 가능하도록 합니다.
3. **다중 포맷 배포**:
    - MediaPackage를 통해 생성된 다양한 스트리밍 포맷은 전 세계적으로 분산된 사용자들에게 제공됩니다.
    - 사용자는 선택한 디바이스에서 최적의 스트리밍 경험을 누릴 수 있습니다.

## 예제

### git

??Visit the?[GitHub repo for this pattern](https://github.com/aws-samples/serverless-patterns/tree/main/elemental-mediaconnect-medialive-mediapackage-cdk-ts).

```bash
git clone https://github.com/aws-samples/serverless-patterns/ 
cd serverless-patterns/elemental-mediaconnect-medialive-mediapackage-cdk-ts
```

### 배포

```bash
cdk deploy
```

### 인프라 생성 코드

```bash
import { Stack, StackProps } from 'aws-cdk-lib';
import { Construct, DependencyGroup } from 'constructs';
import { MediaConnect } from './media_connect';
import { MediaLive } from './media_live';
import { MediaPackage } from './media_package';
// import * as sqs from 'aws-cdk-lib/aws-sqs';

export class StreamingStack extends Stack {
  constructor(scope: Construct, id: string, props?: StackProps) {
    super(scope, id, props);

    //1. Create MediaPackage Channel
    const mediaPackageChannel = new MediaPackage(
      this,
      ""MediaPackage""
    );

    //2. Create the media connect
    const mediaConnect = new MediaConnect(this, ""MyMediaConnect"");

    //3. Create Media Live Channel
    const mediaLiveChannel = new MediaLive(
      this,
      ""MediaLive"",
      mediaPackageChannel.channel.id,
      mediaConnect.flowArnA,
      mediaConnect.flowArnB
    );

    mediaLiveChannel.node.addDependency(mediaConnect);

    //Add dependencyto wait for MediaPackage channel to be ready before deploying MediaLive
    const mediadep = new DependencyGroup();
    mediadep.add(mediaPackageChannel.channel);

    mediaLiveChannel.channelLive.node.addDependency(mediadep);

  }
}

```",https://rattle-stock-d32.notion.site/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2Fe7472e42-7118-406f-8758-f9c76b1cf86a%2Fa6415f1e-3b14-491e-9dd2-585705ab97bd%2FUntitled.png?table=block&id=46f59507-1bca-4e20-abe5-333f05ffc826&spaceId=e7472e42-7118-406f-8758-f9c76b1cf86a&width=1290&userId=&cache=v2,Media Services,Developer,"AWS Elemental MediaConnect, MediaLive, 그리고 MediaPackage를 함께 사용하여 다양한 포맷의 라이브 비디오 스트리밍 서비스를 구축합니다.","Elemental MediaConnect, Elemental MediaLive, Elemental MediaPackage, HLS, DASH, CMAF, CDN, Video Encoding"
14,AWS App Runner를 활용한 신속한 웹 애플리케이션 배포,"## 개요

AWS App Runner를 사용하면 소스 코드 또는 컨테이너 이미지를 바로 AWS 클라우드의 확장 가능하고 안전한 웹 애플리케이션으로 배포할 수 있습니다. 이 서비스는 배포 과정을 간소화하여 빠르고 비용 효율적인 솔루션을 제공합니다. 특히, 새로운 기술을 배울 필요 없이 코드 또는 이미지 저장소와 직접 연결되어 자동 통합 및 배포 파이프라인을 제공합니다.

## 서비스 소개

### **AWS App Runner**

AWS App Runner는 AWS에서 제공하는 완전 관리형 웹 애플리케이션 배포 서비스입니다. 개발자는 복잡한 인프라 설정에 신경 쓰지 않고 소스 코드나 컨테이너 이미지를 직접적으로 배포할 수 있습니다. 이 서비스는 고성능, 확장성 및 보안을 제공하며, 관리가 필요 없는 운영을 지원합니다.

## 통합 사용 시나리오

1. **간소화된 애플리케이션 배포**:
    - 개발자는 AWS App Runner를 사용하여 Node Js 기반의 간단한 ""Hello World"" 애플리케이션을 즉시 배포할 수 있습니다. 이 과정에서 AWS CDK 템플릿을 사용하여 사용자 정의 이미지를 지정할 수 있습니다.
    - 애플리케이션에 필요한 환경 변수는 배포 프로세스 중에 이미지에 직접 전달됩니다.
2. **자동 통합 및 배포**:
    - App Runner는 코드 또는 이미지 저장소와 직접 연결되어 자동으로 애플리케이션을 통합, 테스트 및 배포합니다.
    - 이는 개발자가 인프라에 대해 걱정할 필요 없이 애플리케이션 개발에 집중할 수 있게 해 줍니다.

## 예제

### git

??[GitHub repo for this pattern](https://github.com/aws-samples/serverless-patterns/tree/main/apprunner-cdk).

```java
git clone https://github.com/aws-samples/serverless-patterns/ 
cd serverless-patterns/apprunner-cdk
```

### 배포

```bash
cdk deploy
```

### 인프라 생성 코드

```bash
import * as path from 'path';
import { CfnOutput, Stack, StackProps } from '@aws-cdk/core';
import * as apprunner from '@aws-cdk/aws-apprunner';
import * as ecrAssests from '@aws-cdk/aws-ecr-assets';
import { Construct } from 'constructs';
import { Cpu, Memory } from '@aws-cdk/aws-apprunner';

export class CdkStack extends Stack {
  constructor(scope: Construct, id: string, props?: StackProps) {
    super(scope, id, props);

    const appRunnerService = new apprunner.Service(this, 'Service', {
      serviceName: 'sample-apprunner-service-cdk',
      source: apprunner.Source.fromAsset({
        imageConfiguration: {
          port: 80,
          environment: {
            region: process.env.CDK_DEFAULT_REGION!,
          },
        },
        asset: new ecrAssests.DockerImageAsset(this, 'DockerImageAsset', {
          directory: path.join(__dirname, '../src/')
        })
      }),
      cpu: Cpu.ONE_VCPU,
      memory: Memory.TWO_GB
    });    

    new CfnOutput(this, 'AppRunnerServiceARN', { value: appRunnerService.serviceArn });
    new CfnOutput(this, 'AppRunnerServiceURL', { value: `https://${appRunnerService.serviceUrl}`});
  }
}

```",https://rattle-stock-d32.notion.site/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2Fe7472e42-7118-406f-8758-f9c76b1cf86a%2F99805ad7-24b5-4778-acd5-c55eb2e5befd%2FUntitled.png?table=block&id=ee8e1a5c-e185-4ee1-b69a-2d6131a5542f&spaceId=e7472e42-7118-406f-8758-f9c76b1cf86a&width=1330&userId=&cache=v2,Devops,DevOps Engineer,AWS App Runner를 통해 소스 코드나 컨테이너 이미지를 클라우드로 직접 배포하여 웹 애플리케이션을 신속하고 간편하게 실행합니다.,"App Runner, CDK, ECR, GitHub, web application, container image, deployment, integration"
15,웹소켓과 컨테이너를 활용한 고가용성 서비스 아키텍처 설계,"## 개요

AWS API Gateway WebSocket, ALB (Application Load Balancer), 그리고 Amazon ECS Fargate를 결합하면, 실시간 통신을 가능하게 하는 웹소켓 API를 효과적으로 구축하고 관리할 수 있습니다. 이러한 서비스들을 통합하여 구현하는 방법을 아래에서 자세히 설명하겠습니다.

## 서비스 소개

### **AWS API Gateway WebSocket**

AWS API Gateway의 WebSocket 지원은 실시간 양방향 통신을 가능하게 합니다. 개발자들은 이를 사용하여 실시간으로 데이터를 클라이언트와 서버 간에 주고받을 수 있는 API를 구축할 수 있습니다. WebSocket은 특히 실시간 메시지 및 상호작용이 중요한 애플리케이션에 적합합니다.

### **Application Load Balancer (ALB)**

ALB는 고가용성, 자동 확장 및 보안 기능을 제공하며, 트래픽을 여러 태스크 또는 서비스 인스턴스에 분산시키는 역할을 합니다. HTTP 및 HTTPS 트래픽에 최적화되어 있으며, 조건부 라우팅과 함께 효율적으로 트래픽을 관리할 수 있습니다.

### **Amazon ECS Fargate**

Amazon ECS Fargate는 서버를 관리할 필요 없이 컨테이너를 실행할 수 있는 서비스입니다. Fargate는 애플리케이션의 실행에 필요한 컴퓨팅 파워를 자동으로 관리하며, 사용자는 애플리케이션 구성과 관리에 집중할 수 있습니다. Fargate는 특히 서버리스 컨테이너 관리에 적합합니다.

## 통합 사용 시나리오

1. **실시간 데이터 통신**:
    - WebSocket 클라이언트는 API Gateway를 통해 API 엔드포인트 URL에 연결합니다. 클라이언트와 서버 간의 실시간 데이터 교환은 이 연결을 통해 이루어집니다.
    - API Gateway는 HTTP 통합을 사용하여 ALB에 연결되며, 이는 Fargate 태스크를 호출합니다.
    - Fargate에서 실행 중인 FASTAPI 프레임워크는 POST 요청을 받아 처리하고, 요청 컨텍스트에 있는 connectionId를 사용하여 API Gateway와 통신합니다.
2. **탄력적인 트래픽 관리**:
    - ALB는 들어오는 트래픽을 Fargate 태스크에 효과적으로 분산시켜, 트래픽 급증 시에도 서비스의 안정성을 유지합니다.
    - 이 구조는 큰 규모의 사용자가 동시에 서비스를 이용할 때도 높은 성능을 유지하게 도와줍니다.

## 예제

### git

?? Visit the?[GitHub repo for this pattern](https://github.com/aws-samples/serverless-patterns/tree/main/apigw-websocket-fargate-cdk).

```java
git clone https://github.com/aws-samples/serverless-patterns/ 
cd serverless-patterns/apigw-websocket-api-fargate-cdk
```

### 배포

```bash
cdk deploy
```

### 인프라 생성 코드

```bash
from aws_cdk import (
    RemovalPolicy,
    Stack,
    aws_apigatewayv2 as apigw,
    aws_ec2 as ec2,
    CfnOutput,
    aws_ecs as ecs,
    aws_logs as logs,
    aws_ecs_patterns as ecs_patterns,
    aws_iam as iam,
)
import aws_cdk as core
from constructs import Construct
from aws_cdk.aws_logs import RetentionDays

class ApigwWebsocketFargateCdkStack(Stack):
    def __init__(self, scope: Construct, construct_id: str, **kwargs) -> None:
        super().__init__(scope, construct_id, **kwargs)

        # create cloudwatch log group - ApiGW
        api_log_group = logs.LogGroup(
            self,
            ""apigw-websocket-log-group"",
            removal_policy=RemovalPolicy.DESTROY,
            retention=RetentionDays.FIVE_DAYS,
        )

        # create api gateway websocket api
        websockets_api = apigw.WebSocketApi(self, ""apigw-websocket-fargate-api"")

        stage = apigw.CfnStage(
            scope=self,
            id=""DEV-WS-API-STAGE"",
            api_id=websockets_api.api_id,
            stage_name=""dev"",
            auto_deploy=True,
            default_route_settings=apigw.CfnStage.RouteSettingsProperty(
                data_trace_enabled=True,
                detailed_metrics_enabled=True,
                logging_level=""INFO"",
            ),
            access_log_settings=apigw.CfnStage.AccessLogSettingsProperty(
                destination_arn=api_log_group.log_group_arn,
                format='{ ""requestId"":""$context.requestId"", ""ip"": ""$context.identity.sourceIp"", ""requestTime"":""$context.requestTime"", ""routeKey"":""$context.routeKey"", ""status"":""$context.status"",""responseLength"":""$context.responseLength""}',
            ),
        )

        # create VPC for fargate cluster
        vpc = ec2.Vpc(self, ""apigw-websocket-fargate-vpc"", max_azs=2)

        # create cloudwatch log group - FARGATE
        log_group = logs.LogGroup(
            self,
            ""apigw-websocket-fargate-log-group"",
            removal_policy=RemovalPolicy.DESTROY,
            retention=RetentionDays.FIVE_DAYS,
        )

        # create Fargate task definition
        task_definition = ecs.FargateTaskDefinition(
            self,
            ""apigw-websocket-fargate-task-definition"",
            cpu=1024,
            memory_limit_mib=2048,
            runtime_platform=ecs.RuntimePlatform(
                cpu_architecture=ecs.CpuArchitecture.ARM64
            ),
        )

        # add container to task definition
        task_definition.add_container(
            ""apigw-websocket-fargate-container"",
            image=ecs.ContainerImage.from_asset(""./src/api""),
            memory_reservation_mib=2048,
            cpu=512,
            logging=ecs.LogDriver.aws_logs(
                stream_prefix=""apigw-websocket-fargate"", log_group=log_group
            ),
            port_mappings=[ecs.PortMapping(container_port=8000)],
            # add web socket api endpoint as env variable
            environment={
                ""WEBSOCKET_API_ENDPOINT"": f""https://{websockets_api.api_id}.execute-api.{core.Aws.REGION}.amazonaws.com/{stage.stage_name}""
            },
        )

        # add task role policy for cloud watch
        task_definition.add_to_task_role_policy(
            statement=iam.PolicyStatement(
                actions=[
                    ""logs:PutLogEvents"",
                    ""logs:CreateLogGroup"",
                    ""logs:CreateLogStream"",
                    ""logs:DescribeLogStreams"",
                    ""logs:DescribeLogGroups"",
                    ""xray:*"",
                ],
                resources=[""*""],
                effect=iam.Effect.ALLOW,
            )
        )

        # add task role policy for websockets api
        task_definition.add_to_task_role_policy(
            statement=iam.PolicyStatement(
                actions=[""execute-api:ManageConnections""],
                resources=[
                    f""arn:aws:execute-api:{core.Aws.REGION}:{core.Aws.ACCOUNT_ID}:{websockets_api.api_id}/{stage.stage_name}/*/*""
                ],
                effect=iam.Effect.ALLOW,
            )
        )

        # create security group to allow inbound traffic on port 8000
        security_group = ec2.SecurityGroup(
            self,
            ""apigw-websocket-fargate-security-group"",
            vpc=vpc,
            allow_all_outbound=True,
        )
        security_group.add_ingress_rule(ec2.Peer.any_ipv4(), ec2.Port.tcp(8000))

        # create application balanced Fargate service
        fargate_service = ecs_patterns.ApplicationLoadBalancedFargateService(
            self,
            ""apigw-websocket-fargate-service"",
            task_definition=task_definition,
            cpu=1024,
            memory_limit_mib=2048,
            desired_count=1,
            public_load_balancer=True,
            security_groups=[security_group],
            assign_public_ip=True,
            vpc=vpc,
        )

        # setup auto scaling for the Fargate service
        fargate_service.service.auto_scale_task_count(max_capacity=2)

        template = """"""{""connectionId"": ""$context.connectionId"", ""body"": $input.body}""""""

        # http integration
        http_api_integration = apigw.CfnIntegration(
            self,
            ""http_api_integration"",
            api_id=websockets_api.api_id,
            integration_type=""HTTP"",
            integration_method=""POST"",
            integration_uri=f""http://{fargate_service.load_balancer.load_balancer_dns_name}"",
            template_selection_expression=""\\$default"",
            request_templates={""\\$default"": template},
        )

        # create default route for api and associate http integration
        apigw.CfnRoute(
            self,
            ""default_route"",
            api_id=websockets_api.api_id,
            route_key=""$default"",
            target=f""integrations/{http_api_integration.ref}"",
        )

        CfnOutput(self, ""websockets_api_endpoint"", value=websockets_api.api_endpoint)
        CfnOutput(
            self,
            ""alb_endpoint"",
            value=fargate_service.load_balancer.load_balancer_dns_name,
        )

```",https://rattle-stock-d32.notion.site/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2Fe7472e42-7118-406f-8758-f9c76b1cf86a%2F56254a50-f125-46dd-9741-efb3057be920%2FUntitled.png?table=block&id=ab22cde9-0de6-4c39-9e9e-b410cf769812&spaceId=e7472e42-7118-406f-8758-f9c76b1cf86a&width=1330&userId=&cache=v2,Architecting,Architect,"API Gateway WebSocket, ALB (Application Load Balancer), 그리고 Fargate를 결합하면 실시간 데이터 교환 및 탄력적 트래픽 관리를 지원하는 웹소켓 API를 구축합니다."," ECS Fargate, API Gateway WebSocket, Application Load Balancer, CloudWatch, WebSocket, Fargate, ALB, Real-time communication"
16,AWS에서 고가용성 서비스 구축하기: Lambda와 ALB의 결합,"## 개요

AWS Application Load Balancer (ALB)와 AWS Lambda 함수를 통합하여 사용하면, 경로 기반 라우팅을 통해 다양한 요청을 특정 Lambda 함수로 효율적으로 분산할 수 있습니다. 이러한 구성은 서버리스 아키텍처를 활용하여 고가용성과 확장성을 갖춘 웹 애플리케이션을 구축할 수 있게 해 줍니다.

## 서비스 소개

### **AWS Application Load Balancer (ALB)**

ALB는 고성능의 트래픽 분산 기능을 제공하는 관리형 로드 밸런서입니다. HTTP 및 HTTPS 요청을 처리하며, 경로, 호스트, IP 프로토콜 기반의 라우팅을 지원합니다. ALB는 트래픽을 처리하며 세션 지속성 및 상태 검사와 같은 기능을 제공하여 애플리케이션의 부하 분산을 최적화합니다.

### **AWS Lambda**

AWS Lambda는 서버를 구성할 필요 없이 코드를 실행할 수 있는 서비스로, 이벤트에 반응하여 자동으로 코드를 실행합니다. Lambda 함수는 고도로 확장 가능하며, 다양한 AWS 서비스와 통합될 수 있어 복잡한 애플리케이션을 구성할 수 있습니다.

## 통합 사용 시나리오

1. **경로 기반 요청 처리**:
    - ALB는 설정된 경로 기반 라우팅 규칙에 따라 들어오는 요청을 적절한 Lambda 함수로 전달합니다. 예를 들어, 사용자는 '/api/users'와 '/api/products' 같은 다양한 엔드포인트에 대해 각기 다른 Lambda 함수를 설정할 수 있습니다.
    - 이렇게 하면 각 요청은 지정된 함수에 의해 처리되며, 이는 특정 요구사항에 맞춰 다양한 서비스나 리소스를 효과적으로 관리할 수 있게 해 줍니다.
2. **비용 효율적이고 확장 가능한 아키텍처**:
    - Lambda 함수는 사용한 만큼의 비용을 지불하는 구조이므로, 실제 사용량에 따라 비용을 최적화할 수 있습니다.
    - ALB의 높은 확장성과 결합됨으로써, 사용량이 많은 시간에는 자동으로 리소스를 확장하고, 사용량이 적은 시간에는 축소하여 리소스 사용을 최적화합니다.

## 예제

### git

??Visit the?[GitHub repo for this pattern](https://github.com/aws-samples/serverless-patterns/tree/main/alb-path-based-route-lambda-cdk).

```java
git clone https://github.com/aws-samples/serverless-patterns/ 
cd serverless-patterns/alb-path-based-route-lambda-cdk
```

### 배포

```bash
cdk deploy
```

### 인프라 생성 코드

```bash
//See the GitHub repo for detailed testing instructions.
```",https://rattle-stock-d32.notion.site/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2Fe7472e42-7118-406f-8758-f9c76b1cf86a%2Fded28a1a-ff1a-45ca-8bee-60ae8e5a20e1%2FUntitled.png?table=block&id=e8da9a17-de43-432c-a853-45a7fbb90bd7&spaceId=e7472e42-7118-406f-8758-f9c76b1cf86a&width=1320&userId=&cache=v2,Serverless,Architect,"AWS ALB와 Lambda를 통합하여 경로 기반 요청 처리를 실현하고, 비용 효율적이며 확장 가능한 서버리스 아키텍처를 구축합니다.","Application Load Balancer, Lambda, CloudFormation, CDK, serverless architecture, routing, scalability, high availability"
17,EC2에서 NGINX를 통한 REST API 구축 실습,"## **개요**

Amazon API Gateway, Network Load Balancer (NLB), 및 Amazon Elastic Compute Cloud (EC2)에서 호스팅되는 NGINX 서버를 통합하면, REST API를 통해 NGINX 서버에 안전하게 프록시 접근할 수 있습니다. 이 구성은 내부 리소스에 대한 안전한 접근을 제공하며, 공개 인터넷에 노출되지 않는 방식으로 관리됩니다.

## **서비스 소개**

### **Amazon API Gateway**

API Gateway는 개발자들이 HTTP, HTTPS 프로토콜 기반의 RESTful API를 쉽게 생성, 배포, 유지 관리할 수 있게 해주는 완전 관리형 서비스입니다. API Gateway는 트래픽 관리, 권한 부여 및 접근 제어, 모니터링, API 버전 관리 등의 기능을 제공합니다.

### **Network Load Balancer (NLB)**

NLB는 고성능 로드 밸런싱 솔루션으로, TCP 트래픽 및 UDP 트래픽을 처리하고, 높은 처리량 및 낮은 지연시간을 제공합니다. NLB는 자동 확장을 지원하며, 탄력적인 네트워크 인터페이스를 통해 EC2 인스턴스에 트래픽을 라우팅합니다.

### **Amazon Elastic Compute Cloud (EC2)**

EC2는 확장 가능한 컴퓨팅 용량을 제공하는 서비스로, 사용자가 가상 서버 인스턴스를 온디맨드로 제공받을 수 있게 합니다. EC2는 다양한 컴퓨팅 및 메모리 조합으로 인스턴스를 구성할 수 있으며, 네트워크 연결과 보안, 데이터 스토리지 옵션을 제공합니다.

## 통합 사용 시나리오

1. **내부 NGINX 서버로의 안전한 트래픽 라우팅**:
    - 사용자는 API Gateway를 통해 REST API를 설정하고, VPC Link를 사용하여 NLB와 연결합니다.
    - NLB는 안전하게 트래픽을 EC2 인스턴스로 라우팅하며, 이 인스턴스에서는 NGINX 서버가 구동 중입니다.
    - 이러한 설정을 통해, API Gateway는 공개 인터넷을 통하지 않고도 내부 NGINX 서버에 접근할 수 있습니다.
2. **보안 및 접근 제어**:
    - API Gateway는 권한 부여 및 인증 메커니즘을 통해 보안을 강화하고, 요청에 대한 접근을 제어합니다.
    - NLB를 통해 EC2의 NGINX 서버로의 접근은 내부 네트워크를 통해서만 이루어집니다, 이는 높은 보안 수준을 유지하며 중요한 데이터를 보호합니다.

## 예제

### git

??Visit the?[GitHub repo for this pattern](https://github.com/aws-samples/serverless-patterns/tree/main/apigw-ec2).

```java
git clone https://github.com/aws-samples/serverless-patterns/ 
cd serverless-patterns/apigw-ec2
```

### 배포

```bash
sam deploy --guided
```

### 인프라 생성 코드

```bash
AWSTemplateFormatVersion: '2010-09-09'
Transform: AWS::Serverless-2016-10-31
Description: >
  (uksb-1tthgi812) (tag:apigw-ec2)
  This CloudFormation deploys public REST API along with private network load balancer which will route the request to an EC2 website via vpc link
Parameters:
  InstanceType:
    Type: String
    Description: Select an instance type
    Default: t2.micro
    AllowedValues: [c4.2xlarge, c4.4xlarge, c4.8xlarge, c4.large, c4.xlarge, c5.12xlarge, c5.18xlarge, c5.24xlarge, c5.2xlarge, c5.4xlarge, c5.9xlarge, c5.large, c5.metal, c5.xlarge, c5a.12xlarge, c5a.16xlarge, c5a.24xlarge, c5a.2xlarge, c5a.4xlarge, c5a.8xlarge, c5a.large, c5a.xlarge, c5d.12xlarge, c5d.18xlarge, c5d.24xlarge, c5d.2xlarge, c5d.4xlarge, c5d.9xlarge, c5d.large, c5d.metal, c5d.xlarge, c5n.18xlarge, c5n.2xlarge, c5n.4xlarge, c5n.9xlarge, c5n.large, c5n.metal, c5n.xlarge, c6g.12xlarge, c6g.16xlarge, c6g.2xlarge, c6g.4xlarge, c6g.8xlarge, c6g.large, c6g.medium, c6g.metal, c6g.xlarge, c6gd.12xlarge, c6gd.16xlarge, c6gd.2xlarge, c6gd.4xlarge, c6gd.8xlarge, c6gd.large, c6gd.medium, c6gd.metal, c6gd.xlarge, c6gn.12xlarge, c6gn.16xlarge, c6gn.2xlarge, c6gn.4xlarge, c6gn.8xlarge, c6gn.large, c6gn.medium, c6gn.xlarge, c6i.12xlarge, c6i.16xlarge, c6i.24xlarge, c6i.2xlarge, c6i.32xlarge, c6i.4xlarge, c6i.8xlarge, c6i.large, c6i.metal, c6i.xlarge, d2.2xlarge, d2.4xlarge, d2.8xlarge, d2.xlarge, d3.2xlarge, d3.4xlarge, d3.8xlarge, d3.xlarge, g3.16xlarge, g3.4xlarge, g3.8xlarge, g4ad.16xlarge, g4ad.2xlarge, g4ad.4xlarge, g4ad.8xlarge, g4ad.xlarge, g4dn.12xlarge, g4dn.16xlarge, g4dn.2xlarge, g4dn.4xlarge, g4dn.8xlarge, g4dn.metal, g4dn.xlarge, g5.12xlarge, g5.16xlarge, g5.24xlarge, g5.2xlarge, g5.48xlarge, g5.4xlarge, g5.8xlarge, g5.xlarge, i3.16xlarge, i3.2xlarge, i3.4xlarge, i3.8xlarge, i3.large, i3.metal, i3.xlarge, i3en.12xlarge, i3en.24xlarge, i3en.2xlarge, i3en.3xlarge, i3en.6xlarge, i3en.large, i3en.metal, i3en.xlarge, i4i.16xlarge, i4i.2xlarge, i4i.32xlarge, i4i.4xlarge, i4i.8xlarge, i4i.large, i4i.metal, i4i.xlarge, im4gn.16xlarge, im4gn.2xlarge, im4gn.4xlarge, im4gn.8xlarge, im4gn.large, im4gn.xlarge, inf1.24xlarge, inf1.2xlarge, inf1.6xlarge, inf1.xlarge, is4gen.2xlarge, is4gen.4xlarge, is4gen.8xlarge, is4gen.large, is4gen.medium, is4gen.xlarge, m4.10xlarge, m4.16xlarge, m4.2xlarge, m4.4xlarge, m4.large, m4.xlarge, m5.12xlarge, m5.16xlarge, m5.24xlarge, m5.2xlarge, m5.4xlarge, m5.8xlarge, m5.large, m5.metal, m5.xlarge, m5a.12xlarge, m5a.16xlarge, m5a.24xlarge, m5a.2xlarge, m5a.4xlarge, m5a.8xlarge, m5a.large, m5a.xlarge, m5ad.12xlarge, m5ad.16xlarge, m5ad.24xlarge, m5ad.2xlarge, m5ad.4xlarge, m5ad.8xlarge, m5ad.large, m5ad.xlarge, m5d.12xlarge, m5d.16xlarge, m5d.24xlarge, m5d.2xlarge, m5d.4xlarge, m5d.8xlarge, m5d.large, m5d.metal, m5d.xlarge, m6g.12xlarge, m6g.16xlarge, m6g.2xlarge, m6g.4xlarge, m6g.8xlarge, m6g.large, m6g.medium, m6g.metal, m6g.xlarge, m6i.12xlarge, m6i.16xlarge, m6i.24xlarge, m6i.2xlarge, m6i.32xlarge, m6i.4xlarge, m6i.8xlarge, m6i.large, m6i.metal, m6i.xlarge, p3.16xlarge, p3.2xlarge, p3.8xlarge, r4.16xlarge, r4.2xlarge, r4.4xlarge, r4.8xlarge, r4.large, r4.xlarge, r5.12xlarge, r5.16xlarge, r5.24xlarge, r5.2xlarge, r5.4xlarge, r5.8xlarge, r5.large, r5.metal, r5.xlarge, r5a.12xlarge, r5a.16xlarge, r5a.24xlarge, r5a.2xlarge, r5a.4xlarge, r5a.8xlarge, r5a.large, r5a.xlarge, r5ad.12xlarge, r5ad.16xlarge, r5ad.24xlarge, r5ad.2xlarge, r5ad.4xlarge, r5ad.8xlarge, r5ad.large, r5ad.xlarge, r5b.12xlarge, r5b.16xlarge, r5b.24xlarge, r5b.2xlarge, r5b.4xlarge, r5b.8xlarge, r5b.large, r5b.metal, r5b.xlarge, r5d.12xlarge, r5d.16xlarge, r5d.24xlarge, r5d.2xlarge, r5d.4xlarge, r5d.8xlarge, r5d.large, r5d.metal, r5d.xlarge, r5n.12xlarge, r5n.16xlarge, r5n.24xlarge, r5n.2xlarge, r5n.4xlarge, r5n.8xlarge, r5n.large, r5n.metal, r5n.xlarge, r6g.12xlarge, r6g.16xlarge, r6g.2xlarge, r6g.4xlarge, r6g.8xlarge, r6g.large, r6g.medium, r6g.metal, r6g.xlarge, r6gd.12xlarge, r6gd.16xlarge, r6gd.2xlarge, r6gd.4xlarge, r6gd.8xlarge, r6gd.large, r6gd.medium, r6gd.metal, r6gd.xlarge, r6i.12xlarge, r6i.16xlarge, r6i.24xlarge, r6i.2xlarge, r6i.32xlarge, r6i.4xlarge, r6i.8xlarge, r6i.large, r6i.metal, r6i.xlarge, t2.2xlarge, t2.large, t2.medium, t2.micro, t2.nano, t2.small, t2.xlarge, t3.2xlarge, t3.large, t3.medium, t3.micro, t3.nano, t3.small, t3.xlarge, t3a.2xlarge, t3a.large, t3a.medium, t3a.micro, t3a.nano, t3a.small, t3a.xlarge, t4g.2xlarge, t4g.large, t4g.medium, t4g.micro, t4g.nano, t4g.small, t4g.xlarge, u-3tb1.56xlarge, u-6tb1.112xlarge, u-6tb1.56xlarge, x1.16xlarge, x1.32xlarge, x1e.16xlarge, x1e.2xlarge, x1e.32xlarge, x1e.4xlarge, x1e.8xlarge, x1e.xlarge, x2idn.16xlarge, x2idn.24xlarge, x2idn.32xlarge, x2idn.metal, x2iedn.16xlarge, x2iedn.24xlarge, x2iedn.2xlarge, x2iedn.32xlarge, x2iedn.4xlarge, x2iedn.8xlarge, x2iedn.metal, x2iedn.xlarge, c5ad.12xlarge, c5ad.16xlarge, c5ad.24xlarge, c5ad.2xlarge, c5ad.4xlarge, c5ad.8xlarge, c5ad.large, c5ad.xlarge, c6a.12xlarge, c6a.16xlarge, c6a.24xlarge, c6a.2xlarge, c6a.32xlarge, c6a.48xlarge, c6a.4xlarge, c6a.8xlarge, c6a.large, c6a.metal, c6a.xlarge, c6id.12xlarge, c6id.16xlarge, c6id.24xlarge, c6id.2xlarge, c6id.32xlarge, c6id.4xlarge, c6id.8xlarge, c6id.large, c6id.metal, c6id.xlarge, c6in.12xlarge, c6in.16xlarge, c6in.24xlarge, c6in.2xlarge, c6in.32xlarge, c6in.4xlarge, c6in.8xlarge, c6in.large, c6in.xlarge, c7g.12xlarge, c7g.16xlarge, c7g.2xlarge, c7g.4xlarge, c7g.8xlarge, c7g.large, c7g.medium, c7g.metal, c7g.xlarge, d3en.12xlarge, d3en.2xlarge, d3en.4xlarge, d3en.6xlarge, d3en.8xlarge, d3en.xlarge, dl1.24xlarge, f1.16xlarge, f1.2xlarge, f1.4xlarge, g3s.xlarge, g5g.16xlarge, g5g.2xlarge, g5g.4xlarge, g5g.8xlarge, g5g.metal, g5g.xlarge, h1.16xlarge, h1.2xlarge, h1.4xlarge, h1.8xlarge, m5dn.12xlarge, m5dn.16xlarge, m5dn.24xlarge, m5dn.2xlarge, m5dn.4xlarge, m5dn.8xlarge, m5dn.large, m5dn.metal, m5dn.xlarge, m5n.12xlarge, m5n.16xlarge, m5n.24xlarge, m5n.2xlarge, m5n.4xlarge, m5n.8xlarge, m5n.large, m5n.metal, m5n.xlarge, m5zn.12xlarge, m5zn.2xlarge, m5zn.3xlarge, m5zn.6xlarge, m5zn.large, m5zn.metal, m5zn.xlarge, m6a.12xlarge, m6a.16xlarge, m6a.24xlarge, m6a.2xlarge, m6a.32xlarge, m6a.48xlarge, m6a.4xlarge, m6a.8xlarge, m6a.large, m6a.metal, m6a.xlarge, m6gd.12xlarge, m6gd.16xlarge, m6gd.2xlarge, m6gd.4xlarge, m6gd.8xlarge, m6gd.large, m6gd.medium, m6gd.metal, m6gd.xlarge, m6id.12xlarge, m6id.16xlarge, m6id.24xlarge, m6id.2xlarge, m6id.32xlarge, m6id.4xlarge, m6id.8xlarge, m6id.large, m6id.metal, m6id.xlarge, m6idn.12xlarge, m6idn.16xlarge, m6idn.24xlarge, m6idn.2xlarge, m6idn.32xlarge, m6idn.4xlarge, m6idn.8xlarge, m6idn.large, m6idn.xlarge, m6in.12xlarge, m6in.16xlarge, m6in.24xlarge, m6in.2xlarge, m6in.32xlarge, m6in.4xlarge, m6in.8xlarge, m6in.large, m6in.xlarge, m7g.12xlarge, m7g.16xlarge, m7g.2xlarge, m7g.4xlarge, m7g.8xlarge, m7g.large, m7g.medium, m7g.metal, m7g.xlarge, mac1.metal, mac2.metal, p2.16xlarge, p2.8xlarge, p2.xlarge, p3dn.24xlarge, p4d.24xlarge, r5dn.12xlarge, r5dn.16xlarge, r5dn.24xlarge, r5dn.2xlarge, r5dn.4xlarge, r5dn.8xlarge, r5dn.large, r5dn.metal, r5dn.xlarge, r6a.12xlarge, r6a.16xlarge, r6a.24xlarge, r6a.2xlarge, r6a.32xlarge, r6a.48xlarge, r6a.4xlarge, r6a.8xlarge, r6a.large, r6a.metal, r6a.xlarge, r6id.12xlarge, r6id.16xlarge, r6id.24xlarge, r6id.2xlarge, r6id.32xlarge, r6id.4xlarge, r6id.8xlarge, r6id.large, r6id.metal, r6id.xlarge, r6idn.12xlarge, r6idn.16xlarge, r6idn.24xlarge, r6idn.2xlarge, r6idn.32xlarge, r6idn.4xlarge, r6idn.8xlarge, r6idn.large, r6idn.xlarge, r6in.12xlarge, r6in.16xlarge, r6in.24xlarge, r6in.2xlarge, r6in.32xlarge, r6in.4xlarge, r6in.8xlarge, r6in.large, r6in.xlarge, r7g.12xlarge, r7g.16xlarge, r7g.2xlarge, r7g.4xlarge, r7g.8xlarge, r7g.large, r7g.medium, r7g.metal, r7g.xlarge, trn1.2xlarge, trn1.32xlarge, u-12tb1.112xlarge, u-18tb1.112xlarge, u-24tb1.112xlarge, u-9tb1.112xlarge, vt1.24xlarge, vt1.3xlarge, vt1.6xlarge, x2gd.12xlarge, x2gd.16xlarge, x2gd.2xlarge, x2gd.4xlarge, x2gd.8xlarge, x2gd.large, x2gd.medium, x2gd.metal, x2gd.xlarge, x2iezn.12xlarge, x2iezn.2xlarge, x2iezn.4xlarge, x2iezn.6xlarge, x2iezn.8xlarge, x2iezn.metal, z1d.12xlarge, z1d.2xlarge, z1d.3xlarge, z1d.6xlarge, z1d.large, z1d.metal, z1d.xlarge, hpc6a.48xlarge, hpc6id.32xlarge]

  KeyPair:
    Description: Select the key pair 
    Type: AWS::EC2::KeyPair::KeyName

  VPC:
    Description: Please select if you want to use existing VPC
    Type: AWS::EC2::VPC::Id
  
  PrivateSubnetIDs: 
    Description: Private Subnet IDs for VPCE
    Type: ""List<AWS::EC2::Subnet::Id>""

  SecurityGroupIDsForNLBAndEC2: 
    Description: Security group IDs for NLB and EC2. Note - please make sure that the security group allows traffic on port 80 from VPC Cidr or 0.0.0.0
    Type: ""List<AWS::EC2::SecurityGroup::Id>""
  
  RouteTableId:
    Description: PrivateSubnets route table Id
    Type: String

Mappings:
  RegionMap:
    us-east-1:
      AMI: ami-0dfcb1ef8550277af
    us-east-2:
      AMI: ami-0cc87e5027adcdca8
    us-west-1:
      AMI: ami-00569e54da628d17c
    us-west-2:
      AMI: ami-0f1a5f5ada0e7da53
    ap-southeast-4:
      AMI: ami-0272ee0cbe63bb8e8
    ap-east-1:
      AMI: ami-0e679816c1d0be6df
    ap-south-2:
      AMI: ami-0155ae3341da656ae
    ap-south-1:
      AMI: ami-0e742cca61fb65051
    ap-northeast-3:
      AMI: ami-090ae0a4750988734
    ap-northeast-2:
      AMI: ami-0f6e451b865011317
    ca-central-1:
      AMI: ami-099effcf516c942b7
    eu-north-1:
      AMI: ami-0bb935e4614c12d86
    eu-west-1:
      AMI: ami-06e0ce9d3339cb039
    eu-west-2:
      AMI: ami-09ee0944866c73f62
    eu-west-3:
      AMI: ami-00575c0cbc20caf50
    eu-central-1:
      AMI: ami-0c0d3776ef525d5dd
    ap-southeast-1:
      AMI: ami-0f2eac25772cd4e36
    ap-southeast-2:
      AMI: ami-0692dea0a2f8a1b35
    ap-northeast-1:
      AMI: ami-0ffac3e16de16665e
    sa-east-1:
      AMI: ami-01fc9174dd9330556
    af-south-1:
      AMI: ami-0d4fd6ba7ffe8260e
    ap-southeast-3:
      AMI: ami-0ebaeda1c62cceddb
    eu-west-3:
      AMI: ami-00575c0cbc20caf50
    eu-south-2:
      AMI: ami-089ea1de61e0c9c18
    me-south-1:
      AMI: ami-06131a860e2930b5c
    me-central-1:
      AMI: ami-0c30c5d64bef7fade
    

Resources:
  VPCE:
    Type: AWS::EC2::VPCEndpoint
    Properties: 
      RouteTableIds: 
        - !Ref RouteTableId
      ServiceName: !Sub com.amazonaws.${AWS::Region}.s3
      VpcEndpointType: Gateway
      VpcId: !Ref VPC

  EC2:
    Type: AWS::EC2::Instance
    DependsOn: ApiGatewayModel
    Properties:
      InstanceType: !Ref InstanceType
      KeyName: !Ref KeyPair
      ImageId: !FindInMap [RegionMap, !Ref 'AWS::Region', AMI]
      SecurityGroupIds: !Ref SecurityGroupIDsForNLBAndEC2
      SubnetId: !Select [0, !Ref PrivateSubnetIDs]
      UserData:
        Fn::Base64:
          !Sub  |
            #!/bin/bash
            yum update -y
            sudo amazon-linux-extras install nginx1 -y
            sudo systemctl enable --now nginx
      Tags:
        - Key: Name
          Value: priv

  NetworkLoadBalancer:
    DependsOn:  EC2
    Type: AWS::ElasticLoadBalancingV2::LoadBalancer
    Properties: 
      Name: NLB
      Scheme: internal
      Subnets:
        - !Select [0, !Ref PrivateSubnetIDs]
        - !Select [1, !Ref PrivateSubnetIDs]
      Type: network
  
  NetworkLoadBalancerTargetGroup:
    DependsOn:  EC2
    Type: AWS::ElasticLoadBalancingV2::TargetGroup
    Properties:
      Port: 80
      Name: NLBTargetGroup
      HealthCheckEnabled: true
      Protocol: TCP
      VpcId: !Ref VPC
      Targets:
        - Id: !GetAtt EC2.PrivateIp
          Port: 80
      TargetType: ip
  
  NetworkLoadBalancerListener:
    DependsOn: NetworkLoadBalancerTargetGroup
    Type: AWS::ElasticLoadBalancingV2::Listener
    Properties:
      DefaultActions:
        - Type: forward
          TargetGroupArn: !Ref NetworkLoadBalancerTargetGroup
      LoadBalancerArn: !Ref NetworkLoadBalancer
      Port: '80'
      Protocol: TCP

  ApiGatewayRestApi:
    Type: 'AWS::ApiGateway::RestApi'
    DependsOn: VPCE
    Properties:
      ApiKeySourceType: HEADER
      Description: An API Gateway to connect to ec2 server
      Name: PublicApiViaCFN
      EndpointConfiguration:
        Types:
          - REGIONAL
  
  ApiGatewayGetMethod:
    DependsOn: VPCLink
    Type: AWS::ApiGateway::Method
    Properties:
      HttpMethod: GET
      AuthorizationType: NONE
      Integration:
        ConnectionType: VPC_LINK
        ConnectionId: ""${stageVariables.vpclink}""
        IntegrationHttpMethod: GET
        PassthroughBehavior: WHEN_NO_MATCH
        TimeoutInMillis: 10000
        Type: HTTP_PROXY
        Uri: !Sub 
              - ""http://${privateIP}""
              - privateIP: !GetAtt EC2.PrivateIp
      ResourceId: !GetAtt ApiGatewayRestApi.RootResourceId
      RestApiId: !Ref ApiGatewayRestApi
  
  ApiGatewayModel:
    DependsOn: ApiGatewayRestApi
    Type: AWS::ApiGateway::Model
    Properties:
      ContentType: 'application/json'
      RestApiId: !Ref ApiGatewayRestApi
      Schema: {}
  
  ApiGatewayStage:
    Type: AWS::ApiGateway::Stage
    DependsOn: ApiGatewayDeployment
    Properties:
      DeploymentId: !Ref ApiGatewayDeployment
      Description: API Stage v0
      RestApiId: !Ref ApiGatewayRestApi
      StageName: 'v0'
      Variables:
        vpclink: !Ref VPCLink
  
  ApiGatewayDeployment:
    Type: 'AWS::ApiGateway::Deployment'
    DependsOn: ApiGatewayGetMethod
    Properties:
      RestApiId: !Ref ApiGatewayRestApi
 
  VPCLink:
    Type: AWS::ApiGateway::VpcLink
    DependsOn: NetworkLoadBalancer
    Properties: 
      Name: NLB
      TargetArns:
        - !Join
            - ''
            - - 'arn:aws:elasticloadbalancing:'
              - !Ref AWS::Region
              - ':'
              - !Ref AWS::AccountId
              - ':loadbalancer/'
              - !GetAtt NetworkLoadBalancer.LoadBalancerFullName

Outputs:
  WebsiteURL:
    Value: !Sub 
            - ""curl https://${ApiId}.execute-api.${AWS::Region}.amazonaws.com/v0""
            - ApiId: !Ref ApiGatewayRestApi
    Description: ApiGateway URL
```",https://rattle-stock-d32.notion.site/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2Fe7472e42-7118-406f-8758-f9c76b1cf86a%2Fefd78a35-c62a-4f8e-b123-5eef86644b1b%2FUntitled.png?table=block&id=03e3e5f4-fdac-43a9-ad92-57e630962bff&spaceId=e7472e42-7118-406f-8758-f9c76b1cf86a&width=1320&userId=&cache=v2,Network & Content Delivery,Developer,"API Gateway, NLB, 및 EC2에서 실행되는 NGINX를 통합하여 내부 리소스에 대한 안전하고 효율적인 접근 방식을 구현합니다."," API Gateway, Network Load Balancer, Elastic Compute Cloud, VPC Link, RESTful API, NGINX server, TCP traffic, UDP traffic, VPC, Security groups, Route table, Load balancer, EC2 instance,"
18,VPC Link를 통한 안전한 컨테이너 배포,"## **개요**

AWS API Gateway, ECS Fargate, 그리고 Application Load Balancer (ALB)를 조합하여 사용하면, 완전히 관리되는 컨테이너 서비스와 고성능 로드 밸런서를 활용하여 보안이 강화된 공개 API 엔드포인트를 구성할 수 있습니다. 이 아키텍처는 내부 네트워크 리소스를 외부에 노출하지 않으면서도 공개적으로 접근 가능한 API를 제공합니다.

## **서비스 소개**

### **AWS API Gateway**

API Gateway는 사용자가 HTTP, HTTPS 프로토콜을 기반으로 API를 쉽게 생성, 배포, 유지 관리할 수 있도록 해주는 완전 관리형 서비스입니다. 공개 API를 제공하는 동시에 보안과 트래픽 관리, API 버전 관리 등의 기능을 지원합니다.

### **ECS Fargate**

ECS Fargate는 서버를 직접 관리하지 않고도 컨테이너를 실행할 수 있는 서비스입니다. 사용자는 애플리케이션의 실행에 필요한 컴퓨팅 파워를 관리할 필요 없이, 컨테이너 오케스트레이션과 스케일링에 집중할 수 있습니다.

### **Application Load Balancer (ALB)**

ALB는 고가용성과 자동 확장 기능을 제공하는 로드 밸런서로, HTTP 및 HTTPS 트래픽의 효율적인 라우팅을 지원합니다. ALB는 다중 태스크 또는 서비스에 걸쳐 트래픽을 분산시키고, 세션 지속성을 관리하여 애플리케이션의 부하를 균등하게 분배합니다.

## **통합 사용 시나리오**

1. **보안 API 엔드포인트 구성**:
    - API Gateway는 VPC Link를 사용하여 사설 ALB에 접근하며, 이 ALB는 ECS Fargate 클러스터 뒤에 위치합니다.
    - 이 구조는 공개 인터넷을 통해 직접 접근할 수 없는 리소스에 대한 보안된 경로를 제공하며, 사용자는 API Gateway를 통해서만 ECS Fargate에서 호스팅되는 애플리케이션에 접근할 수 있습니다.
2. **리소스 보호 및 접근 제어**:
    - 필요한 보안 그룹, 서비스 및 태스크 정의를 포함한 ECS Fargate 클러스터가 구성되어, 내부 네트워크 리소스의 보호를 강화합니다.
    - ALB는 사설 네트워크 내에서만 활성화되며, 외부로부터의 직접적인 접근을 차단합니다. API Gateway와의 통합은 VPC Link를 통해 이루어져, 높은 수준의 보안을 유지합니다.

## 예제

### git

??Visit the?[GitHub repo for this pattern](https://github.com/aws-samples/serverless-patterns/tree/main/apigw-vpclink-pvt-alb-terraform).

```java
git clone https://github.com/aws-samples/serverless-patterns/ 
cd serverless-patterns/apigw-vpclink-pvt-alb-terraform
```

### 배포

```bash
terraform init
terraform apply --auto-approve
```

### 인프라 생성 코드

```bash
# Required providers configuration
terraform {
  required_providers {
    aws = {
      source  = ""hashicorp/aws""
      version = ""~> 4.0.0""
    }
  }

  required_version = "">= 1.0.11""
}

# AWS provider configuration
provider ""aws"" {
  profile = ""default""
  region  = ""us-east-1""
}

# Load balancer security group. CIDR and port ingress can be changed as required.
resource ""aws_security_group"" ""lb_security_group"" {
  description = ""LoadBalancer Security Group""
  vpc_id = var.vpc_id
  ingress {
    description      = ""Allow from anyone on port 80""
    from_port        = 80
    to_port          = 80
    protocol         = ""tcp""
    cidr_blocks      = [""0.0.0.0/0""]
  }
}
resource ""aws_security_group_rule"" ""sg_ingress_rule_all_to_lb"" {
  type	= ""ingress""
  description = ""Allow from anyone on port 80""
  from_port         = 80
  to_port           = 80
  protocol          = ""tcp""
  cidr_blocks       = [""0.0.0.0/0""]
  ipv6_cidr_blocks  = [""::/0""]
  security_group_id = aws_security_group.lb_security_group.id
}

# Load balancer security group egress rule to ECS cluster security group.
resource ""aws_security_group_rule"" ""sg_egress_rule_lb_to_ecs_cluster"" {
  type	= ""egress""
  description = ""Target group egress""
  from_port         = 80
  to_port           = 80
  protocol          = ""tcp""
  security_group_id = aws_security_group.lb_security_group.id
  source_security_group_id = aws_security_group.ecs_security_group.id
}

# ECS cluster security group.
resource ""aws_security_group"" ""ecs_security_group"" {
  description = ""ECS Security Group""
  vpc_id = var.vpc_id
  egress {
    description      = ""Allow all outbound traffic by default""
    from_port        = 0
    to_port          = 0
    protocol         = ""-1""
    cidr_blocks      = [""0.0.0.0/0""]
  }
}

# ECS cluster security group ingress from the load balancer.
resource ""aws_security_group_rule"" ""sg_ingress_rule_ecs_cluster_from_lb"" {
  type	= ""ingress""
  description = ""Ingress from Load Balancer""
  from_port         = 80
  to_port           = 80
  protocol          = ""tcp""
  security_group_id = aws_security_group.ecs_security_group.id
  source_security_group_id = aws_security_group.lb_security_group.id
}

# Create the internal application load balancer (ALB) in the private subnets.
resource ""aws_lb"" ""ecs_alb"" {
  load_balancer_type = ""application""
  internal = true
  subnets = var.private_subnets
  security_groups = [aws_security_group.lb_security_group.id]
}

# Create the ALB target group for ECS.
resource ""aws_lb_target_group"" ""alb_ecs_tg"" {
  port        = 80
  protocol    = ""HTTP""
  target_type = ""ip""
  vpc_id      = var.vpc_id
}

# Create the ALB listener with the target group.
resource ""aws_lb_listener"" ""ecs_alb_listener"" {
  load_balancer_arn = aws_lb.ecs_alb.arn
  port              = ""80""
  protocol          = ""HTTP""
  default_action {
    type             = ""forward""
    target_group_arn = aws_lb_target_group.alb_ecs_tg.arn
  }
}

# Create the ECS Cluster and Fargate launch type service in the private subnets
resource ""aws_ecs_cluster"" ""ecs_cluster"" {
  name  = ""demo-ecs-cluster""
}

resource ""aws_ecs_service"" ""demo-ecs-service"" {
  name            = ""demo-ecs-svc""
  cluster         = aws_ecs_cluster.ecs_cluster.id
  task_definition = aws_ecs_task_definition.ecs_taskdef.arn
  desired_count   = 2
  deployment_maximum_percent = 200
  deployment_minimum_healthy_percent = 50
  enable_ecs_managed_tags = false
  health_check_grace_period_seconds = 60
  launch_type = ""FARGATE""
  depends_on      = [aws_lb_target_group.alb_ecs_tg, aws_lb_listener.ecs_alb_listener]

  load_balancer {
    target_group_arn = aws_lb_target_group.alb_ecs_tg.arn
    container_name   = ""web""
    container_port   = 80
  }

  network_configuration {
    security_groups = [aws_security_group.ecs_security_group.id]
    subnets = var.private_subnets
  }
}

# Create the ECS Service task definition. 
# 'nginx' image is being used in the container definition.
# This image is pulled from the docker hub which is the default image repository.
# ECS task execution role and the task role is used which can be attached with additional IAM policies to configure the required permissions.
resource ""aws_ecs_task_definition"" ""ecs_taskdef"" {
  family = ""service""
  container_definitions = jsonencode([
    {
      name      = ""web""
      image     = ""nginx""
      essential = true
      portMappings = [
        {
          containerPort = 80
          protocol      = ""tcp""
        }
      ]
    }
  ])
  cpu       = 512
  memory    = 1024
  execution_role_arn = aws_iam_role.ecs_task_exec_role.arn
  task_role_arn = aws_iam_role.ecs_task_role.arn
  requires_compatibilities = [""FARGATE""]
  network_mode             = ""awsvpc""
}
resource ""aws_iam_role"" ""ecs_task_exec_role"" {
  name = ""ecs_task_exec_role""
  assume_role_policy = jsonencode({
    Version = ""2012-10-17""
    Statement = [
      {
        Action = ""sts:AssumeRole""
        Effect = ""Allow""
        Principal = {
          Service = ""ecs-tasks.amazonaws.com""
        }
      },
    ]
  })
}
resource ""aws_iam_role"" ""ecs_task_role"" {
  name = ""ecs_task_role""
  assume_role_policy = jsonencode({
    Version = ""2012-10-17""
    Statement = [
      {
        Action = ""sts:AssumeRole""
        Effect = ""Allow""
        Principal = {
          Service = ""ecs-tasks.amazonaws.com""
        }
      },
    ]
  })
}

# Create the VPC Link configured with the private subnets. Security groups are kept empty here, but can be configured as required.
resource ""aws_apigatewayv2_vpc_link"" ""vpclink_apigw_to_alb"" {
  name        = ""vpclink_apigw_to_alb""
  security_group_ids = []
  subnet_ids = var.private_subnets
}

# Create the API Gateway HTTP endpoint
resource ""aws_apigatewayv2_api"" ""apigw_http_endpoint"" {
  name          = ""serverlessland-pvt-endpoint""
  protocol_type = ""HTTP""
}

# Create the API Gateway HTTP_PROXY integration between the created API and the private load balancer via the VPC Link.
# Ensure that the 'DependsOn' attribute has the VPC Link dependency.
# This is to ensure that the VPC Link is created successfully before the integration and the API GW routes are created.
resource ""aws_apigatewayv2_integration"" ""apigw_integration"" {
  api_id           = aws_apigatewayv2_api.apigw_http_endpoint.id
  integration_type = ""HTTP_PROXY""
  integration_uri  = aws_lb_listener.ecs_alb_listener.arn

  integration_method = ""ANY""
  connection_type    = ""VPC_LINK""
  connection_id      = aws_apigatewayv2_vpc_link.vpclink_apigw_to_alb.id
  payload_format_version = ""1.0""
  depends_on      = [aws_apigatewayv2_vpc_link.vpclink_apigw_to_alb, 
                    aws_apigatewayv2_api.apigw_http_endpoint, 
                    aws_lb_listener.ecs_alb_listener]
}

# API GW route with ANY method
resource ""aws_apigatewayv2_route"" ""apigw_route"" {
  api_id    = aws_apigatewayv2_api.apigw_http_endpoint.id
  route_key = ""ANY /{proxy+}""
  target = ""integrations/${aws_apigatewayv2_integration.apigw_integration.id}""
  depends_on  = [aws_apigatewayv2_integration.apigw_integration]
}

# Set a default stage
resource ""aws_apigatewayv2_stage"" ""apigw_stage"" {
  api_id = aws_apigatewayv2_api.apigw_http_endpoint.id
  name   = ""$default""
  auto_deploy = true
  depends_on  = [aws_apigatewayv2_api.apigw_http_endpoint]
}

# Generated API GW endpoint URL that can be used to access the application running on a private ECS Fargate cluster.
output ""apigw_endpoint"" {
  value = aws_apigatewayv2_api.apigw_http_endpoint.api_endpoint
    description = ""API Gateway Endpoint""
}

```",https://rattle-stock-d32.notion.site/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2Fe7472e42-7118-406f-8758-f9c76b1cf86a%2F60c47635-f24e-44e6-a95b-b56f3c4a36d1%2FUntitled.png?table=block&id=d28c53c6-2189-44cf-a457-9e5027e14053&spaceId=e7472e42-7118-406f-8758-f9c76b1cf86a&width=1130&userId=&cache=v2,Architecting,Architect,"API Gateway, ECS Fargate, ALB를 통합하여 사설 네트워크 리소스에 안전하고 효율적인 접근을 제공하는 공개 API 엔드포인트를 구성합니다.","API Gateway, ECS Fargate, Application Load Balancer, VPC Link, containerization, microservices, security groups, Terraform"
19,도메인 이름으로 ECS Fargate 서비스에 접근하기,"## 개요

Amazon ECS Fargate, Application Load Balancer (ALB), 그리고 Route53을 사용하여 컨테이너화된 Web API를 배포하고 사용자 정의 도메인을 통해 외부에 노출하는 구성은 안전하고 확장 가능한 서버리스 웹 애플리케이션을 구축하는 효과적인 방법을 제공합니다. 이 구조는 공개 및 사설 서브넷을 활용하여 웹 API의 보안과 접근성을 최적화합니다.

## 서비스 소개

### **Amazon ECS Fargate**

ECS Fargate는 서버 관리의 필요성 없이 컨테이너를 실행할 수 있게 해주는 서비스입니다. 이를 통해 개발자는 인프라 관리보다 애플리케이션 개발에 더 집중할 수 있으며, Fargate는 자동 확장과 보안을 관리합니다.

### **Application Load Balancer (ALB)**

ALB는 고가용성과 자동 확장 기능을 제공하는 로드 밸런서로, 애플리케이션의 트래픽을 관리하고 SSL 오프로딩을 수행하여 보안을 강화합니다. ALB는 경로 기반 라우팅을 지원하여 다양한 서비스 요구 사항에 유연하게 대응할 수 있습니다.

### **Route53**

Route53은 AWS에서 제공하는 확장 가능한 도메인 이름 시스템(DNS) 웹 서비스입니다. 이를 통해 도메인 이름을 관리하고 인터넷 트래픽을 적절한 서버나 리소스로 라우팅할 수 있습니다. Route53은 사용자 정의 도메인 이름으로 서비스를 접근할 수 있게 하며, 높은 가용성과 빠른 응답성을 제공합니다.

## 통합 사용 시나리오

1. **안전한 웹 API 배포**:
    - CDK 스택은 ECS Fargate 서비스를 생성하여 컨테이너화된 Web API를 호스팅합니다. 이 서비스는 공개 서브넷에 위치한 ALB에 의해 전면에서 관리되고, ECS 작업은 사설 서브넷에서 실행됩니다.
    - ALB는 SSL 오프로딩을 수행하여 보안을 강화하고, HTTPS를 통해 안전한 연결을 제공합니다.
2. **사용자 정의 도메인을 통한 접근성 향상**:
    - Route53은 사용자의 요청을 받아 ALB로 전달하고, ALB는 해당 요청을 적절한 ECS 태스크로 라우팅합니다. 이 과정에서 사용자는 사용자 정의 도메인을 통해 API에 접근할 수 있습니다.
    - 이 구성은 웹 애플리케이션의 접근성을 높이고, 브랜드 인지도를 강화하는데 기여합니다.

## 예제

### git

??Visit the?[GitHub repo for this pattern](https://github.com/aws-samples/serverless-patterns/tree/main/route53-alb-fargate-cdk-dotnet).

```java
git clone https://github.com/aws-samples/serverless-patterns/ 
cd serverless-patterns/route53-alb-fargate-cdk-dotnet
```

### 배포

```bash
See the GitHub repo for detailed deployment instructions.
```

### 인프라 생성 코드

```bash
using Amazon.CDK;
using Amazon.CDK.AWS.CertificateManager;
using Amazon.CDK.AWS.EC2;
using Amazon.CDK.AWS.Ecr.Assets;
using Amazon.CDK.AWS.ECS;
using Amazon.CDK.AWS.ECS.Patterns;
using Amazon.CDK.AWS.Route53;
using Amazon.CDK.AWS.Route53.Targets;
using Constructs;
using Microsoft.Extensions.Options;
using System.Collections.Generic;

namespace Route53AlbFargateCdkDotnet
{
    public class Route53AlbFargateCdkDotnetStack : Stack
    {
        internal Route53AlbFargateCdkDotnetStack(Construct scope, string id, IStackProps props = null) : base(scope, id, props)
        {
            // Replace the value with your domain name
            string apiDomainName = ""api.YOUR-DOMAIN.com"";

            // 1. Hosted zone
            var hostedZone = new HostedZone(this, ""hosted-zone"", new HostedZoneProps
            {
                ZoneName = apiDomainName
            });
            hostedZone.ApplyRemovalPolicy(RemovalPolicy.RETAIN);

            // 2. SSL certificate via ACM
            var certificate = new Certificate(this, ""certificate"", new CertificateProps
            {
                DomainName = apiDomainName,
                Validation = CertificateValidation.FromDns(hostedZone),
            });

            // 3. VPC with public and private subnets
            var vpc = new Vpc(this, ""vpc"", new VpcProps
            {
                Cidr = ""10.0.0.0/16"",
                MaxAzs = 3,
                SubnetConfiguration = new[]
                {
                    new SubnetConfiguration
                    {
                        Name=""private"",
                        SubnetType= SubnetType.PRIVATE_ISOLATED,
                        CidrMask= 24
                    },
                    new SubnetConfiguration
                    {
                        Name=""public"",
                        SubnetType= SubnetType.PUBLIC,
                        CidrMask= 24
                    }
                }
            });

            // Create required VPC endpoints to privately retrieve docker images from the ECR repository
            // Reference link - https://docs.aws.amazon.com/AmazonECR/latest/userguide/vpc-endpoints.html

            // 4.1. VPC endpoint 1
            var ecrDockerVpcEndpoint = new InterfaceVpcEndpoint(this, ""ecr-dkr-vpc-endpoint"", new InterfaceVpcEndpointProps
            {
                Vpc = vpc,
                Service = InterfaceVpcEndpointAwsService.ECR_DOCKER,
                PrivateDnsEnabled = true
            });

            // 4.2. VPC endpoint 2
            var ecrVpcEndpoint = new InterfaceVpcEndpoint(this, ""ecr-vpc-endpoint"", new InterfaceVpcEndpointProps
            {
                Vpc = vpc,
                Service = InterfaceVpcEndpointAwsService.ECR,
                PrivateDnsEnabled = true
            });

            // 4.3. VPC endpoint 3
            var cwVpcEndpoint = new InterfaceVpcEndpoint(this, ""cloudwatch-vpc-endpoint"", new InterfaceVpcEndpointProps
            {
                Vpc = vpc,
                Service = InterfaceVpcEndpointAwsService.CLOUDWATCH,
                PrivateDnsEnabled = true
            });

            // 4.4. VPC endpoint 4
            var cwLogsVpcEndpoint = new InterfaceVpcEndpoint(this, ""cloudwatch-logs-vpc-endpoint"", new InterfaceVpcEndpointProps
            {
                Vpc = vpc,
                Service = InterfaceVpcEndpointAwsService.CLOUDWATCH_LOGS,
                PrivateDnsEnabled = true
            });

            // 4.5. VPC endpoint 5
            var s3VpcEndpoint = new GatewayVpcEndpoint(this, ""s3-vpc-endpoint"", new GatewayVpcEndpointProps
            {
                Vpc = vpc,
                Service = GatewayVpcEndpointAwsService.S3
            });

            // 5. ECS cluster
            var ecsCluster = new Cluster(this, ""ecs-cluster"", new ClusterProps
            {
                Vpc = vpc
            });

            // 6. ECS fargate service frontend by ALB
            var albFargateService = new ApplicationLoadBalancedFargateService(this, ""sample-api-service"", new ApplicationLoadBalancedFargateServiceProps
            {
                // ----: Networking (Task Subnets) :-----
                // By default, public subnets are used if assignPublicIp is set, otherwise the first available one of Private, Isolated, Public, in that order.

                Cluster = ecsCluster,
                DesiredCount = 1,
                Cpu = 1024,  // 1024 unit represents 1 vCPU (per task)
                MemoryLimitMiB = 2048,
                TaskImageOptions = new ApplicationLoadBalancedTaskImageOptions
                {
                    ContainerPort = 80, // container port, automatically assigned to host port via dynamic port mapping
                    Image = ContainerImage.FromAsset(""./src/SampleApplication.API"")
                },
                Certificate = certificate,
                DomainName = apiDomainName,
                DomainZone = hostedZone,
                AssignPublicIp = false
            });

            albFargateService.TargetGroup.ConfigureHealthCheck(new Amazon.CDK.AWS.ElasticLoadBalancingV2.HealthCheck
            {
                Path = ""/WeatherForecast""
            });
        }
    }
}

```",https://rattle-stock-d32.notion.site/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2Fe7472e42-7118-406f-8758-f9c76b1cf86a%2Fb83620ba-6062-4f5a-8a46-c9478a4a10fc%2FUntitled.png?table=block&id=95a8dc9d-d930-4adb-8c6d-05cf2bdb027b&spaceId=e7472e42-7118-406f-8758-f9c76b1cf86a&width=1330&userId=&cache=v2,Container,Developer,사용자 정의 도메인을 통한 컨테이너화된 Web API를 안전하고 확장 가능하게 배포합니다.," ECS Fargate, Application Load Balancer, Route53, CDK, containerization, load balancing, DNS, SSL"
20,AWS Lambda와 AppConfig를 이용한 실시간 피처 플래그 관리,"## 개요

AWS AppConfig와 Lambda Extension을 통합 사용하면, 애플리케이션 설정을 동적으로 관리하고, 피처 플래그의 상태를 실시간으로 검색할 수 있습니다. 이 접근 방식은 애플리케이션의 안정성을 높이면서도 기능의 배포와 테스트를 유연하게 할 수 있는 방법을 제공합니다.

## 서비스 소개

### **AWS AppConfig**

AWS AppConfig는 애플리케이션의 구성을 안전하고 간편하게 관리할 수 있게 해주는 서비스입니다. 이를 통해 개발자는 애플리케이션 설정을 중앙에서 관리하고, 변경 사항을 안전하게 배포할 수 있습니다.

### **AWS Lambda**

AWS Lambda는 서버를 구성할 필요 없이 코드를 실행할 수 있는 서비스로, 이벤트에 반응하여 자동으로 코드를 실행합니다. Lambda는 확장성이 뛰어나며 다양한 AWS 서비스와의 통합이 가능합니다.

### **Lambda Extension**

Lambda Extension은 AWS Lambda의 기능을 확장하여, 실행 중인 람다 함수에 대한 추가적인 로직을 수행할 수 있게 해주는 도구입니다. 이를 통해 람다 함수가 외부 서비스와의 통신이나 추가 데이터 처리 등을 보다 효과적으로 수행할 수 있습니다.

## 통합 사용 시나리오

1. **피처 플래그 관리**:
    - AWS CDK를 사용하여 AppConfig에 피처 플래그를 구현합니다. 이 피처 플래그는 애플리케이션의 특정 기능을 제어하는 데 사용됩니다.
    - AppConfig를 통해 피처 플래그의 배포 및 업데이트를 중앙에서 관리하며, 이는 애플리케이션의 기능 변경을 신속하고 안전하게 반영할 수 있게 해줍니다.
2. **실시간 상태 검색**:
    - Lambda Extension을 활용하여 람다 함수 실행 중 AppConfig에서 피처 플래그의 최신 상태를 실시간으로 검색합니다.
    - 이 구성은 람다 함수가 실행될 때마다 피처 플래그의 상태를 확인하고, 해당 정보에 따라 다른 행동을 취하도록 할 수 있습니다.

## 예제

### git

??

```java
git clone https://github.com/aws-samples/serverless-patterns/ 
cd serverless-patterns/appconfig-feature-flag-cdk
```

### 배포

```bash
cdk deploy --all --parameters appConfigExtensionArn='AppConfig Extension version ARN'
```

### 인프라 생성 코드

```bash
import { Stack, StackProps, aws_appconfig as appconfig, aws_lambda_nodejs as nodejs_lambda, aws_lambda as lambda, Duration, CfnParameter, aws_iam as iam } from 'aws-cdk-lib';
import { Construct } from 'constructs';
import * as path from 'path';

export class AppConfigFeatureFlagCdkStack extends Stack {
  constructor(scope: Construct, id: string, props?: StackProps) {
    super(scope, id, props);

    const appConfigExtensionArn = new CfnParameter(this, 'appConfigExtensionArn', { type: 'String' });

    // ##########################################################################
    // # APPCONFIG RESOURCES
    // ##########################################################################
    const myAppconfigApplication = new appconfig.CfnApplication(this, 'MyAppconfigApplication', {
      name: 'MyAppconfigApplication',
    });

    const myAppconfigConfigurationProfile = new appconfig.CfnConfigurationProfile(this, 'myAppconfigConfigurationProfile', {
      applicationId: myAppconfigApplication.ref,
      locationUri: 'hosted',
      name: 'DiscountCodeConfigurationProfile',
      type: 'AWS.AppConfig.FeatureFlags',
    });

    const myHostedConfigurationVersion = new appconfig.CfnHostedConfigurationVersion(this, 'MyHostedConfigurationVersion', {
      applicationId: myAppconfigApplication.ref,
      configurationProfileId: myAppconfigConfigurationProfile.ref,
      contentType: 'application/json',
      content: JSON.stringify({
        ""version"": ""1"",
        ""flags"": {
          myFeatureFlag: {
            ""name"": ""myFeatureFlag"",
          }
        },
        ""values"": {
          myFeatureFlag: {
            ""enabled"": true,
          }
        }
      }),
    });

    const myAppconfigEnv = new appconfig.CfnEnvironment(this, 'myAppconfigEnv', {
      applicationId: myAppconfigApplication.ref,
      name: 'dev',
    });

    const myDeploymentStrategy = new appconfig.CfnDeploymentStrategy(this, 'myDeploymentStrategy', {
      deploymentDurationInMinutes: 0,
      growthFactor: 100,
      name: 'myDeploymentStrategy',
      replicateTo: 'SSM_DOCUMENT',
      finalBakeTimeInMinutes: 0,
    });

    const deployment = new appconfig.CfnDeployment(this, 'InitialDeployment', {
      applicationId: myAppconfigApplication.ref,
      configurationProfileId: myAppconfigConfigurationProfile.ref,
      configurationVersion: myHostedConfigurationVersion.ref,
      environmentId: myAppconfigEnv.ref,
      deploymentStrategyId: myDeploymentStrategy.ref,
    });

    // ##########################################################################
    // # LAMBDA FUNCTION
    // ##########################################################################

    const APPCONFIG_EXTENSION_ARN = appConfigExtensionArn.valueAsString;

    const checkFeatureFlagStatusLambda = new nodejs_lambda.NodejsFunction(this, ""CheckFeatureFlagStatusLambda"", {
      runtime: lambda.Runtime.NODEJS_14_X,
      entry: path.join(__dirname, `/../lambda/index.ts`),
      handler: ""handler"",
      retryAttempts: 0,
      timeout: Duration.seconds(15),
      environment: {
        APPCONFIG_APPLICATION_ID: myAppconfigApplication.ref,
        APPCONFIG_ENVIRONMENT: myAppconfigEnv.name,
        APPCONFIG_CONFIGURATION_ID: myAppconfigConfigurationProfile.ref,
        FEATURE_FLAG_NAME: ""myFeatureFlag"",
      }
    });

    checkFeatureFlagStatusLambda.addLayers(
      lambda.LayerVersion.fromLayerVersionArn(this, 'AppConfigExtension', APPCONFIG_EXTENSION_ARN)
    );

    // Setting permissions for AppConfig
    checkFeatureFlagStatusLambda.role?.attachInlinePolicy(
      new iam.Policy(this, 'additionalPermissionsForAppConfig', {
        statements: [
          new iam.PolicyStatement({
            actions: ['appconfig:StartConfigurationSession', 'appconfig:GetLatestConfiguration'],
            resources: ['*'],
          }),
        ],
      }),
    )
  }
}

```",https://rattle-stock-d32.notion.site/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2Fe7472e42-7118-406f-8758-f9c76b1cf86a%2F44936df1-a062-4618-9482-1d3fbd87394a%2FUntitled.png?table=block&id=5ed25008-942b-4ad0-a544-6b4917ebe5bd&spaceId=e7472e42-7118-406f-8758-f9c76b1cf86a&width=1330&userId=&cache=v2,Architecting,Architect,AWS AppConfig와 Lambda Extension을 통합하여 애플리케이션의 피처 플래그 상태를 실시간으로 관리하고 검색합니다.,"AppConfig, Lambda, CDK, SSM, AppConfig Extension, Feature Flag, Lambda Extension, Serverless"
21,GraphQL API 보안 강화 : AWS에서 국가별 접근 제한을 설정하는 WAF 규칙 구현,"## 개요

AWS AppSync와 AWS WAF (Web Application Firewall)를 함께 사용하면, GraphQL API를 보호하고 지리적 위치 기반 제한과 일반적인 GraphQL 공격으로부터 API를 안전하게 보호할 수 있습니다. 이 통합은 고성능 API 보안을 제공하면서도 유연성을 유지합니다.

## 서비스 소개

### **AWS AppSync**

AWS AppSync는 개발자가 신속하게 GraphQL API를 생성하고 배포할 수 있도록 지원하는 완전 관리형 서비스입니다. AppSync는 데이터 동기화와 사용자와의 상호작용을 간소화하며, 실시간 데이터 업데이트 기능을 제공합니다.

### **AWS WAF**

AWS WAF는 사용자의 웹 애플리케이션을 공격으로부터 보호하는 웹 애플리케이션 방화벽입니다. 이 서비스를 통해 사용자는 SQL 인젝션, 크로스 사이트 스크립팅(XSS) 공격 등 다양한 웹 공격 유형을 차단할 수 있습니다. 또한, 특정 국가에서 오는 요청을 제한하는 등의 규칙을 설정할 수 있습니다.

## 통합 사용 시나리오

1. **GraphQL API 보호**:
    - AppSync를 사용하여 GraphQL API를 구성하고, 이 API는 DynamoDB를 데이터 소스로 사용하는 리졸버와 통합됩니다.
    - WAF는 AppSync GraphQL API 앞에 배치되어, 특정 국가에서의 접근을 제한하고, GraphQL API에 대한 일반적인 공격을 방어합니다.
2. **보안 규칙 구현**:
    - WAF Web ACL은 고도로 구성 가능한 보안 규칙을 제공하여, GraphQL API의 트래픽을 모니터링하고 필터링합니다. 이 규칙들은 특정 조건에 따라 트래픽을 차단하거나 허용하여 애플리케이션의 보안을 강화합니다.

## 예제

### git

???Visit the?GitHub repo for this pattern.

```java
git clone https://github.com/aws-samples/serverless-patterns/ 
cd serverless-patterns/waf-appsync-cdk
```

### 배포

```bash
cdk deploy --all
```

### 인프라 생성 코드

```bash
#!/usr/bin/env node
import ""source-map-support/register"";
import * as cdk from ""aws-cdk-lib"";
import { CdkStack } from ""./cdk-stack"";

const app = new cdk.App();
new CdkStack(app, ""Waf2AppSyncStack"", {});

```",https://rattle-stock-d32.notion.site/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2Fe7472e42-7118-406f-8758-f9c76b1cf86a%2F924b7e83-313a-4933-a9a9-c1bde1a43fde%2FUntitled.png?table=block&id=8c899546-d9b1-478f-b405-772673394a72&spaceId=e7472e42-7118-406f-8758-f9c76b1cf86a&width=1320&userId=&cache=v2,"Security, Identity & Compliance",Security Engineer,"AWS AppSync와 AWS WAF를 통합하여 GraphQL API를 보호하고, 특정 국가의 접근 제한 및 일반적인 GraphQL 공격으로부터 API를 안전하게 유지합니다.","AppSync, WAF, DynamoDB, CloudFormation, GraphQL, Web Application Firewall, GitHub, CDK"
22,복잡한 이벤트 처리를 위한 AWS OAuth 인증 설계,"## 개요

AWS EventBridge, AppSync GraphQL API, 그리고 OAuth 인증을 통합 사용하면 복잡한 이벤트 기반 아키텍처에서 안전하게 데이터를 관리하고 업데이트할 수 있습니다. 이 구성은 서버리스 이벤트 처리를 통해 실시간 데이터 동기화를 가능하게 하며, 다양한 인증 방식을 지원하여 보안을 강화합니다.

## 서비스 소개

### **AWS EventBridge**

AWS EventBridge는 서버리스 이벤트 버스 서비스로, 애플리케이션 간에 데이터를 쉽게 전달할 수 있도록 해줍니다. 이 서비스는 이벤트 기반의 아키텍처를 지원하여, 다양한 소스에서 발생하는 이벤트를 AWS 서비스나 사용자 정의 애플리케이션으로 라우팅할 수 있습니다.

### **AWS AppSync**

AWS AppSync는 GraphQL 서비스를 제공하는 완전 관리형 서비스로, 데이터 동기화와 사용자 상호작용을 간소화합니다. AppSync는 실시간 업데이트와 오프라인 데이터 액세스를 지원하여, 모바일과 웹 애플리케이션 개발을 용이하게 합니다.

### **OAuth 인증**

OAuth는 인터넷 사용자가 웹사이트나 애플리케이션에 패스워드를 제공하지 않고도 다른 사이트의 정보에 안전하게 접근할 수 있도록 허용하는 오픈 스탠다드 프로토콜입니다. 이 인증 방식은 사용자의 자격 증명을 안전하게 보호하면서 서비스 간 통합을 가능하게 합니다.

## 통합 사용 시나리오

1. **이벤트 기반 GraphQL 업데이트**:
    - EventBridge는 AppSync GraphQL API의 'updateTodo' 변형을 트리거하기 위해 EventBridge API 목적지를 사용합니다. 정의된 규칙에 맞는 이벤트가 수신될 때 이 변형이 실행됩니다.
    - OAuth 인증은 AppSync의 Lambda Authorizer를 통해 실행되어, 제공된 액세스 토큰을 검증합니다. 이는 API 요청의 보안을 강화합니다.
2. **보안 및 인증 관리**:
    - EventBridge API 목적지는 AWS Secrets Manager를 사용하여 클라이언트 비밀을 관리합니다. 비밀 관리의 비용은 API 목적지 사용료에 포함됩니다.
    - JWT 액세스 토큰은 EventBridge에 의해 캐시되며, 인증 엔드포인트가 401 또는 403 HTTP 응답을 반환할 때 토큰이 갱신됩니다. 이는 Lambda Authorizer에 의해 처리되며, 올바른 인증 에러 코드가 반환되어야 합니다.

## 예제

### git

??Visit the?[GitHub repo for this pattern](https://github.com/aws-samples/serverless-patterns/tree/main/cdk-eventbridge-appsync-oauth).

```java
git clone https://github.com/aws-samples/serverless-patterns/ 
cd serverless-patterns/cdk-eventbridge-appsync-oauth
```

### 배포

```bash
cdk deploy --parameters authDomainName=<your_domain_name>
```

### 인프라 생성 코드

```bash
import { Stack, StackProps, CfnParameter, CfnOutput } from 'aws-cdk-lib';
import { Construct } from 'constructs';
import { GraphqlApi, Schema, MappingTemplate, AuthorizationType } from '@aws-cdk/aws-appsync-alpha'
import { PythonFunction } from '@aws-cdk/aws-lambda-python-alpha'
import { Runtime } from 'aws-cdk-lib/aws-lambda'
import { aws_events as Events } from 'aws-cdk-lib'
import { aws_iam as IAM } from 'aws-cdk-lib'
import { join } from 'path'
import { Auth } from './auth'

const requestTemplate = `
#set( $createdAt = $util.time.nowISO8601() )
$util.qr($context.args.put(""createdAt"", $createdAt))
$util.qr($context.args.put(""updatedAt"", $createdAt))
{
  ""version"": ""2017-02-28"",
  ""payload"": $util.toJson($ctx.args)
}`

const responseTemplate = `$util.toJson($context.result)`

export class MainStack extends Stack {
  constructor(scope: Construct, id: string, props?: StackProps) {
    super(scope, id, props)

    const authDomainParameter = new CfnParameter(this, ""authDomainName"", {
      type: ""String"",
      description: ""Unique domain name for auth""
    })

    const auth = new Auth(this, ""Auth"", {
      authDomainPrefix: authDomainParameter.valueAsString
    });

    const authorizerFunction = new PythonFunction(this, ""AuthorizerFunction"", {
      entry: join(__dirname, ""authorizer""),
      index: ""app.py"",
      runtime: Runtime.PYTHON_3_8,
      environment: {
        USER_POOL_ID: auth.userPoolId,
        APP_CLIENT_ID: auth.destinationClientId
      }
    })

    const api = new GraphqlApi(this, 'Api', {
      name: 'TriggeredByEventBridge',
      schema: Schema.fromAsset(join(__dirname, 'schema.graphql')),
      authorizationConfig: {
        // for the time being, use API key for default
        defaultAuthorization: {
          authorizationType: AuthorizationType.API_KEY,
        },
        additionalAuthorizationModes: [
          {
            authorizationType: AuthorizationType.LAMBDA,
            lambdaAuthorizerConfig: {
              handler: authorizerFunction
            }
          }
        ]
      }
    }) 

    authorizerFunction.addPermission(""AppSyncInvokeLambdaPermission"", {
      principal: new IAM.ServicePrincipal(""appsync.amazonaws.com""),
      sourceArn: api.arn,
      sourceAccount: process.env.CDK_DEPLOYED_ACCOUNT || process.env.CDK_DEFAULT_ACCOUNT
    })

    const noneDS = api.addNoneDataSource('NONE')
    noneDS.createResolver({
      typeName: 'Mutation',
      fieldName: 'updateTodo',
      requestMappingTemplate: MappingTemplate.fromString(requestTemplate),
      responseMappingTemplate: MappingTemplate.fromString(responseTemplate),
    })

    const bus = new Events.CfnEventBus(this, 'bus', { name: 'todos' })

    const connection = new Events.CfnConnection(this, 'connection', {
      authorizationType: ""OAUTH_CLIENT_CREDENTIALS"",
      authParameters: {
        oAuthParameters: {
          authorizationEndpoint: `${auth.authEndpoint}/oauth2/token`,
          clientParameters: {
            clientId: auth.destinationClientId,
            clientSecret: auth.destinationClientSecret
          },
          httpMethod: ""POST"",
          oAuthHttpParameters: {
            bodyParameters: [
              {
                key: ""grant_type"",
                value: ""client_credentials""
              }
            ]
          }
        }
      }
    })

    const destination = new Events.CfnApiDestination(this, 'destination', {
      connectionArn: connection.attrArn,
      httpMethod: 'POST',
      invocationEndpoint: api.graphqlUrl,
    })

    const role = new IAM.Role(this, 'role', {
      assumedBy: new IAM.ServicePrincipal('events.amazonaws.com'),
      inlinePolicies: {
        invokeAPI: new IAM.PolicyDocument({
          statements: [
            new IAM.PolicyStatement({
              resources: [`arn:aws:events:${this.region}:${this.account}:api-destination/${destination.ref}/*`],
              actions: ['events:InvokeApiDestination'],
            }),
          ],
        }),
      },
    })

    const rule = new Events.CfnRule(this, 'rule', {
      name: 'default-todo-rule',
      eventBusName: bus.attrName,
      eventPattern: {
        source: ['todos.system'],
        'detail-type': ['todos update'],
      },
      targets: [
        {
          id: 'default-target-appsync',
          arn: destination.attrArn,
          roleArn: role.roleArn,
          inputTransformer: {
            inputPathsMap: {
              id: '$.detail.todo-id',
              name: '$.detail.name',
              description: '$.detail.description',
            },
            inputTemplate: `{
              ""query"": ""mutation UpdateTodo($id:ID!, $name:String, $description:String) {
                updateTodo(id:$id, name:$name, description:$description) { id name description createdAt updatedAt }
              }"",
              ""variables"": {
                ""id"": ""<id>"",
                ""name"": ""<name>"",
                ""description"": ""<description>""
              }
            }`.replace(/\n\s*/g, ' '),
          },
        },
      ],
    })
    rule.addDependsOn(bus)

    new CfnOutput(this, 'apiId', { value: api.apiId })
    new CfnOutput(this, 'apiName', { value: api.name })
    new CfnOutput(this, 'graphqlUrl', { value: api.graphqlUrl })
    new CfnOutput(this, 'apiKey', { value: api.apiKey! })
  }
}

```",https://rattle-stock-d32.notion.site/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2Fe7472e42-7118-406f-8758-f9c76b1cf86a%2F585e60bb-1383-4f1d-86af-e0fd81e11402%2FUntitled.png?table=block&id=38e234ee-ecdd-4545-8615-6765567ceb5a&spaceId=e7472e42-7118-406f-8758-f9c76b1cf86a&width=1330&userId=&cache=v2,"Security, Identity & Compliance",Security Engineer,"EventBridge, AppSync GraphQL API, 및 OAuth 인증을 통합하여 이벤트 기반 업데이트를 보안적으로 관리하고, AppSync API에 대한 접근을 효과적으로 제어합니다.","EventBridge, AppSync, OAuth, Lambda, GraphQL, Serverless, Real-time data synchronization, Authorization, Security"
23,AppSync와 DynamoDB를 이용한 데이터 동기화 전략,"## 개요

## 서비스 소개

### **AWS AppSync**

AWS AppSync는 데이터를 실시간으로 관리하고 업데이트하는 데 사용되는 GraphQL 서비스입니다. AppSync는 네트워크 상태와 관계없이 데이터를 애플리케이션 사용자에게 동기화할 수 있게 해줍니다.

### **Amazon DynamoDB**

Amazon DynamoDB는 완전 관리형 NoSQL 데이터베이스 서비스로, 빠르고 예측 가능한 성능을 제공합니다. DynamoDB는 대규모 분산 데이터베이스 시스템에서도 확장성을 유지하면서 데이터를 저장하고 검색할 수 있습니다.

### **AWS Lambda**

AWS Lambda는 서버를 관리할 필요 없이 코드를 실행할 수 있는 컴퓨팅 서비스입니다. 이벤트에 응답하여 코드를 자동으로 실행하며, AWS 서비스나 외부 애플리케이션과의 통합을 관리합니다.

## 통합 사용 시나리오

1. **DynamoDB 변경 감지 및 알림**:
    - DynamoDB 테이블에 새 항목이 생성될 때마다 Lambda 함수가 호출됩니다. 이 함수는 변화를 감지하고, AppSync의 특정 뮤테이션을 호출하여 이 변경 사항을 처리합니다.
    - 이 뮤테이션은 데이터 소스 없이 설정되며, AppSync 구독을 통해 연결된 클라이언트에게 새로 생성된 항목에 대해 실시간으로 알림을 제공합니다.
2. **실시간 데이터 피드 구현**:
    - 사용자는 AppSync 구독을 통해 DynamoDB 테이블의 변화를 실시간으로 받아볼 수 있습니다. 이는 데이터가 변경될 때마다 애플리케이션 사용자가 즉각적인 업데이트를 받을 수 있도록 해줍니다.

## 예제

### git

??Visit the?[GitHub repo for this pattern](https://github.com/aws-samples/serverless-patterns/tree/main/dynamodb-streams-appsync-subscription).

```java
git clone https://github.com/aws-samples/serverless-patterns/ 
cd serverless-patterns/dynamodb-streams-appsync-subscription
```

### 배포

```bash
sam deploy
```

### 인프라 생성 코드

```bash
AWSTemplateFormatVersion: '2010-09-09'
Transform: AWS::Serverless-2016-10-31
Description: Serverless patterns - Appsync DynamoDB Streams Subscription (uksb-1tthgi812) (tag:dynamodb-streams-appsync-subscription)

Resources:
##########################################################################
#   DynamoDB Table                                                       #
##########################################################################
  DDBTable:
    Type: ""AWS::DynamoDB::Table""
    Properties:
      BillingMode: PAY_PER_REQUEST
      AttributeDefinitions:
        - AttributeName: PK
          AttributeType: S
        - AttributeName: SK
          AttributeType: S
      KeySchema:
        - AttributeName: PK
          KeyType: HASH
        - AttributeName: SK
          KeyType: RANGE
      StreamSpecification:
        StreamViewType: NEW_IMAGE

##########################################################################
#   AppSync API                                                          #
##########################################################################
  AppSyncApi:
    Type: AWS::Serverless::GraphQLApi
    Properties:
      SchemaUri: ./sam_graphql_api/schema.graphql
      ApiKeys:
        TestApiKey:
          Description: Test Api Key
      Auth:
        Type: API_KEY
        Additional:
          - Type: AWS_IAM
      Functions:
        onCreateItemFunction:
          Runtime: 
            Name: APPSYNC_JS
            Version: 1.0.0
          DataSource: None
          CodeUri: ./sam_graphql_api/resolvers/functions/onCreateItem.js 
      Resolvers:
        Mutation:
          onCreateItem:
            Runtime:
              Name: APPSYNC_JS
              Version: ""1.0.0""
            Pipeline:
            - onCreateItemFunction

##########################################################################
#   Lambda Function                                                      #
##########################################################################
  DDBStreamFunction:
    Type: AWS::Serverless::Function
    Properties:
      CodeUri: src/DDBStreamFunction
      Handler: app.handler
      Runtime: nodejs18.x
      Architectures: [""arm64""]
      Timeout: 30
      MemorySize: 1024
      Policies:
        - Statement:
            - Effect: Allow
              Action: appsync:GraphQL
              Resource: !Sub ${AppSyncApi}/types/Mutation/*
      Events:
        DynamoStream:
          Type: DynamoDB
          Properties:
            BatchSize: 100
            ParallelizationFactor: 10
            StartingPosition: LATEST
            MaximumRetryAttempts: 2
            BisectBatchOnFunctionError: true
            MaximumRecordAgeInSeconds: 120
            FilterCriteria:
              Filters:
                - Pattern: '{""eventName"": [""INSERT""]}'
            Stream: !GetAtt DDBTable.StreamArn
      Environment:
        Variables:
          APP_SYNC_API: !GetAtt AppSyncApi.GraphQLUrl
    Metadata:
      BuildMethod: esbuild
      BuildProperties:
        External: 
          - '@aws-sdk/util-dynamodb'
          - '@aws-sdk/credential-provider-node'
          - '@aws-sdk/signature-v4'
          - '@aws-sdk/protocol-http'
        Minify: true
        Target: ""es2022""
        Sourcemap: true
        EntryPoints: 
          - app.ts
  DDBStreamFunctionLogGroup:
    Type: AWS::Logs::LogGroup
    Properties:
      RetentionInDays: 1
      LogGroupName: !Sub /aws/lambda/${DDBStreamFunction}
```",https://rattle-stock-d32.notion.site/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2Fe7472e42-7118-406f-8758-f9c76b1cf86a%2Fb239dc51-e58a-4384-ac8c-6d560b4a894a%2FUntitled.png?table=block&id=ae33efaa-24c1-45a9-aff0-c8082997ce08&spaceId=e7472e42-7118-406f-8758-f9c76b1cf86a&width=1320&userId=&cache=v2,Database,Developer,"AppSync와 DynamoDB를 통해 데이터베이스 변경 사항을 실시간으로 감지하고, 해당 변화를 사용자에게 신속하게 알리는 구독 기반의 데이터 통신 시스템을 구축합니다.","AppSync, DynamoDB, Lambda, GraphQL, NoSQL, Serverless computing, Real-time data synchronization, SAM"
24,"데이터 분석 자동화 : S3, Athena, Step Functions을 활용한 데이터 처리","## 개요

AWS Step Functions, Amazon Athena, 그리고 Amazon S3를 결합하여 서버리스 데이터 분석 파이프라인을 구축할 수 있습니다. 이러한 서비스들을 통합하여 사용하면, 대규모 데이터 세트에 대한 효율적이고 자동화된 쿼리 및 결과 처리 시스템을 만들 수 있습니다. 각 서비스의 역할과 이들을 통합하여 할 수 있는 일들을 아래와 같이 설명드릴게요.

## 서비스 소개

### **Amazon S3**

Amazon Simple Storage Service(S3)는 인터넷 스토리지 서비스로, 웹에서 어디서나 양방향으로 대량의 데이터를 저장하고 검색할 수 있습니다. S3는 높은 확장성, 데이터 가용성, 보안 및 성능을 제공합니다.

### **Amazon Athena**

Amazon Athena는 S3에 저장된 데이터를 SQL을 사용하여 서버리스로 질의할 수 있는 인터랙티브 쿼리 서비스입니다. Athena는 설정이 간단하며, 별도의 인프라를 관리할 필요가 없어 사용하기 쉽습니다.

### **AWS Glue**

AWS Glue는 ETL(Extract, Transform, Load) 서비스로, 데이터 준비와 로딩을 단순화합니다. 여기에서는 S3 데이터에 대한 메타데이터를 스캔하여 Athena가 쿼리할 수 있는 데이터베이스 테이블을 생성합니다.

### **AWS Step Functions**

AWS Step Functions는 서버리스 함수와 서비스를 조정하여 워크플로우를 자동화하는 서비스입니다. 복잡한 프로세스를 여러 단계로 나누어 관리하고 실행할 수 있습니다.

## 통합 사용 시나리오

1. **데이터 쿼리 및 처리 자동화**:
    - AWS Glue Crawler를 사용하여 S3에 저장된 데이터로부터 데이터베이스 테이블을 생성합니다.
    - 생성된 데이터베이스 테이블은 Athena를 통해 쿼리됩니다.
    - Step Functions는 Athena의 쿼리 결과를 처리하고, 필요에 따라 추가 쿼리를 실행하기 위해 NextToken을 사용하여 반복적으로 Athena를 호출합니다.
2. **결과의 후속 처리 및 자동화**:
    - Athena로부터의 쿼리 결과는 Step Functions에서 수집되며, 이 결과를 기반으로 데이터 변환, 요약, 또는 분석 작업을 수행할 수 있습니다.
    - 최종 결과는 비즈니스 인텔리전스 도구나 다른 시스템으로 전송될 수 있습니다.

## 예제

### git

???Visit the?[GitHub repo for this pattern](https://https//github.com/aws-samples/serverless-patterns/tree/main/step-functions-athena-glue-sam).

```java
git clone https://github.com/aws-samples/serverless-patterns/ 
cd serverless-patterns/step-functions-athena-glue-sam
```

### 배포

```bash
sam deploy --guided
```

### 인프라 생성 코드

```bash
Transform: AWS::Serverless-2016-10-31
AWSTemplateFormatVersion: ""2010-09-09""
Description: Sample SAM Template for Athena Querying (uksb-1tthgi812) (tag:step-functions-athena-glue-sam)

Parameters:
  AthenaBucket:
    Type: String
    Description: Enter your unique bucket name to store Athena query results

  CrawlerBucket:
    Type: String
    Description: Enter your unique bucket name to fetch table from

  Database:
    Type: String
    Description: Enter a Database name

Resources:

  SFRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: ""2012-10-17""
        Statement:
          -
            Effect: ""Allow""
            Principal:
              Service:
                - ""states.amazonaws.com""
            Action:
              - ""sts:AssumeRole""
      Policies:
        - PolicyName: AthenaAccess
          PolicyDocument:
            Version: ""2012-10-17""
            Statement:
              - Effect: Allow
                Action: 
                  - ""athena:startQueryExecution""
                  - ""athena:stopQueryExecution""
                  - ""athena:getQueryExecution""
                  - ""athena:getDataCatalog""
                  - ""athena:getQueryResults""
                Resource: 
                  - !Sub ""arn:aws:athena:${AWS::Region}:${AWS::AccountId}:workgroup/*""
                  - !Sub ""arn:aws:athena:${AWS::Region}:${AWS::AccountId}:datacatalog/*""
        
        - PolicyName: S3Access
          PolicyDocument:
            Version: ""2012-10-17""
            Statement:
              - Effect: Allow
                Action:
                  - ""s3:GetBucketLocation""
                  - ""s3:GetObject""
                  - ""s3:ListBucket""
                  - ""s3:ListBucketMultipartUploads""
                  - ""s3:ListMultipartUploadParts""
                  - ""s3:AbortMultipartUpload""
                  - ""s3:CreateBucket""
                  - ""s3:PutObject""
                Resource:
                  - !Sub ""arn:aws:s3:::${AthenaBucket}/*""
                  - !Sub ""arn:aws:s3:::${CrawlerS3Bucket}/*""
                  - !Sub ""arn:aws:s3:::${AthenaBucket}""
                  - !Sub ""arn:aws:s3:::${CrawlerS3Bucket}""

        - PolicyName: GlueAccess
          PolicyDocument:
            Version: ""2012-10-17""
            Statement:
              - Effect: Allow
                Action:
                  - ""glue:CreateDatabase""
                  - ""glue:GetDatabase""
                  - ""glue:GetDatabases""
                  - ""glue:UpdateDatabase""
                  - ""glue:DeleteDatabase""
                  - ""glue:CreateTable""
                  - ""glue:UpdateTable""
                  - ""glue:GetTable""
                  - ""glue:GetTables""
                  - ""glue:DeleteTable""
                  - ""glue:BatchDeleteTable""
                  - ""glue:BatchCreatePartition""
                  - ""glue:CreatePartition""
                  - ""glue:UpdatePartition""
                  - ""glue:GetPartition""
                  - ""glue:GetPartitions""
                  - ""glue:BatchGetPartition""
                  - ""glue:DeletePartition""
                  - ""glue:BatchDeletePartition""
                Resource:
                - !Sub ""arn:aws:glue:${AWS::Region}:${AWS::AccountId}:catalog""
                - !Sub ""arn:aws:glue:${AWS::Region}:${AWS::AccountId}:database/*""
                - !Sub ""arn:aws:glue:${AWS::Region}:${AWS::AccountId}:table/*""
                - !Sub ""arn:aws:glue:${AWS::Region}:${AWS::AccountId}:userDefinedFunction/*""           

  StateMachine:
    Type: AWS::Serverless::StateMachine
    Properties:
      Name: StateMachine
      DefinitionUri: athenaquery.asl.json
      DefinitionSubstitutions:
        AthenaBucketname: !Ref AthenaBucket
        CrawlerBucketname: !Ref CrawlerBucket
        DBname: !Ref MyDatabase
      Role: !GetAtt SFRole.Arn

  AthenaQueryS3Bucket:
    Type: 'AWS::S3::Bucket'
    Properties:
      BucketName: !Ref AthenaBucket
      AccessControl: ""BucketOwnerFullControl""

  MyRole:
    Type: 'AWS::IAM::Role'
    Properties:
      AssumeRolePolicyDocument:
        Version: ""2012-10-17""
        Statement:
          -
            Effect: ""Allow""
            Principal:
              Service:
                - ""glue.amazonaws.com""
            Action:
              - ""sts:AssumeRole""
      ManagedPolicyArns:
        ['arn:aws:iam::aws:policy/service-role/AWSGlueServiceRole']
      Policies:
        -
          PolicyName: ""S3BucketAccessPolicy""
          PolicyDocument:
            Version: ""2012-10-17""
            Statement:
              -
                Effect: ""Allow""
                Action: 
                  - ""s3:GetObject""
                  - ""s3:PutObject""
                Resource: 
                  !Join 
                    - ''
                    - - !GetAtt CrawlerS3Bucket.Arn
                      - ""*""
 
  MyDatabase:
    Type: 'AWS::Glue::Database'
    Properties:
      CatalogId: !Ref AWS::AccountId
      DatabaseInput:
        Name: !Ref Database
 
  CrawlerS3Bucket:
    Type: 'AWS::S3::Bucket'
    Properties:
      BucketName: !Ref CrawlerBucket
      AccessControl: ""BucketOwnerFullControl""
 
  MyCrawler:
    Type: 'AWS::Glue::Crawler'
    Properties:
      Name: ""testcrawler""
      Role: !GetAtt MyRole.Arn
      DatabaseName: !Ref MyDatabase
      Targets:
        S3Targets:
          - Path: 
              !Join
                - ''
                - - !Ref CrawlerS3Bucket
                  - ""/""

Outputs:
  ActivityStateMachineArn:
    Description: ""Activity State machine ARN""
    Value: !Ref StateMachine
  ActivityStateMachineRoleArn:
    Description: ""IAM Role created for Activity State machine based on the specified SAM Policy Templates""
    Value: !GetAtt SFRole.Arn
```",https://rattle-stock-d32.notion.site/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2Fe7472e42-7118-406f-8758-f9c76b1cf86a%2F932a2af1-6e77-4a5d-a1f1-16d9848f1f52%2FUntitled.png?table=block&id=72b65da5-9199-409c-b77b-38476469a9ca&spaceId=e7472e42-7118-406f-8758-f9c76b1cf86a&width=1280&userId=&cache=v2,Data Analytics,Data Engineer,"Amazon S3의 데이터를 AWS Glue, Athena, Step Functions를 통해 자동 쿼리 및 처리하여 효율적인 데이터 분석 파이프라인을 구축합니다."," S3, Athena, Glue, Step Functions, serverless, ETL, SQL, metadata"
25,데이터 쿼리와 병렬 처리를 위한 AWS 솔루션: Athena와 Step Functions의 통합,"## 개요

AWS Step Functions와 Amazon Athena를 결합하여 효율적인 데이터 쿼리 워크플로우를 구축할 수 있습니다. 이러한 서비스 통합은 대량의 데이터 분석 및 복잡한 워크플로우 관리를 가능하게 하며, 복잡한 데이터 처리 작업을 자동화하는 데 이상적입니다. 각 서비스의 역할과 이들을 통합하여 구현할 수 있는 시나리오를 아래에서 설명드릴게요.

## 서비스 소개

### **Amazon Athena**

Amazon Athena는 S3에 저장된 데이터를 서버리스, SQL 기반 쿼리 서비스를 통해 직접 분석할 수 있게 해주는 서비스입니다. 사용자는 인프라를 관리할 필요 없이, SQL 쿼리를 사용하여 데이터를 즉시 분석할 수 있습니다.

### **AWS Step Functions**

AWS Step Functions는 서비스와 애플리케이션의 서버리스 오케스트레이션을 가능하게 하는 관리형 서비스입니다. 복잡한 워크플로우를 시각적으로 디자인하고, 다양한 AWS 서비스 간의 상호 작용을 자동화하며, 상태 관리와 오류 처리를 효율적으로 수행할 수 있습니다.

### **통합 사용**

## 통합 사용 시나리오

1. **대규모 데이터 쿼리 및 결과 처리**:
    - AWS Glue를 사용하여 S3에 저장된 데이터로부터 메타데이터를 생성하고, Glue 데이터베이스 및 테이블을 구성합니다.
    - 사용자가 Step Functions 워크플로우를 통해 Athena 쿼리를 실행합니다. 이 워크플로우는 Athena의 **`GetQueryResults`** 메소드를 이용하여 최대 1000개의 결과를 가져옵니다.
    - 워크플로우는 결과가 더 있는 경우 루프를 사용하여 추가 결과를 반복적으로 요청하고, 이를 Map 상태를 통해 병렬 또는 순차적으로 처리합니다.
2. **결과 데이터의 후속 처리**:
    - 쿼리 결과를 받은 후, 결과 데이터에 대한 후속 처리를 수행할 수 있는 ‘DoSomething’ 상태를 구성하여, 이 데이터를 분석, 변환 또는 다른 시스템으로 전송합니다.

## 예제

### git

??

```java
git clone https://github.com/aws-samples/serverless-patterns/ 
cd serverless-patterns/sfn-athena-cdk-python
```

### 배포

```bash
sam deploy
```

### 인프라 생성 코드

```bash
from aws_cdk import (
    Aws,
    Stack,
    CfnOutput,
    Duration,
    aws_s3 as s3,
    aws_glue as glue,
    aws_stepfunctions as sf,
    aws_stepfunctions_tasks as tasks,
)
region = Aws.REGION
account = Aws.ACCOUNT_ID

from constructs import Construct

class SfnAthenaCdkPythonStack(Stack):

    def __init__(self, scope: Construct, construct_id: str, **kwargs) -> None:
        super().__init__(scope, construct_id, **kwargs)

        #the S3 bucket where CloudFront Access Logs will be stored
        cf_access_logs = s3.Bucket(self, ""LogBucket"")

        #S3 bucket where Athena will put the results
        athena_results = s3.Bucket(self, ""AthenaResultsBucket"")

        #create an Athena database
        glue_database_name = ""serverlessland_database""
        myDatabase = glue.CfnDatabase(
            self,
            id=glue_database_name,
            catalog_id=account,
            database_input=glue.CfnDatabase.DatabaseInputProperty(
                description=f""Glue database '{glue_database_name}'"",
                name=glue_database_name,
            )
        )

        #define a table with the structure of CloudFront Logs https://docs.aws.amazon.com/athena/latest/ug/cloudfront-logs.html
        athena_table = glue.CfnTable(self,
            id='cfaccesslogs',
            catalog_id=account,
            database_name=glue_database_name,
            table_input=glue.CfnTable.TableInputProperty(
                name='cf_access_logs',
                description='CloudFront access logs',
                table_type='EXTERNAL_TABLE',
                parameters = {
                    'skip.header.line.count': '2',
                },
                storage_descriptor=glue.CfnTable.StorageDescriptorProperty(
                    location=""s3://""+cf_access_logs.bucket_name+""/"",
                    input_format='org.apache.hadoop.mapred.TextInputFormat',
                    output_format='org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat',
                    compressed=False,
                    serde_info=glue.CfnTable.SerdeInfoProperty(
                        serialization_library='org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe',
                        parameters={
                            'field.delim' : '	'
                        }
                    ),
                    columns=[
                        glue.CfnTable.ColumnProperty(name='date', type='date'),
                        glue.CfnTable.ColumnProperty(name='time', type='string'),
                        glue.CfnTable.ColumnProperty(name='location', type='string'),
                        glue.CfnTable.ColumnProperty(name='bytes', type='bigint'),
                        glue.CfnTable.ColumnProperty(name='request_ip', type='string'),
                        glue.CfnTable.ColumnProperty(name='method', type='string'),
                        glue.CfnTable.ColumnProperty(name='host', type='string'),
                        glue.CfnTable.ColumnProperty(name='uri', type='string'),
                        glue.CfnTable.ColumnProperty(name='status', type='string'),
                        glue.CfnTable.ColumnProperty(name='referer', type='string'),
                        glue.CfnTable.ColumnProperty(name='user_agent', type='string'),
                        glue.CfnTable.ColumnProperty(name='query_string', type='string'),
                        glue.CfnTable.ColumnProperty(name='cookie', type='string'),
                        glue.CfnTable.ColumnProperty(name='result_type', type='string'),
                        glue.CfnTable.ColumnProperty(name='request_id', type='string'),
                        glue.CfnTable.ColumnProperty(name='host_header', type='string'),
                        glue.CfnTable.ColumnProperty(name='request_protocol', type='string'),
                        glue.CfnTable.ColumnProperty(name='request_bytes', type='bigint'),
                        glue.CfnTable.ColumnProperty(name='time_taken', type='float'),
                        glue.CfnTable.ColumnProperty(name='xforwarded_for', type='string'),
                        glue.CfnTable.ColumnProperty(name='ssl_protocol', type='string'),
                        glue.CfnTable.ColumnProperty(name='ssl_cipher', type='string'),
                        glue.CfnTable.ColumnProperty(name='response_result_type', type='string'),
                        glue.CfnTable.ColumnProperty(name='http_version', type='string'),
                        glue.CfnTable.ColumnProperty(name='fle_status', type='string'),
                        glue.CfnTable.ColumnProperty(name='fle_encrypted_fields', type='int'),
                        glue.CfnTable.ColumnProperty(name='c_port', type='int'),
                        glue.CfnTable.ColumnProperty(name='time_to_first_byte', type='float'),
                        glue.CfnTable.ColumnProperty(name='x_edge_detailed_result_type', type='string'),
                        glue.CfnTable.ColumnProperty(name='sc_content_type', type='string'),
                        glue.CfnTable.ColumnProperty(name='sc_content_len', type='string'),
                        glue.CfnTable.ColumnProperty(name='sc_range_start', type='bigint'),
                        glue.CfnTable.ColumnProperty(name='sc_range_end', type='bigint')
                    ]
                ),
            )
        )

        #submit the query and wait for the results
        start_query_execution_job = tasks.AthenaStartQueryExecution(self, ""Start Athena Query"",
            query_string=""SELECT uri FROM cf_access_logs limit 10"",
            integration_pattern=sf.IntegrationPattern.RUN_JOB, #executes the command in SYNC mode
            query_execution_context=tasks.QueryExecutionContext(
                database_name=glue_database_name
            ),
            result_configuration=tasks.ResultConfiguration(
                output_location=s3.Location(
                    bucket_name=athena_results.bucket_name,
                    object_key=""results""
                )
            )
        )

        #get the results
        get_query_results_job = tasks.AthenaGetQueryResults(self, ""Get Query Results"",
            query_execution_id=sf.JsonPath.string_at(""$.QueryExecution.QueryExecutionId""),
            result_path=sf.JsonPath.string_at(""$.GetQueryResults""),
        )

        #prepare the query to see if more results are available (up to 1000 can be retrieved)
        prepare_next_params = sf.Pass(self, ""Prepare Next Query Params"",
            parameters={
                ""QueryExecutionId.$"": ""$.StartQueryParams.QueryExecutionId"",
                ""NextToken.$"": ""$.GetQueryResults.NextToken""
            },
            result_path=sf.JsonPath.string_at(""$.StartQueryParams"")
        )

        #check to see if more results are available
        has_more_results = sf.Choice(self, ""Has More Results?"").when(
                    sf.Condition.is_present(""$.GetQueryResults.NextToken""),
                    prepare_next_params.next(get_query_results_job)
                ).otherwise(sf.Succeed(self, ""Done""))

        #do something with each result
        #here add your own logic
        map = sf.Map(self, ""Map State"",
            max_concurrency=1,
            input_path=sf.JsonPath.string_at(""$.GetQueryResults.ResultSet.Rows[1:]""),
            result_path = sf.JsonPath.DISCARD
        )
        map.iterator(sf.Pass(self, ""DoSomething""))

        # Step function to orchestrate Athena query and retrieving the results
        workflow = sf.StateMachine(self, ""AthenaQuery"",
            definition=start_query_execution_job.next(get_query_results_job).next(map).next(has_more_results),
            timeout=Duration.minutes(60)
        )

        CfnOutput(self, ""Logs"",
            value=cf_access_logs.bucket_name, export_name='LogsBucket')

        CfnOutput(self, ""SFName"",
            value=workflow.state_machine_name, export_name='SFName')

        CfnOutput(self, ""SFArn"",
            value = workflow.state_machine_arn,
            export_name = 'StepFunctionArn',
            description = 'Step Function arn')

```",https://rattle-stock-d32.notion.site/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2Fe7472e42-7118-406f-8758-f9c76b1cf86a%2F39bf6d25-25fe-4f82-a85a-48dd3f7e7229%2FUntitled.png?table=block&id=4cba55f7-40a4-4e6f-bd5d-504597463104&spaceId=e7472e42-7118-406f-8758-f9c76b1cf86a&width=1280&userId=&cache=v2,Data Analytics,Data Engineer,AWS Step Functions와 Amazon Athena를 사용하여 대규모 데이터 쿼리와 병렬 처리 워크플로우를 자동화하고 최적화합니다.," Athena, Step Functions, Glue, S3, serverless, SQL, data analysis, workflow management"
26,AWS Lambda와 Athena를 사용한 데이터 쿼리 자동화,"## 개요

AWS Lambda와 Amazon Athena를 결합하여 데이터 쿼리를 실행하는 강력한 서버리스 솔루션을 구축할 수 있습니다. 이 조합은 데이터 분석 및 보고서 작성에 효율적이며, 코드의 복잡성을 최소화하면서 높은 확장성과 관리 용이성을 제공합니다. 각 서비스의 역할과 이들을 통합하여 할 수 있는 일들을 아래와 같이 설명드릴게요.

## 서비스 소개

### **AWS Lambda**

AWS Lambda는 서버리스 컴퓨팅 서비스로, 서버를 관리하지 않고도 코드 실행이 가능합니다. 이벤트 기반으로 코드를 자동 실행하며, 다양한 AWS 서비스와 통합될 수 있습니다.

### **Amazon Athena**

Amazon Athena는 서버리스 쿼리 서비스로, Amazon S3에 저장된 데이터를 SQL을 사용하여 직접 쿼리할 수 있습니다. Athena는 빠른 시간 안에 대량의 데이터를 분석할 수 있는 능력을 제공하며, 별도의 인프라 관리가 필요 없습니다.

### **Boto3**

Boto3는 AWS 서비스와 상호작용하기 위한 AWS의 Python SDK입니다. 이를 통해 Python 어플리케이션에서 AWS의 리소스를 쉽게 생성, 관리 및 사용할 수 있습니다.

## 통합 사용 시나리오

### **통합 사용 시나리오**

1. **데이터 쿼리 및 결과 추출**:
    - Lambda 함수는 Boto3 라이브러리를 사용하여 Athena에 SQL 쿼리를 실행합니다.
    - 이 쿼리는 미리 채워진 Athena 데이터베이스 테이블을 대상으로 하며, 필요한 정보를 검색합니다.
    - Lambda 함수는 쿼리 결과를 수집하고, 이를 다양한 방식으로 처리하거나 저장할 수 있습니다.
2. **서버리스 데이터 처리 및 자동화**:
    - Lambda를 통해 자동화된 쿼리 실행을 구성함으로써, 주기적인 데이터 분석이나 실시간 데이터 처리가 가능합니다.
    - 결과 데이터는 다른 AWS 서비스, 예를 들어 Amazon S3, DynamoDB, 또는 RDS에 저장할 수 있습니다.

## 예제

### git

??Visit the?[GitHub repo for this pattern](https://github.com/aws-samples/serverless-patterns/tree/main/lambda-athena-sam).

```java
git clone https://github.com/aws-samples/serverless-patterns/ 
cd serverless-patterns/lambda-athena-sam
```

### 배포

```bash
sam deploy
```

### 인프라 생성 코드

```bash
AWSTemplateFormatVersion: '2010-09-09'
Transform: AWS::Serverless-2016-10-31
Description: A demonstration of how to start query execution and fetch the result from an Athena table using an AWS Lambda function. (uksb-1tthgi812) (tag:lambda-athena-sam)
Parameters:
  AthenaWorkGroupName:
    Type: String
    Default: primary
    Description: Enter the Workgroup name for your Athena table
  S3BucketName:
    Type: String
    Default: sabsden
    Description: Enter your S3 Bucket Name

Resources:
  # Define a Lambda function
  AthenaQueryFunction:
    Type: AWS::Serverless::Function
    Properties:
      CodeUri: function/
      Runtime: python3.9
      Timeout: 10
      Handler: athenaquerymaker.lambda_handler
      Policies:
      - AthenaQueryPolicy:
          WorkGroupName: !Ref AthenaWorkGroupName
      - S3CrudPolicy:
          BucketName: !Ref S3BucketName
      - Statement:
        - Sid: GlueGetTablePolicy
          Effect: Allow
          Action:
          - glue:GetTable
          Resource: [ !Sub 'arn:${AWS::Partition}:glue:${AWS::Region}:${AWS::AccountId}:catalog', 
            !Sub 'arn:${AWS::Partition}:glue:${AWS::Region}:${AWS::AccountId}:database/*', 
            !Sub 'arn:${AWS::Partition}:glue:${AWS::Region}:${AWS::AccountId}:table/*']
Outputs:
  AthenaQueryFunction:
    Description: AthenaQueryFunction ARN
    Value: !Ref AthenaQueryFunction
```",https://rattle-stock-d32.notion.site/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2Fe7472e42-7118-406f-8758-f9c76b1cf86a%2Ffa35f849-bc5d-4569-a369-6d49ffe0037e%2FUntitled.png?table=block&id=6298ac7c-dca3-45c8-8bcf-b6d547b3733d&spaceId=e7472e42-7118-406f-8758-f9c76b1cf86a&width=1280&userId=&cache=v2,Data Analytics,Data Engineer,AWS Lambda와 Amazon Athena를 통해 미리 채워진 데이터 테이블에서 SQL 쿼리를 자동으로 실행하고 결과를 처리합니다.,"Lambda, Athena, Boto3, S3, serverless computing, SQL, Python SDK, SDK"
27,Athena와 S3 Express One Zone을 이용한 고성능 데이터 분석 솔루션,"## 개요

Amazon S3 Express One Zone, AWS Glue Data Catalog, 그리고 Amazon Athena를 함께 사용하여 데이터 카탈로그 생성, 저장 및 질의를 실행하는 고성능 데이터 분석 솔루션을 구축할 수 있습니다. 이 서비스들의 조합은 비용 효율적이며, 데이터 접근성과 분석의 용이성을 향상시키는 강력한 데이터 처리 파이프라인을 제공합니다.

## 서비스 소개

### **Amazon S3 Express One Zone**

Amazon S3 Express One Zone은 Amazon S3의 저장 옵션 중 하나로, 비용 효율적인 단일 가용 영역 데이터 저장을 제공합니다. 이 서비스는 중요하지 않은 임시 데이터나 복제가 필요하지 않은 데이터에 적합합니다.

### **AWS Glue Data Catalog**

AWS Glue Data Catalog는 중앙 메타데이터 리포지토리 역할을 하며, AWS에서 데이터 관리를 간소화합니다. 데이터 세트를 카탈로그화하고, ETL 작업을 쉽게 설정하며, 데이터 검색 및 관리를 위한 메타데이터 저장소로 사용됩니다.

## 통합 사용 시나리오

1. **데이터 카탈로그 및 저장**:
    - 데이터를 Amazon S3 Express One Zone에 업로드합니다. 이는 비용 효율적인 저장 옵션을 제공하며, 일반적으로 접근 빈도가 낮은 데이터에 사용됩니다.
    - AWS Glue Data Catalog를 사용하여 S3 버킷의 데이터를 카탈로그화합니다. 이 과정은 데이터 구조를 정의하고, 후속 분석을 위해 데이터 소스를 준비합니다.
2. **데이터 질의 및 분석**:
    - 카탈로그화된 데이터는 Amazon Athena를 사용하여 질의됩니다. 사용자는 SQL 쿼리를 사용하여 데이터를 검색하고 분석할 수 있습니다.
    - Athena의 서버리스 쿼리 기능을 활용하여, 복잡한 데이터 분석 작업을 빠르고 간편하게 수행할 수 있습니다.

## 예제

### git

???Visit the?[GitHub repo for this pattern](https://github.com/aws-samples/serverless-patterns/tree/main/athena-glue-s3-sam).

```java
git clone https://github.com/aws-samples/serverless-patterns/ 
cd serverless-patterns/athena-glue-s3-sam
```

### 배포

```bash
sam deploy --guided
```

### 인프라 생성 코드

```bash
Transform: AWS::Serverless-2016-10-31
AWSTemplateFormatVersion: ""2010-09-09""
Description: Sample SAM Template for querying Amazon S3 Express One Zone directory bucket using Amazon Athena

# Get the required input parameters
Parameters:
  AvailabilityZoneId:
    Type: String
    Description: Please enter the availability Zone Id (e.g. use1-az6) for your region

Resources:

  # Create an Amazon S3 Express One Zone storage class input bucket
  MyInputBucketExpressOneZone:
    Type: AWS::S3Express::DirectoryBucket
    Properties:
      DataRedundancy: SingleAvailabilityZone
      LocationName: !Sub ""${AvailabilityZoneId}""

  # Create an Amazon S3 Express One Zone storage class output bucket
  MyOutputBucketExpressOneZone:
    Type: AWS::S3Express::DirectoryBucket
    Properties:
      DataRedundancy: SingleAvailabilityZone
      LocationName: !Sub ""${AvailabilityZoneId}""

  # Create an AWS Glue database and table for Amazon Athen to query the Amazon S3 Express One Zone storage class input bucket
  MyDatabase:
    Type: AWS::Glue::Database
    Properties:
      CatalogId: !Ref ""AWS::AccountId""
      DatabaseInput:
        Name: mydatabase
        Description: My database

  MyTable:
    Type: ""AWS::Glue::Table""
    Properties:
      CatalogId: !Ref ""AWS::AccountId""
      DatabaseName: mydatabase
      TableInput:
        Name: mytable
        TableType: EXTERNAL_TABLE
        StorageDescriptor:
          Location: !Sub ""s3://${MyInputBucketExpressOneZone}/""
          StoredAsSubDirectories: true
          InputFormat: org.apache.hadoop.mapred.TextInputFormat
          OutputFormat: IgnoreKeyTextOutputFormat
          SerdeInfo:
            SerializationLibrary: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
            Parameters:
              field.delim: "",""
              serialization.format: "",""
          Columns:
            - Name: id
              Type: int
            - Name: name
              Type: string
            - Name: age
              Type: int
            - Name: city
              Type: string

Outputs:
  MyInputBucketExpressOneZone:
    Description: ""MyInputBucketExpressOneZone Name""
    Value: !Ref MyInputBucketExpressOneZone
  MyOutputBucketExpressOneZone:
    Description: ""MyOutputBucketExpressOneZone Name""
    Value: !Ref MyOutputBucketExpressOneZone    

```",https://rattle-stock-d32.notion.site/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2Fe7472e42-7118-406f-8758-f9c76b1cf86a%2F261e22a8-1ab8-4fd9-af7a-6c73d99291e3%2FUntitled.png?table=block&id=c636c972-0f8e-49ea-ab15-71d0c7aac8ee&spaceId=e7472e42-7118-406f-8758-f9c76b1cf86a&width=1290&userId=&cache=v2,Data Analytics,Data Engineer,"Amazon S3 Express One Zone, AWS Glue, 및 Athena를 통해 데이터를 효율적으로 카탈로그하고, 저장하며, 분석합니다."," S3 Express One Zone, Glue Data Catalog, Athena, SAM, data catalog, data storage, data analysis, serverless computing"
28,AWS Secrets Manager를 이용한 데이터베이스 자격 증명 관리,"## 개요

AWS Aurora Serverless와 AWS Secrets Manager를 결합하면, 관리가 편리하고 비용 효율적인 데이터베이스 솔루션을 구축할 수 있습니다. 이 서비스들을 통합함으로써, 보안이 강화된 환경에서 데이터베이스 관리 및 접근이 용이해집니다. 각 서비스의 역할과 이들을 통합하여 할 수 있는 일들을 아래와 같이 설명드릴게요.

## 서비스 소개

### **Amazon Aurora Serverless**

Amazon Aurora Serverless는 MySQL과 PostgreSQL 호환 데이터베이스 엔진을 제공하는 서버리스 데이터베이스 옵션입니다. 이는 자동으로 확장되며, 데이터베이스가 사용되지 않을 때는 자동으로 종료되어 비용을 절감할 수 있습니다.

### **AWS Secrets Manager**

AWS Secrets Manager는 비밀번호, 키, API 키 등의 민감한 정보를 안전하게 저장하고 관리할 수 있는 서비스입니다. 이 서비스를 사용하면, 애플리케이션에서 필요할 때 안전하게 접근하여 사용할 수 있습니다.

### **AWS Cloud Development Kit (AWS CDK)**

AWS CDK는 클라우드 리소스를 소프트웨어로 정의하여 관리하는 인프라스트럭처 코드 도구입니다. 이를 통해 개발자는 익숙한 프로그래밍 언어를 사용하여 클라우드 애플리케이션을 정의하고 프로비저닝할 수 있습니다.

## 통합 사용 시나리오

1. **서버리스 데이터베이스 클러스터 구축 및 관리**:
    - AWS CDK를 사용하여 Aurora Serverless 데이터베이스 클러스터를 배포합니다. 이 과정에는 필요한 VPC 및 서브넷 설정이 포함됩니다.
    - 데이터베이스 접속 정보 및 자격 증명은 AWS Secrets Manager에 안전하게 저장됩니다.
2. **안전한 데이터베이스 접근 관리**:
    - 애플리케이션은 AWS Secrets Manager를 통해 데이터베이스 접근 정보를 안전하게 검색하여 사용할 수 있습니다.
    - 이 구조는 보안이 강화되며, 데이터베이스 자격 증명의 직접 관리 필요성을 제거합니다.

## 예제

### git

??

```java
git clone https://github.com/aws-samples/serverless-patterns/ 
cd serverless-patterns/auroraserverless-secretsmanager
```

### 배포

```bash
npm install
cdk deploy
```

### 인프라 생성 코드

```bash

import { Stack, StackProps, CfnOutput  } from 'aws-cdk-lib';
import { Construct } from 'constructs';
import { aws_secretsmanager as sm } from ""aws-cdk-lib"";
import { CfnDBCluster, CfnDBSubnetGroup } from 'aws-cdk-lib/aws-rds';
import { SubnetType, Vpc } from 'aws-cdk-lib/aws-ec2';

export class CdkStack extends Stack {
  constructor(scope: Construct, id: string, props?: StackProps) {
    super(scope, id, props);

    const service = 'demordsservice'
    const stage = 'demostage'
    const username = 'demousername'

    //VPC and Subnet Group
    const vpc = new Vpc(this, 'Vpc', {
      cidr: '10.0.0.0/16',
      natGateways: 0,
      subnetConfiguration: [   { name: 'aurora_isolated_', subnetType: SubnetType.ISOLATED } ] }); 

    const subnetIds: string[] = [];
    vpc.isolatedSubnets.forEach((subnet, index) => { subnetIds.push(subnet.subnetId); });
    const dbSubnetGroup: CfnDBSubnetGroup = new CfnDBSubnetGroup(this, 'AuroraSubnetGroup', {
     dbSubnetGroupDescription: 'Subnet group to access aurora',
     dbSubnetGroupName: 'aurora-serverless-subnet-group',
     subnetIds
  });
    //Secret Manager
    const secret = new sm.Secret(this, ""RelationalDBStackSecret"", {
      secretName: `${service}-${stage}-credentials`,
      generateSecretString: {
        secretStringTemplate: JSON.stringify({ username, }),
        excludePunctuation: true,
        includeSpace: false,
        generateStringKey: ""password"",
      },
    });

    //Serverless cluster
    const aurora = new CfnDBCluster(this, 'AuroraServerless', {
      databaseName: 'dbname',
      dbClusterIdentifier: 'aurora-serverless',
      engine: 'aurora',
      engineMode: 'serverless',
      enableHttpEndpoint: true,
      masterUserPassword: secret.secretValueFromJson(""password"").toString(),
      masterUsername: secret.secretValueFromJson(""username"").toString(),
      port: 3306,
      dbSubnetGroupName: dbSubnetGroup.dbSubnetGroupName,
      scalingConfiguration: {
        autoPause: true,
        maxCapacity: 2,
        minCapacity: 2,
        secondsUntilAutoPause: 3600
      }
    });
    aurora.addDependsOn(dbSubnetGroup);

    // Outputs
    new CfnOutput(this, 'VpcSubnetIds', {
      value: JSON.stringify(subnetIds)
    });
    
    new CfnOutput(this, 'VpcDefaultSecurityGroup', {
      value: vpc.vpcDefaultSecurityGroup
    });
  }
}
```",https://rattle-stock-d32.notion.site/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2Fe7472e42-7118-406f-8758-f9c76b1cf86a%2Ff28cb918-7338-4db6-b2a5-2f2c905b0781%2FUntitled.png?table=block&id=80ac1b18-dcf9-4cc5-a102-130b722c5bf7&spaceId=e7472e42-7118-406f-8758-f9c76b1cf86a&width=1290&userId=&cache=v2,"Security, Identity & Compliance",Security Engineer,AWS Aurora Serverless와 Secrets Manager를 사용하여 비용 효율적이고 보안이 강화된 데이터베이스 클러스터를 구축합니다.," Aurora Serverless, Secrets Manager, Cloud Development Kit, VPC, Subnet, Serverless Database, Infrastructure as Code, Security, Scalability"
29,서버리스 데이터베이스 관리: AWS Lambda와 Amazon Aurora Serverless의 통합,"## 개요

AWS Lambda와 Amazon Aurora Serverless를 결합하여, 서버리스 데이터베이스 환경에서 데이터 처리를 자동화하고 관리하는 솔루션을 구축할 수 있습니다. 이 조합은 높은 확장성과 저렴한 비용으로 데이터베이스 관리를 자동화하는 데 이상적입니다. 각 서비스의 역할과 이들을 통합하여 할 수 있는 일들을 아래와 같이 설명드릴게요.

## 서비스 소개

### **AWS Lambda**

AWS Lambda는 서버를 구성할 필요 없이 코드를 실행할 수 있는 서버리스 컴퓨팅 서비스입니다. 이벤트에 반응하여 자동으로 코드를 실행하고, 사용한 컴퓨팅 시간에 따라 요금을 지불합니다.

### **Amazon Aurora Serverless**

Amazon Aurora Serverless는 자동 스케일링이 가능한 관리형 데이터베이스 서비스로, 사용량에 따라 데이터베이스 용량을 자동으로 조정합니다. 이는 사용량이 변동적인 애플리케이션에 이상적인 솔루션을 제공합니다.

### **AWS Secrets Manager**

AWS Secrets Manager는 애플리케이션의 비밀번호, API 키 등 민감한 데이터를 안전하게 저장하고 관리하는 서비스입니다. 이를 통해 애플리케이션은 필요한 비밀 정보에 안전하게 접근할 수 있습니다.

## 통합 사용 시나리오

1. **데이터베이스와의 통합 및 관리**:
    - AWS Lambda 함수는 Secrets Manager에서 데이터베이스 접속 정보를 안전하게 검색합니다.
    - Lambda 함수는 Amazon Aurora Serverless DB 클러스터에 접속하여 SQL 쿼리를 실행합니다. 이 과정에서 예제 'music' 테이블을 생성하고, 이벤트 객체에서 받은 데이터를 삽입합니다.
2. **데이터 검색 및 반환**:
    - Lambda 함수는 삽입된 데이터에 대한 쿼리를 실행한 후 결과를 반환합니다.
    - 이 구성은 데이터베이스 작업을 자동화하고, 애플리케이션 로직을 간소화하는데 도움을 줍니다.

## 예제

### git

??Visit the?[GitHub repo for this pattern](https://github.com/aws-samples/serverless-patterns/tree/main/lambda-aurora-serverless).

```java
git clone https://github.com/aws-samples/serverless-patterns/ 
cd serverless-patterns/lambda-aurora-serverless
```

### 배포

```bash
sam deploy --guided
```

### 인프라 생성 코드

```bash
AWSTemplateFormatVersion: 2010-09-09
Transform: 'AWS::Serverless-2016-10-31'
Description: An AWS Lambda function and an Amazon Aurora Serverless DB cluster with Data API and a Secrets Manager secret (uksb-1tthgi812) (tag:lambda-aurora-serverless)

# Global values that are applied to all applicable resources in this template
Globals:
  Function:
    CodeUri: ./src
    Runtime: nodejs14.x
    MemorySize: 128
    Timeout: 30

Parameters:
  DBClusterName:
    Description: Aurora DB cluster name.
    Type: String
    Default: aurora-test-cluster
  DatabaseName:
    Description: Aurora database name.
    Type: String
    Default: aurora_test_db
    AllowedPattern: '[a-zA-Z][a-zA-Z0-9_]*'
    ConstraintDescription: Must begin with a letter and only contain alphanumeric characters.
  DBAdminUserName:
    Description: The admin user name.
    Type: String
    Default: admin_user
    MinLength: '2'
    MaxLength: '16'
    AllowedPattern: '[a-zA-Z0-9_]+'
    ConstraintDescription: Must be between 2 to 16 alphanumeric characters.

Resources:
  # Secrets Manager secret
  DBSecret:
    Type: 'AWS::SecretsManager::Secret'
    Properties:
      Name: !Sub '${DBClusterName}-AuroraUserSecret'
      Description: RDS database auto-generated user password
      GenerateSecretString:
        SecretStringTemplate: !Sub '{""username"": ""${DBAdminUserName}""}'
        GenerateStringKey: password
        PasswordLength: 30
        ExcludeCharacters: '""@/\'
  # Aurora Serverless DB Cluster with Data API
  AuroraCluster:
    Type: 'AWS::RDS::DBCluster'
    Properties:
      DBClusterIdentifier: !Ref DBClusterName
      MasterUsername: !Sub '{{resolve:secretsmanager:${DBSecret}:SecretString:username}}'
      MasterUserPassword: !Sub '{{resolve:secretsmanager:${DBSecret}:SecretString:password}}'
      DatabaseName: !Ref DatabaseName
      Engine: aurora-mysql
      EngineMode: serverless
      StorageEncrypted: true
      # Enable the Data API for Aurora Serverless
      EnableHttpEndpoint: true
      ScalingConfiguration:
        AutoPause: true
        MinCapacity: 1
        MaxCapacity: 2
        SecondsUntilAutoPause: 3600
  # Lambda Function - uses Globals to define additional configuration values
  LambdaFunction:
    Type: 'AWS::Serverless::Function'
    Properties:
      FunctionName: !Sub '${DBClusterName}-function'
      Handler: app.handler
      # Function environment variables
      Environment:
        Variables:
          DBClusterArn: !Sub 'arn:aws:rds:${AWS::Region}:${AWS::AccountId}:cluster:${DBClusterName}'
          DBName: !Ref DatabaseName
          SecretArn: !Ref DBSecret
      # Creates an IAM Role that defines the services the function can access and which actions the function can perform
      Policies:
        - AWSSecretsManagerGetSecretValuePolicy:
            SecretArn: !Ref DBSecret
        - Statement:
          - Effect: Allow
            Action: 'rds-data:ExecuteStatement'
            Resource: !Sub 'arn:aws:rds:${AWS::Region}:${AWS::AccountId}:cluster:${DBClusterName}'

Outputs:
  DBClusterArn:
    Description: Aurora DB Cluster Resource ARN
    Value: !Sub 'arn:aws:rds:${AWS::Region}:${AWS::AccountId}:cluster:${DBClusterName}'
  DBClusterEndpoint:
    Description: Aurora DB Cluster Endpoint Address
    Value: !GetAtt AuroraCluster.Endpoint.Address
  DBName:
    Description: Aurora Database Name
    Value: !Ref DatabaseName
  DBAdminUserName:
    Description: Aurora Database Admin User
    Value: !Ref DBAdminUserName
  SecretArn:
    Description: Secrets Manager Secret ARN
    Value: !Ref DBSecret

```",https://rattle-stock-d32.notion.site/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2Fe7472e42-7118-406f-8758-f9c76b1cf86a%2F1723d7f4-0f1d-4b8a-afab-3c60298e34b1%2FUntitled.png?table=block&id=ff8284bf-594c-4f68-8c55-8a21487b5dd7&spaceId=e7472e42-7118-406f-8758-f9c76b1cf86a&width=1290&userId=&cache=v2,Serverless,Developer,AWS Lambda와 Amazon Aurora Serverless를 사용하여 서버리스 환경에서 데이터베이스 작업을 자동화하고 안전하게 관리합니다.,"Lambda, Aurora Serverless, Secrets Manager, RDS Data API, serverless computing, database management, infrastructure as code, automatic scaling"
30,AWS에서 컨테이너와 서버리스 데이터베이스 관리하기,"## 개요

AWS Fargate와 Amazon Aurora Serverless를 통합 사용하면, 컨테이너화된 애플리케이션을 서버리스 데이터베이스와 능률적으로 연동하여 관리할 수 있습니다. 이 조합은 스케일링, 관리, 운영의 복잡성을 줄이면서 데이터베이스 작업을 효율적으로 처리할 수 있게 해줍니다. 각 서비스의 역할과 이들을 통합하여 할 수 있는 일들을 아래와 같이 설명드릴게요.

## 서비스 소개

### **AWS Fargate**

AWS Fargate는 서버를 관리할 필요 없이 컨테이너를 실행할 수 있게 하는 컴퓨팅 엔진입니다. Fargate를 사용하면, Amazon ECS와 함께 작동하여 애플리케이션 컨테이너의 배포와 스케일링을 자동화합니다.

### **Amazon Aurora Serverless**

Amazon Aurora Serverless는 사용량에 따라 자동으로 용량 조절이 가능한 서버리스 데이터베이스 옵션을 제공하는 관리형 데이터베이스 서비스입니다. 이는 데이터베이스 운영을 간소화하며, 변동적인 워크로드에 적합합니다.

### **AWS Cloud Development Kit (AWS CDK)**

AWS CDK는 개발자가 클라우드 리소스를 소프트웨어로 정의하고 관리할 수 있게 해주는 개발 프레임워크입니다. 이를 통해 인프라를 코드로 관리하며, 복잡한 클라우드 애플리케이션을 더 쉽고 빠르게 배포할 수 있습니다.

## 통합 사용 시나리오

1. **AWS Fargate를 이용한 데이터베이스 관리**:
    - AWS CDK를 사용하여 AWS Fargate 서비스를 Amazon ECS 클러스터 위에 배포합니다. 이 서비스는 Application Load Balancer를 통해 접근이 관리됩니다.
    - 컨테이너는 데이터베이스 이름, 비밀 정보의 ARN, Aurora Serverless 클러스터의 ARN과 같은 환경 변수를 사용하여 데이터베이스와 상호 작용합니다.
2. **데이터베이스 작업 자동화**:
    - Fargate 서비스는 Aurora Serverless 데이터베이스에서 테이블을 생성하고 표시하는 커맨드를 실행합니다.
    - 이는 '/createtable' 라우트를 통해 테이블을 추가하고, '/showtables' 라우트를 통해 데이터베이스 내의 테이블 목록을 표시합니다.

## 예제

### git

??Visit the?[GitHub repo for this pattern](https://github.com/aws-samples/serverless-patterns/tree/main/fargate-aurora-serverless-cdk).

```java
git clone https://github.com/aws-samples/serverless-patterns/ 
cd serverless-patterns/fargate-aurora-serverless-cdk
```

### 배포

```bash
npm install
cdk deploy
```

### 인프라 생성 코드

```bash
import { Duration, Stack, StackProps} from 'aws-cdk-lib';
import { Construct } from 'constructs';
import { AuroraCapacityUnit, Credentials, DatabaseClusterEngine, ServerlessCluster } from 'aws-cdk-lib/aws-rds';
import { Vpc } from 'aws-cdk-lib/aws-ec2';
import { Secret } from 'aws-cdk-lib/aws-secretsmanager';
import { Cluster, ContainerImage } from 'aws-cdk-lib/aws-ecs';
import { ApplicationLoadBalancedFargateService } from 'aws-cdk-lib/aws-ecs-patterns';
import path = require('path');

export class CdkStack extends Stack {
  constructor(scope: Construct, id: string, props?: StackProps) {
    super(scope, id, props);

    const DATABASE_NAME = 'aurora_db';

    const vpc = new Vpc(this, 'Vpc', {
      maxAzs: 3
    });

    const databaseCredentialsSecret = new Secret(this, 'DBCredentialsSecret', {
      secretName: 'aurora-user-secret',
      description: 'RDS database auto-generated user password',
      generateSecretString: {
        secretStringTemplate: JSON.stringify({ username: 'admin' }),
        generateStringKey: 'password',
        passwordLength: 30,
        excludeCharacters: ""\""@/\\"",
      }
    });

    const auroraServerlessCluster = new ServerlessCluster(this, 'AuroraServerlessCluster', {
      defaultDatabaseName: DATABASE_NAME,
      enableDataApi: true,
      engine: DatabaseClusterEngine.AURORA,
      credentials: Credentials.fromSecret(databaseCredentialsSecret),
      vpc,
      scaling: {
        autoPause: Duration.minutes(10),
        minCapacity: AuroraCapacityUnit.ACU_1,
        maxCapacity: AuroraCapacityUnit.ACU_2,
      }
    });

    const cluster = new Cluster(this, 'Cluster', {
      vpc: vpc,
    });

    const fargate = new ApplicationLoadBalancedFargateService(this, 'FargateService', {
      cluster: cluster,
      cpu: 512,
      desiredCount: 1,
      taskImageOptions: {
        image: ContainerImage.fromAsset(path.join(__dirname, '../src/')),
        environment: {
          secretArn: databaseCredentialsSecret.secretArn,
          dbClusterArn: auroraServerlessCluster.clusterArn,
          dbName: DATABASE_NAME,
        },
      },
      assignPublicIp: false,
      memoryLimitMiB: 2048,
    });

    // Grant the given identity to access to the Data API, including
    // read access to the secret attached to the cluster if present.
    auroraServerlessCluster.grantDataApiAccess(fargate.taskDefinition.taskRole);
  }
}

```",https://rattle-stock-d32.notion.site/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2Fe7472e42-7118-406f-8758-f9c76b1cf86a%2F0280fb45-14e3-4a03-86d2-54d5e29d1d33%2FUntitled.png?table=block&id=8d351dd3-1a4e-4e81-861a-5a0d3187c697&spaceId=e7472e42-7118-406f-8758-f9c76b1cf86a&width=1280&userId=&cache=v2,Containers,Developer ,AWS Fargate와 Amazon Aurora Serverless를 사용하여 서버리스 데이터베이스 작업을 컨테이너화된 애플리케이션과 통합하고 자동화합니다.," ECS, RDS, CDK, VPC, containerization, serverless, database management, infrastructure as code"
31,Aurora 고가용성 솔루션,"## 개요

Amazon Aurora Serverless Global Database를 사용하여, 여러 지역에 걸쳐 데이터 복제와 고가용성을 제공하는 아키텍처를 구축할 수 있습니다. 이 설정은 데이터 접근성을 극대화하고, 지역적 장애에 대비할 수 있게 해줍니다. 각 서비스의 역할과 이들을 통합하여 할 수 있는 일들을 아래와 같이 설명드릴게요.

## 서비스 소개

### **AWS Fargate**

AWS Fargate는 서버를 관리할 필요 없이 컨테이너를 실행할 수 있게 하는 컴퓨팅 엔진입니다. Fargate를 사용하면, Amazon ECS와 함께 작동하여 애플리케이션 컨테이너의 배포와 스케일링을 자동화합니다.

### **Amazon Aurora Serverless Global Database**

Amazon Aurora Serverless는 확장 가능한 서버리스 데이터베이스 솔루션을 제공합니다. Global Database 구성은 데이터를 주요 지역에서 보조 지역으로 자동 복제하여, 지역간 지연 시간을 최소화하고 읽기 성능을 최적화합니다.

### **AWS Cloud Development Kit (AWS CDK)**

AWS CDK는 클라우드 자원을 소프트웨어로 정의하여 프로그래밍 방식으로 관리할 수 있게 해주는 개발 도구입니다. 이를 사용하여 멀티-리전 아키텍처를 구현할 수 있으며, 각 지역에 필요한 리소스를 효과적으로 배포할 수 있습니다.

## 통합 사용 시나리오

1. **글로벌 데이터 복제 및 고가용성**:
    - AWS CDK를 사용하여 주요 지역과 보조 지역에 Aurora Serverless v2 글로벌 데이터베이스를 배포합니다.
    - 주요 지역의 클러스터는 쓰기 및 읽기 작업을 지원하며, 보조 지역의 클러스터는 읽기 전용입니다.
    - 데이터는 주요 지역에서 보조 지역으로 자동으로 복제되며, 이는 데이터 일관성과 접근성을 향상시킵니다.
2. **재해 복구 및 지역 승격**:
    - 지역 장애 또는 저하 발생 시, 보조 지역의 데이터베이스 인스턴스를 1분 이내에 쓰기 및 읽기가 가능하도록 승격시킬 수 있습니다. 이는 비즈니스 연속성을 보장하고, 데이터 손실 위험을 최소화합니다.

## 예제

### git

??Visit the?[GitHub repo for this pattern](https://github.com/aws-samples/serverless-patterns/tree/main/aurora-serverless-global-db-cdk).

```java
git clone https://github.com/aws-samples/serverless-patterns/ 
cd serverless-patterns/aurora-serverless-global-db-cdk
```

### 배포

```bash
cdk deploy --all
```

### 인프라 생성 코드

```bash
import { App } from 'aws-cdk-lib';
import { AuroraGlobalClusterStack } from '../lib/aurora-global-cluster-stack';
import { AuroraRegionalClusterStack } from '../lib/aurora-regional-cluster-stack';
import { FargateTestAppStack } from '../lib/fargate-test-app-stack';

const app = new App();

const account = app.node.tryGetContext('account') || process.env.CDK_INTEG_ACCOUNT || process.env.CDK_DEFAULT_ACCOUNT;
const primaryRegion = { account: account, region: 'eu-west-1' };
const secondaryRegion = { account: account, region: 'eu-west-2' };

const globalCluster = new AuroraGlobalClusterStack(app, ""aurora-global-cluster"", {
    env: primaryRegion
});

const primaryclusterstack = new AuroraRegionalClusterStack(app, `primary-cluster`, {
    env: primaryRegion, cfnGlobalCluster: globalCluster.cfnGlobalCluster, isPrimary: true
});

const secondaryclusterstack = new AuroraRegionalClusterStack(app, `secondary-cluster`, {
    env: secondaryRegion, cfnGlobalCluster: globalCluster.cfnGlobalCluster, isPrimary: false
});

primaryclusterstack.addDependency(globalCluster);
secondaryclusterstack.addDependency(primaryclusterstack)

const primarytestappstack = new FargateTestAppStack(app, `primary-test-app`, {
    env: primaryRegion,
    endpoint: primaryclusterstack.endpoint,
    port: primaryclusterstack.port,
    vpc: primaryclusterstack.vpc,
    isPrimary: true,
    region: primaryclusterstack.region,
    dbSecurityGroupId: primaryclusterstack.dbSecurityGroupId
});

const secondarytestappstack = new FargateTestAppStack(app, `secondary-test-app`, {
    env: secondaryRegion,
    endpoint: secondaryclusterstack.endpoint,
    port: secondaryclusterstack.port,
    vpc: secondaryclusterstack.vpc,
    isPrimary: false,
    region: primaryclusterstack.region,
    dbSecurityGroupId: secondaryclusterstack.dbSecurityGroupId
});

primarytestappstack.addDependency(primaryclusterstack);
secondarytestappstack.addDependency(secondaryclusterstack);

app.synth();
```",https://rattle-stock-d32.notion.site/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2Fe7472e42-7118-406f-8758-f9c76b1cf86a%2Fa7b61368-839d-4dc7-9439-1d38c42e984c%2FUntitled.png?table=block&id=a76ede92-7878-46c7-8551-3f789f6ddf36&spaceId=e7472e42-7118-406f-8758-f9c76b1cf86a&width=1290&userId=&cache=v2,Database,Infrastructure Engineer,"Amazon Aurora Serverless Global Database를 사용하여 여러 지역에 걸쳐 데이터를 복제하고, 장애 발생 시 신속하게 대응할 수 있는 고가용성 데이터베이스 솔루션을 구축합니다."," Aurora Serverless, Fargate, CDK, Global Database, containerization, serverless computing, infrastructure as code, disaster recovery"
32,빠른 API 응답을 위한 Micronaut와 Lambda SnapStart의 결합,"## 개요

AWS Lambda SnapStart와 관계형 데이터베이스를 함께 사용하여 빠른 시작 시간과 효율적인 데이터베이스 연동을 제공하는 아키텍처를 구축할 수 있습니다. 이 통합은 애플리케이션의 반응 속도를 향상시키고, 관리 오버헤드를 줄여줍니다. 각 서비스의 역할과 이들을 통합하여 할 수 있는 일들을 아래와 같이 설명드릴게요.

## 서비스 소개

### **AWS Lambda SnapStart**

AWS Lambda SnapStart는 Lambda 함수의 초기 시작 시간을 크게 줄여주는 기능입니다. 이를 통해 함수의 실행과 반응 속도가 향상되며, 고성능을 요구하는 애플리케이션에 적합합니다.

### **AWS Cloud Development Kit (AWS CDK)**

AWS CDK는 클라우드 자원을 소프트웨어로 정의하여 프로그래밍 방식으로 관리할 수 있게 해주는 개발 도구입니다. 복잡한 인프라를 코드로 간단히 구현할 수 있게 해줍니다.

### **Micronaut Framework**

Micronaut은 높은 성능을 제공하는 모던 JVM 기반의 프레임워크로, 마이크로서비스 개발에 적합합니다. 이는 시작 시간과 메모리 사용량을 최소화하여 빠른 애플리케이션 반응 속도를 제공합니다.

## 통합 사용 시나리오

1. **인프라스트럭처 및 데이터베이스 설정**:
    - AWS CDK를 사용하여 필요한 모든 인프라를 구성합니다. 여기에는 VPC, 서브넷, 보안 그룹, 비밀 정보 등이 포함됩니다.
    - 데이터베이스 설정을 위한 Lambda 함수가 실행되어 주어진 구조로 데이터베이스 테이블을 생성합니다.
2. **API 구현 및 데이터베이스 연동**:
    - Micronaut 프레임워크를 사용하여 REST API를 구현합니다. 이 API는 환경 변수를 통해 데이터베이스 자격 증명을 받아 연동합니다.
    - Lambda SnapStart를 활용하여 API의 반응 속도와 성능을 극대화합니다.

## 예제

### git

??Visit the?[GitHub repo for this pattern](https://github.com/aws-samples/serverless-patterns/tree/main/apigw-lambda-rds-snapstart).

```java
git clone https://github.com/aws-samples/serverless-patterns/ 
cd serverless-patterns/apigw-lambda-rds-snapstart
```

### 배포

```bash
cdk deploy --all
```

### 인프라 생성 코드

```bash
package com.unicorn;

import software.amazon.awscdk.CfnOutput;
import software.amazon.awscdk.CfnOutputProps;
import software.amazon.awscdk.Duration;
import software.amazon.awscdk.Stack;
import software.amazon.awscdk.StackProps;
import software.amazon.awscdk.services.apigateway.LambdaRestApi;
import software.amazon.awscdk.services.apigateway.RestApi;
import software.amazon.awscdk.services.lambda.Alias;
import software.amazon.awscdk.services.lambda.Code;
import software.amazon.awscdk.services.lambda.Function;
import software.amazon.awscdk.services.lambda.IFunction;
import software.amazon.awscdk.services.lambda.Runtime;
import software.amazon.awscdk.services.lambda.SnapStartConf;
import software.constructs.Construct;

import java.util.List;
import java.util.Map;

public class UnicornStoreStack extends Stack {

    private final InfrastructureStack infrastructureStack;

    public UnicornStoreStack(final Construct scope, final String id, final StackProps props,
                             final InfrastructureStack infrastructureStack) {
        super(scope, id, props);

        //Get previously created infrastructure stack
        this.infrastructureStack = infrastructureStack;

        //Create Micronaut Lambda function with SnapStart enabled
        var unicornStoreLambda = createUnicornLambdaFunction();

        //Only Lambda function versions will benefit from SnapStart
        var version = unicornStoreLambda.getCurrentVersion();
        var alias = Alias.Builder.create(this, ""UnicornStoreProdAlias"")
                .aliasName(""Prod"")
                .version(version)
                .build();

        //Setup a API Gateway to access the specific version of the Spring Lambda function using an alias
        var restApi = setupRestApi(alias);

        //Create output values for later reference
        new CfnOutput(this, ""unicorn-store-function-arn"", CfnOutputProps.builder()
                .value(unicornStoreLambda.getFunctionArn())
                .build());

        new CfnOutput(this, ""ApiEndpoint"", CfnOutputProps.builder()
                .value(restApi.getUrl())
                .build());
    }

    private RestApi setupRestApi(IFunction unicornStoreLambda) {
        return LambdaRestApi.Builder.create(this, ""UnicornStoreApi"")
                .restApiName(""UnicornStoreApi"")
                .handler(unicornStoreLambda)
                .build();
    }

    private Function createUnicornLambdaFunction() {
        Function function = Function.Builder.create(this, ""UnicornStoreFunction"")
                .runtime(Runtime.JAVA_17)
                .functionName(""unicorn-store"")
                .memorySize(2048)
                .timeout(Duration.seconds(29))
                .code(Code.fromAsset(""../../software/unicorn-store/target/store-micronaut-1.0.0.jar""))
                .handler(""io.micronaut.function.aws.proxy.MicronautLambdaHandler"")
                .vpc(infrastructureStack.getVpc())
                .securityGroups(List.of(infrastructureStack.getApplicationSecurityGroup()))
                .environment(Map.of(
                        ""DATASOURCES_DEFAULT_USERNAME"", ""postgres"",
                        ""DATASOURCES_DEFAULT_PASSWORD"", infrastructureStack.getDatabaseSecretString(),
                        ""DATASOURCES_DEFAULT_URL"", infrastructureStack.getDatabaseJDBCConnectionString(),
                        ""AWS_SERVERLESS_JAVA_CONTAINER_INIT_GRACE_TIME"", ""500""
                ))
                .snapStart(SnapStartConf.ON_PUBLISHED_VERSIONS)
                .build();

        return function;
    }
}

```",https://rattle-stock-d32.notion.site/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2Fe7472e42-7118-406f-8758-f9c76b1cf86a%2F590a6e25-32a0-4a1f-a24e-865377cde31e%2FUntitled.png?table=block&id=43886af9-fadd-4876-a992-534871896ae3&spaceId=e7472e42-7118-406f-8758-f9c76b1cf86a&width=1290&userId=&cache=v2,Cloud Essentials,Developer,AWS Lambda SnapStart와 관계형 데이터베이스를 통합하여 빠른 초기 실행 시간과 향상된 애플리케이션 성능을 제공합니다.,"Lambda, RDS, VPC, API Gateway, SnapStart, Micronaut Framework, CDK, GitHub repo"
33,데이터베이스 최적화:AWS Lambda와 RDS Proxy의 통합 사용법,"## 개요

Amazon API Gateway, AWS Lambda, 및 RDS Proxy를 사용하여 HTTP API 엔드포인트를 통해 데이터베이스 쿼리를 실행하는 서버리스 아키텍처를 구축할 수 있습니다. 이 구성은 데이터베이스와의 통신을 보다 안전하고 효율적으로 관리할 수 있게 해 줍니다. 각 서비스의 역할과 이들을 통합하여 할 수 있는 일들을 아래와 같이 설명드릴게요.

## 서비스 소개

### **Amazon API Gateway**

Amazon API Gateway는 개발자가 HTTP, HTTPS 프로토콜 기반의 API를 쉽게 생성, 배포 및 관리할 수 있도록 하는 완전 관리형 서비스입니다. 이는 API를 통한 애플리케이션과 데이터 소스 사이의 통신을 관리합니다.

### **AWS Lambda**

AWS Lambda는 서버 없이 코드를 실행할 수 있게 하는 컴퓨팅 서비스입니다. 이벤트가 발생하면 자동으로 코드를 실행하며, 필요에 따라 자원을 자동으로 할당받습니다.

### **Amazon RDS Proxy**

Amazon RDS Proxy는 데이터베이스와의 연결을 관리하여 애플리케이션의 확장성과 보안을 향상시키는 관리형 프록시 서비스입니다. RDS Proxy는 데이터베이스 연결을 풀링하여 Lambda와 같은 서버리스 환경에서 데이터베이스를 효율적으로 활용할 수 있게 해 줍니다.

## 통합 사용 시나리오

1. **HTTP API를 통한 데이터베이스 쿼리 실행**:
    - 사용자가 HTTP POST 요청을 Amazon API Gateway로 보내면, 이 요청은 AWS Lambda 함수를 트리거합니다.
    - Lambda 함수는 IAM에서 일시적인 토큰을 검색하여 RDS Proxy를 통해 데이터베이스에 인증합니다.
2. **데이터베이스 연결 및 쿼리 관리**:
    - RDS Proxy는 데이터베이스 연결을 설정하고, Lambda 함수가 이 연결을 사용하여 필요한 쿼리나 트랜잭션을 실행합니다.
    - 이 과정은 데이터베이스 부하를 줄이고, 연결 지연 시간을 최소화하여 애플리케이션의 성능을 최적화합니다.

## 예제

### git

???Visit the?[GitHub repo for this pattern](https://github.com/aws-samples/serverless-patterns/tree/main/apigw-http-api-lambda-rds-proxy-terraform).

```java
git clone https://github.com/aws-samples/serverless-patterns/ 
cd serverless-patterns/apigw-http-api-lambda-rds-proxy-terraform
```

### 배포

```bash
terraform init
terraform apply
```

### 인프라 생성 코드

```bash
terraform {
  required_providers {
    aws = {
      source  = ""hashicorp/aws""
      version = ""~> 4.8.0""
    }
    random = {
      source  = ""hashicorp/random""
      version = ""~> 3.1.0""
    }
    archive = {
      source  = ""hashicorp/archive""
      version = ""~> 2.2.0""
    }
  }

 required_version = "">= 0.14.9""
}

provider ""aws"" {
  region = var.aws_region
}

data ""aws_caller_identity"" ""current"" {}

locals {
  account_id = data.aws_caller_identity.current.account_id
}

resource ""random_string"" ""random"" {
  length           = 6
  special          = false
}

// get secret info

data ""aws_secretsmanager_secret_version"" ""creds"" {
  secret_id = var.secret_name
}

locals {
  lambda_username = jsondecode(
    data.aws_secretsmanager_secret_version.creds.secret_string
  )
}

###############################################################
# Lambda
###############################################################

resource ""aws_s3_bucket"" ""lambda_bucket"" {
  bucket_prefix = var.bucket_name
  force_destroy = true
  tags = {
    Name        = ""${var.bucket_name}""
  }
}

resource ""aws_s3_bucket_acl"" ""private_bucket"" {
  bucket = aws_s3_bucket.lambda_bucket.id
  acl    = ""private""
}

resource ""null_resource"" ""my_lambda_buildstep"" {
  triggers = {
    app      = ""${base64sha256(file(""${path.module}/src/app.py""))}""
    requirements = ""${base64sha256(file(""${path.module}/src/requirements.txt""))}""
    build        = ""${base64sha256(file(""${path.module}/src/build.sh""))}""
  }

  provisioner ""local-exec"" {
    command = ""${path.module}/src/build.sh""
  }
}

data ""archive_file"" ""lambda_source"" {
  type = ""zip""

  source_dir  = ""${path.module}/src""
  output_path = ""${path.module}/src.zip""
  
  depends_on = [null_resource.my_lambda_buildstep]
}

resource ""aws_s3_object"" ""lambda"" {
  bucket = aws_s3_bucket.lambda_bucket.id

  key    = ""source.zip""
  source = data.archive_file.lambda_source.output_path

  #etag = filemd5(data.archive_file.lambda_source.output_path)
  depends_on = [null_resource.my_lambda_buildstep, data.archive_file.lambda_source]
  
}

//Define lambda function
resource ""aws_lambda_function"" ""rds_proxy_function"" {
  function_name = ""rds_proxy_function-${random_string.random.id}""

  s3_bucket = aws_s3_bucket.lambda_bucket.id
  s3_key    = aws_s3_object.lambda.key

  runtime = ""python3.7""
  handler = ""app.lambda_handler""

  source_code_hash = data.archive_file.lambda_source.output_base64sha256
  
  description = ""function to access RDS Aurora via RDS proxy endpoint""

  role = aws_iam_role.lambda_exec.arn
  timeout = 60
  
  vpc_config {
    subnet_ids         = var.vpc_subnets
    security_group_ids = [var.security_group]
  }
  
  environment {
    variables = {
      region: var.aws_region,
      rds_endpoint: var.rds_proxy_endpoint,
      port: 3306,
      username: local.lambda_username.username
      database: ""dbname""
    }
  }
  
}

resource ""aws_cloudwatch_log_group"" ""rds_proxy_function"" {
  name = ""/aws/lambda/${aws_lambda_function.rds_proxy_function.function_name}""

  retention_in_days = var.lambda_log_retention
}

resource ""aws_iam_role"" ""lambda_exec"" {
  name = ""LambdaRdsProxyRole-${random_string.random.id}""

  assume_role_policy = jsonencode({
    Version = ""2012-10-17""
    Statement = [{
      Action = ""sts:AssumeRole""
      Effect = ""Allow""
      Sid    = """"
      Principal = {
        Service = ""lambda.amazonaws.com""
      }
      }
    ]
  })
}

resource ""aws_iam_policy"" ""lambda-exec-role"" {
  name = ""LambdaRdsProxyPolicy-${random_string.random.id}""

  policy = <<POLICY
{
    ""Version"": ""2012-10-17"",
    ""Statement"": [
        {
            ""Effect"": ""Allow"",
            ""Action"": [
                ""rds-db:connect""
            ],
            ""Resource"": ""arn:aws:rds-db:${var.aws_region}:${local.account_id}:dbuser:${var.rds_proxy_resourceid}/*""
        },
        {
            ""Effect"": ""Allow"",
            ""Action"": [
                ""logs:CreateLogGroup"",
                ""logs:CreateLogStream"",
                ""logs:PutLogEvents"",
                ""ec2:CreateNetworkInterface"",
                ""ec2:DescribeNetworkInterfaces"",
                ""ec2:DeleteNetworkInterface"",
                ""ec2:AssignPrivateIpAddresses"",
                ""ec2:UnassignPrivateIpAddresses""
            ],
            ""Resource"": ""*""
        }
    ]
}
POLICY
}

resource ""aws_iam_role_policy_attachment"" ""lambda_policy"" {
  role       = aws_iam_role.lambda_exec.name
  policy_arn = aws_iam_policy.lambda-exec-role.arn
}

###############################################################
# API Gateway
###############################################################

resource ""aws_apigatewayv2_api"" ""this"" {
  name          = ""apigw-http-lambda-rds-proxy""
  protocol_type = ""HTTP""
}

resource ""aws_cloudwatch_log_group"" ""api_gw"" {
  name = ""/aws/api_gw/${aws_apigatewayv2_api.this.name}""

  retention_in_days = var.lambda_log_retention
}

resource ""aws_apigatewayv2_stage"" ""lambda"" {
  api_id = aws_apigatewayv2_api.this.id

  name        = ""$default""
  auto_deploy = true

  access_log_settings {
    destination_arn = aws_cloudwatch_log_group.api_gw.arn

    format = jsonencode({
      requestId               = ""$context.requestId""
      sourceIp                = ""$context.identity.sourceIp""
      requestTime             = ""$context.requestTime""
      protocol                = ""$context.protocol""
      httpMethod              = ""$context.httpMethod""
      resourcePath            = ""$context.resourcePath""
      routeKey                = ""$context.routeKey""
      status                  = ""$context.status""
      responseLength          = ""$context.responseLength""
      integrationErrorMessage = ""$context.integrationErrorMessage""
      }
    )
  }
}

resource ""aws_apigatewayv2_integration"" ""lambda"" {
  api_id = aws_apigatewayv2_api.this.id

  integration_uri    = aws_lambda_function.rds_proxy_function.invoke_arn
  integration_type   = ""AWS_PROXY""
  integration_method = ""POST""
}

resource ""aws_apigatewayv2_route"" ""any"" {
  api_id = aws_apigatewayv2_api.this.id

  route_key = ""$default""
  target    = ""integrations/${aws_apigatewayv2_integration.lambda.id}""
}

resource ""aws_lambda_permission"" ""api_gw"" {
  statement_id  = ""AllowExecutionFromAPIGateway""
  action        = ""lambda:InvokeFunction""
  function_name = aws_lambda_function.rds_proxy_function.function_name
  principal     = ""apigateway.amazonaws.com""

  source_arn = ""${aws_apigatewayv2_api.this.execution_arn}/*/*""
}
```",https://rattle-stock-d32.notion.site/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2Fe7472e42-7118-406f-8758-f9c76b1cf86a%2F61bffc4b-8afc-4e7d-9fd5-ffaeaea9da81%2FUntitled.png?table=block&id=0ee96a25-4c44-4a5c-8df8-a3f8bcc7b8eb&spaceId=e7472e42-7118-406f-8758-f9c76b1cf86a&width=1280&userId=&cache=v2,Cloud Essentials,Developer,"Amazon API Gateway, AWS Lambda, 및 RDS Proxy를 사용하여 데이터베이스 쿼리를 실행하는 안전하고 효율적인 서버리스 아키텍처를 구축합니다."," API Gateway, Lambda, RDS Proxy, HTTP API, serverless architecture, HTTP POST, 데이터베이스 쿼리, 데이터베이스 연결"
34,X12 EDI 파일을 JSON으로 효율적으로 변환하는 클라우드 솔루션,"## 개요

Amazon S3와 AWS B2B Data Interchange Transformers를 사용하여 X12 EDI 파일을 JSON 형식으로 변환하고 관리하는 효율적인 데이터 처리 파이프라인을 구축할 수 있습니다. 이 통합은 데이터 변환 작업을 자동화하고, 다양한 데이터 형식 간의 상호 운용성을 향상시킵니다. 각 서비스의 역할과 이들을 통합하여 할 수 있는 일들을 아래와 같이 설명드릴게요.

## 서비스 소개

### **Amazon S3**

Amazon Simple Storage Service(S3)는 스케일 아웃이 가능한 객체 스토리지 서비스로, 데이터를 저장하고 어디서나 쉽게 접근할 수 있게 합니다. 사용자는 무제한의 데이터를 저장할 수 있으며, 다양한 보안 옵션과 관리 기능을 통해 데이터를 안전하게 관리할 수 있습니다.

### **AWS B2B Data Interchange Transformers**

AWS B2B Data Interchange Transformers는 비즈니스 문서를 처리하고 다른 형식으로 변환하는 서비스입니다. 이 서비스는 X12와 같은 전자 데이터 교환(EDI) 표준을 JSON과 같은 현대적인 데이터 형식으로 변환하여, 더 넓은 애플리케이션과 시스템과의 호환성을 제공합니다.

## 통합 사용 시나리오

1. **데이터 변환 및 자동 처리**:
    - X12 EDI 파일이 입력 Amazon S3 버킷에 업로드됩니다.
    - 파일 업로드는 AWS B2B Data Interchange Transformers를 트리거하여 파일을 JSON 형식으로 변환합니다.
2. **변환된 데이터의 저장 및 접근성**:
    - 변환된 JSON 파일은 출력 Amazon S3 버킷에 자동으로 업로드됩니다.
    - 이 JSON 파일은 다양한 비즈니스 애플리케이션에서 사용될 수 있으며, 추가 분석이나 처리가 가능합니다.

## 예제

### git

??Visit the?[GitHub repo for this pattern](https://github.com/aws-samples/serverless-patterns/tree/main/s3-b2bi-s3).

```java
git clone https://github.com/aws-samples/serverless-patterns/ 
cd serverless-patterns/s3-b2bi-s3
```

### 배포

```bash
sam deploy -g -t template-part1.yaml
sam deploy -g -t template-part2.yaml
```

### 인프라 생성 코드

```bash
AWSTemplateFormatVersion: '2010-09-09' 
Transform: AWS::Serverless-2016-10-31
Description: This is part 1 of a 2 part template to demonstrate how AWS B2B Data Interchange can transform EDI Files into JSON as per the transformation logic. This is part 1 of the template.

# Get the required input parameters
Parameters:
  BusinessName:
    Type: String
    Description: Please enter the business name
  Email:
    Type: String
    Description: Please enter email id
    AllowedPattern: ^[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\.[a-zA-Z0-9-.]+$
    ConstraintDescription: You should enter a valid email
  Phone:
    Type: String
    Description: Please enter phone number

Resources:
  # Create profile for Business Partner using resoure type AWS::B2BI::Profile
  MyProfile: 
    Type: AWS::B2BI::Profile
    Properties: 
      BusinessName: !Sub ""${BusinessName}""
      Email: !Sub ""${Email}""
      Logging: ENABLED
      Name: MyProfile
      Phone: !Sub ""${Phone}""

  # Create a transformer using resource type AWS::B2BI::Transformer
  MyTransformer: 
    Type: AWS::B2BI::Transformer
    Properties:
      EdiType: 
          X12Details: 
            TransactionSet: X12_214
            Version: VERSION_4010
      FileFormat: JSON
      MappingTemplate: |
        {
          ""ReferenceID"":functional_groups.transactions[0].segments[0].B10_01,
          ""ShipmentID"":functional_groups.transactions[0].segments[0].B10_02,
          ""BillOfLandingNumber"":functional_groups.transactions[0].segments[1].L11_01,
          ""From"":functional_groups.transactions[0].segments[4].'0100_loop'[2].* ~> $join("",""),
          ""To"":functional_groups.transactions[0].segments[4].'0100_loop'[4].* ~> $join("",""),
          ""ShipmentStatusCode"":functional_groups.transactions[0].**.AT7_01
        }
      Name: MyTransformer
      Status: active

  # Create a input bucket for EDI file
  EDI214InputBucket: 
    Type: AWS::S3::Bucket
    Properties: 
      BucketName: !Sub ""edi-214-input-${AWS::AccountId}-${AWS::Region}""
      NotificationConfiguration: 
        EventBridgeConfiguration:
          EventBridgeEnabled: true
      
  # Create bucket policy to allow read operations from AWS B2B Data Interchange
  EDI214InputBucketPolicy:
    Type: AWS::S3::BucketPolicy
    Properties:
      Bucket: !Ref EDI214InputBucket
      PolicyDocument:
        Version: 2012-10-17
        Statement:
          - Sid: B2BIEdiCapabilityInputPolicy
            Effect: Allow
            Principal:
              Service: b2bi.amazonaws.com
            Action: 
            - s3:GetObject
            - s3:GetObjectAttributes
            Resource: !Join 
              - """"
              - - ""arn:aws:s3:::""
                - !Ref EDI214InputBucket
                - /*
            Condition:
              StringEquals:
                aws:SourceAccount:
                  Ref: AWS::AccountId  

  # Create output bucket for EDI file
  EDI214OutputBucket: 
    Type: AWS::S3::Bucket
    Properties: 
      BucketName: !Sub ""edi-214-output-${AWS::AccountId}-${AWS::Region}""

  # Create bucket policy to allow write operations from AWS B2B Data Interchange
  EDI214OutputBucketPolicy:
    Type: AWS::S3::BucketPolicy
    Properties:
      Bucket: !Ref EDI214OutputBucket
      PolicyDocument:
        Version: 2012-10-17
        Statement:
          - Sid: B2BIEdiCapabilityOutputPolicy
            Effect: Allow
            Principal:
              Service: b2bi.amazonaws.com
            Action: 
            - s3:PutObject
            - s3:AbortMultipartUpload
            Resource: !Join 
              - """"
              - - ""arn:aws:s3:::""
                - !Ref EDI214OutputBucket
                - /*
            Condition:
              StringEquals:
                aws:SourceAccount:
                  Ref: AWS::AccountId  

# Output the bucket names, transformer Id, Profile Id
Outputs:
  EDI214InputBucketName:
    Value: !Ref EDI214InputBucket
  EDI214OutputBucketName:
    Value: !Ref EDI214OutputBucket
  MyTransformerId:
    Value: !Ref MyTransformer
  MyProfileId:
    Value: !Ref MyProfile

```",https://rattle-stock-d32.notion.site/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2Fe7472e42-7118-406f-8758-f9c76b1cf86a%2F94eee95e-6575-45bd-b73e-ec168b53e31a%2FUntitled.png?table=block&id=6d13507a-7c92-4945-8ba3-7ccb6dcd84dd&spaceId=e7472e42-7118-406f-8758-f9c76b1cf86a&width=1290&userId=&cache=v2,SaaS,Developer,"Amazon S3와 AWS B2B Data Interchange Transformers를 사용하여 X12 EDI 파일을 자동으로 JSON 형식으로 변환하고, 이를 효율적으로 관리합니다."," S3, B2B Data Interchange Transformers, EventBridge, CloudFormation, data processing, JSON conversion, serverless architecture, data interchange"
35,EDI 파일의 변환과 이벤트 기반 메시지 큐 시스템 구축,"## 개요

AWS B2B Data Interchange, Amazon EventBridge, 및 Amazon SQS를 통합하여 이벤트 주도 방식의 EDI 변환을 수행하는 아키텍처를 구축할 수 있습니다. 이 구성은 데이터 처리를 자동화하고, 시스템 간의 효율적인 메시지 전달을 가능하게 합니다. 각 서비스의 역할과 이들을 통합하여 할 수 있는 일들을 아래와 같이 설명드릴게요.

## 서비스 소개

### **AWS B2B Data Interchange Transformers**

AWS B2B Data Interchange Transformers는 EDI 파일을 다른 형식으로 변환하는 서비스로, 특히 B2B 거래에서 널리 사용되는 X12와 같은 포맷을 JSON 등의 현대적 데이터 형식으로 변환합니다.

### **Amazon EventBridge**

Amazon EventBridge는 서버리스 이벤트 버스 서비스로, 애플리케이션의 다양한 부분 간에 데이터를 실시간으로 라우팅할 수 있습니다. 이를 통해 이벤트를 필터링하고, 관련 시스템이나 서비스로 전달합니다.

### **Amazon SQS (Simple Queue Service)**

Amazon SQS는 관리형 메시지 큐 서비스로, 시스템 간 메시지를 안전하게 전송하고 저장하는 데 사용됩니다. 이는 대량의 분산된 애플리케이션 간의 통신을 쉽게 관리할 수 있게 해 줍니다.

## 통합 사용 시나리오

1. **EDI 파일의 자동 변환 및 처리**:
    - X12 EDI 파일이 Amazon S3 버킷에 업로드 됩니다.
    - 파일 업로드는 AWS B2B Data Interchange Transformers를 트리거하여 EDI 파일을 JSON 형식으로 변환합니다.
2. **이벤트 기반 통합 및 메시지 큐**:
    - 변환 완료 이벤트는 AWS B2B Data Interchange에 의해 Amazon EventBridge로 전송됩니다.
    - Amazon EventBridge Rule은 특정 이벤트를 선택하고 이를 Amazon SQS로 전달합니다.
    - SQS는 변환된 데이터에 대한 후속 처리를 위해 다른 서비스나 애플리케이션으로 메시지를 안전하게 큐잉합니다.

## 예제

### git

???Visit the?[GitHub repo for this pattern](https://github.com/aws-samples/serverless-patterns/tree/main/s3-b2bi-eventbridge-sqs).

```java
git clone https://github.com/aws-samples/serverless-patterns/ 
cd serverless-patterns/s3-b2bi-eventbridge-sqs
```

### 배포

```bash
See the GitHub repo for detailed deployment instructions.
sam deploy -g
```

### 인프라 생성 코드

```bash
AWSTemplateFormatVersion: '2010-09-09' 
Transform: AWS::Serverless-2016-10-31
Description: This template to demonstrate how AWS B2B Data Interchange can transform EDI Files into JSON as per the transformation logic. This is part 1 of the template.(uksb-1tthgi812) (tag:s3-b2bi-eventbridge-sqs)

# Get the required input parameters
Parameters:
  BusinessName:
    Type: String
    Description: Please enter the business name
  Email:
    Type: String
    Description: Please enter email id
    AllowedPattern: ^[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\.[a-zA-Z0-9-.]+$
    ConstraintDescription: You should enter a valid email
  Phone:
    Type: String
    Description: Please enter phone number

Resources:
  # Create profile for Business Partner using resoure type AWS::B2BI::Profile
  MyProfile: 
    Type: AWS::B2BI::Profile
    Properties: 
      BusinessName: !Sub ""${BusinessName}""
      Email: !Sub ""${Email}""
      Logging: ENABLED
      Name: MyProfile
      Phone: !Sub ""${Phone}""

  # Create a transformer using resource type AWS::B2BI::Transformer
  MyTransformer: 
    Type: AWS::B2BI::Transformer
    Properties:
      EdiType: 
          X12Details: 
            TransactionSet: X12_214
            Version: VERSION_4010
      FileFormat: JSON
      MappingTemplate: |
        {
          ""ReferenceID"":functional_groups.transactions[0].segments[0].B10_01,
          ""ShipmentID"":functional_groups.transactions[0].segments[0].B10_02,
          ""BillOfLandingNumber"":functional_groups.transactions[0].segments[1].L11_01,
          ""From"":functional_groups.transactions[0].segments[4].'0100_loop'[2].* ~> $join("",""),
          ""To"":functional_groups.transactions[0].segments[4].'0100_loop'[4].* ~> $join("",""),
          ""ShipmentStatusCode"":functional_groups.transactions[0].**.AT7_01
        }
      Name: MyTransformer
      Status: active

  # Create a input bucket for EDI file
  EDI214InputBucket: 
    Type: AWS::S3::Bucket
    Properties: 
      BucketName: !Sub ""edi-214-input-${AWS::AccountId}-${AWS::Region}""
      NotificationConfiguration: 
        EventBridgeConfiguration:
          EventBridgeEnabled: true
      
  # Create bucket policy to allow read operations from AWS B2B Data Interchange
  EDI214InputBucketPolicy:
    Type: AWS::S3::BucketPolicy
    Properties:
      Bucket: !Ref EDI214InputBucket
      PolicyDocument:
        Version: 2012-10-17
        Statement:
          - Sid: B2BIEdiCapabilityInputPolicy
            Effect: Allow
            Principal:
              Service: b2bi.amazonaws.com
            Action: 
            - s3:GetObject
            - s3:GetObjectAttributes
            Resource: !Join 
              - """"
              - - ""arn:aws:s3:::""
                - !Ref EDI214InputBucket
                - /*
            Condition:
              StringEquals:
                aws:SourceAccount:
                  Ref: AWS::AccountId  

  # Create output bucket for EDI file
  EDI214OutputBucket: 
    Type: AWS::S3::Bucket
    Properties: 
      BucketName: !Sub ""edi-214-output-${AWS::AccountId}-${AWS::Region}""

  # Create bucket policy to allow write operations from AWS B2B Data Interchange
  EDI214OutputBucketPolicy:
    Type: AWS::S3::BucketPolicy
    Properties:
      Bucket: !Ref EDI214OutputBucket
      PolicyDocument:
        Version: 2012-10-17
        Statement:
          - Sid: B2BIEdiCapabilityOutputPolicy
            Effect: Allow
            Principal:
              Service: b2bi.amazonaws.com
            Action:
            - s3:GetObject
            - s3:DeleteObject 
            - s3:PutObject
            - s3:AbortMultipartUpload
            Resource: !Join 
              - """"
              - - ""arn:aws:s3:::""
                - !Ref EDI214OutputBucket
                - /*
            Condition:
              StringEquals:
                aws:SourceAccount:
                  Ref: AWS::AccountId  

  # Create create a trading capability
  MyTradingCapability: 
    Type: AWS::B2BI::Capability
    Properties:
      Configuration: 
        Edi: 
          InputLocation: 
            BucketName: !Ref EDI214InputBucket
            Key: input
          OutputLocation: 
            BucketName: !Ref EDI214OutputBucket
            Key: output
          TransformerId: !Ref MyTransformer
          Type: 
            X12Details: 
              TransactionSet: X12_214
              Version: VERSION_4010
      Name: EDI214-MyTradingCapability
      Type: edi

  # Create a B2BI Partnership
  MyPartner: 
    Type: AWS::B2BI::Partnership
    Properties:
      Capabilities: 
        - !Ref MyTradingCapability
      Email: !Sub ""${Email}""
      Name: MyPartner
      Phone: !Sub ""${Phone}""
      ProfileId: !Ref MyProfile
  
  # Create a SQS queue to receive the events from AWS B2B Data Interchange
  MyQueue:
    Type: AWS::SQS::Queue
    Properties:
      QueueName: MyQueue

  # Create a event rule to receive the events from AWS B2B Data Interchange and send it to SQS queue.
  MyEventRule:
    Type: AWS::Events::Rule
    Properties:
      Description: Receive the events from AWS B2B Data Interchange and send it to SQS queue.
      EventPattern:
        source:
          - aws.b2bi
        detail-type:
          - Transformation Completed
          - Transformation Failed
        detail:
          trading-partner-id: 
            - !GetAtt MyPartner.TradingPartnerId
      State: ENABLED
      Targets:
        - Arn: !GetAtt MyQueue.Arn
          Id: MyQueueTarget

  # Create a SQS queue policy to allow send message to SQS queue from AWS B2B Data Interchange.
  MyQueuePolicy:
    Type: AWS::SQS::QueuePolicy
    Properties:
      Queues:
        - !Ref MyQueue
      PolicyDocument:
        Statement:
          - Effect: Allow
            Principal:
              Service: events.amazonaws.com
            Action: sqs:SendMessage
            Resource: !GetAtt MyQueue.Arn
            Condition:
              ArnEquals:
                'aws:SourceArn': !GetAtt MyEventRule.Arn

# Output the bucket names, transformer Id, Profile Id
Outputs:
  EDI214InputBucketName:
    Description: EDI214 Input Bucket Name
    Value: !Ref EDI214InputBucket
  EDI214OutputBucketName:
    Description: EDI214 Output Bucket Name
    Value: !Ref EDI214OutputBucket
  MyTransformerId:
    Description: Transformer Id
    Value: !Ref MyTransformer
  MyProfileId:
    Description: Profile Id
    Value: !Ref MyProfile
  MyTradingCapability:
    Description: Trading Capability
    Value: !Ref MyTradingCapability
  MyPartner:
    Description: Partner
    Value: !Ref MyPartner
  MyQueue:
    Description: MyQueue
    Value: !Ref MyQueue

```",https://rattle-stock-d32.notion.site/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2Fe7472e42-7118-406f-8758-f9c76b1cf86a%2F563fa337-9052-4246-b2e5-c4c04e7bb24f%2FUntitled.png?table=block&id=d1af56d5-35ce-44a1-a690-46cc5211ad5c&spaceId=e7472e42-7118-406f-8758-f9c76b1cf86a&width=1280&userId=&cache=v2,SaaS,Developer,"AWS B2B Data Interchange, Amazon EventBridge, 및 Amazon SQS를 통합하여 이벤트 주도 방식으로 EDI 파일을 자동으로 변환하고 관련 이벤트를 효과적으로 처리합니다.","B2B Data Interchange, EventBridge, SQS, S3, serverless, event-driven architecture, message queue, data transformation"
36,안전한 REST API 프록시 구축,"## **개요**

Amazon EC2에서 호스팅되는 NGINX 서버를 위한 프록시 역할을 하는 REST API를 구축합니다. 이 패턴은 Amazon API Gateway, Network Load Balancer(NLB), 그리고 EC2 인스턴스를 활용하여 VPC 내에서 안전하게 통합을 제공합니다. 아래에서는 각 서비스의 역할과 통합 사용 시나리오에 대해 설명합니다.

## **서비스 소개**

### **Amazon API Gateway**

API Gateway는 개발자들이 RESTful API를 쉽게 생성하고 배포할 수 있는 완전 관리형 서비스입니다. 특히, API Gateway는 VPC 링크 기능을 제공하여, 내부의 NLB와 같은 AWS 리소스에 안전하게 연결할 수 있도록 지원합니다.

### **Network Load Balancer (NLB)**

NLB는 고성능, 저지연의 로드 밸런서를 제공하여 EC2 인스턴스에 트래픽을 효율적으로 분산시킵니다. API Gateway와 통합하여 NGINX 서버로 연결할 때 사용됩니다.

### **Amazon Elastic Compute Cloud (Amazon EC2)**

Amazon EC2는 확장 가능하고 유연한 컴퓨팅 자원을 제공하는 서비스입니다. 이 예제에서는 EC2 인스턴스에서 NGINX 서버를 호스팅합니다.

### **NGINX 서버**

NGINX는 고성능의 웹 서버 및 리버스 프록시 서버로, 다양한 웹 및 애플리케이션 트래픽을 효율적으로 관리합니다. EC2 인스턴스에 설치되어 API 요청을 처리하고 적절한 백엔드 서비스로 라우팅합니다.

## **통합 사용 시나리오**

1. **안전한 REST API 프록시 구축**:
    - API Gateway에서 REST API를 생성하고, VPC 링크를 통해 내부 NLB에 연결합니다.
    - NLB는 Amazon EC2에서 실행 중인 NGINX 서버로 트래픽을 라우팅합니다.
    - NGINX 서버는 백엔드 서비스 또는 데이터베이스로의 요청을 안전하게 처리합니다.
2. **Event-Driven EDI Transformation**:
    - API Gateway는 이벤트 기반으로 EC2 인스턴스에서 EDI 변환 작업을 수행하는 REST API를 제공합니다.
    - API Gateway를 통해 NGINX 서버로 트래픽이 전달되면, NGINX 서버는 EDI 데이터를 변환하고 Amazon S3 또는 다른 데이터 저장소로 전송합니다.
3. **내부 애플리케이션 및 데이터베이스 통합**:
    - API Gateway를 통해 EC2 인스턴스에 호스팅된 내부 애플리케이션과 데이터베이스에 안전하게 접근할 수 있습니다.
    - 이를 통해 사용자 또는 시스템이 외부 공개 없이 안전하게 내부 리소스에 접근할 수 있습니다.

## 예제

### git

??Visit the?[GitHub repo for this pattern](https://github.com/aws-samples/serverless-patterns/tree/main/apigw-ec2).

```java
git clone https://github.com/aws-samples/serverless-patterns/ 
cd serverless-patterns/apigw-ec2
```

### 배포

```bash
sam deploy --guided
```

### 인프라 생성 코드

```bash
AWSTemplateFormatVersion: '2010-09-09'
Transform: AWS::Serverless-2016-10-31
Description: >
  (uksb-1tthgi812) (tag:apigw-ec2)
  This CloudFormation deploys public REST API along with private network load balancer which will route the request to an EC2 website via vpc link
Parameters:
  InstanceType:
    Type: String
    Description: Select an instance type
    Default: t2.micro
    AllowedValues: [c4.2xlarge, c4.4xlarge, c4.8xlarge, c4.large, c4.xlarge, c5.12xlarge, c5.18xlarge, c5.24xlarge, c5.2xlarge, c5.4xlarge, c5.9xlarge, c5.large, c5.metal, c5.xlarge, c5a.12xlarge, c5a.16xlarge, c5a.24xlarge, c5a.2xlarge, c5a.4xlarge, c5a.8xlarge, c5a.large, c5a.xlarge, c5d.12xlarge, c5d.18xlarge, c5d.24xlarge, c5d.2xlarge, c5d.4xlarge, c5d.9xlarge, c5d.large, c5d.metal, c5d.xlarge, c5n.18xlarge, c5n.2xlarge, c5n.4xlarge, c5n.9xlarge, c5n.large, c5n.metal, c5n.xlarge, c6g.12xlarge, c6g.16xlarge, c6g.2xlarge, c6g.4xlarge, c6g.8xlarge, c6g.large, c6g.medium, c6g.metal, c6g.xlarge, c6gd.12xlarge, c6gd.16xlarge, c6gd.2xlarge, c6gd.4xlarge, c6gd.8xlarge, c6gd.large, c6gd.medium, c6gd.metal, c6gd.xlarge, c6gn.12xlarge, c6gn.16xlarge, c6gn.2xlarge, c6gn.4xlarge, c6gn.8xlarge, c6gn.large, c6gn.medium, c6gn.xlarge, c6i.12xlarge, c6i.16xlarge, c6i.24xlarge, c6i.2xlarge, c6i.32xlarge, c6i.4xlarge, c6i.8xlarge, c6i.large, c6i.metal, c6i.xlarge, d2.2xlarge, d2.4xlarge, d2.8xlarge, d2.xlarge, d3.2xlarge, d3.4xlarge, d3.8xlarge, d3.xlarge, g3.16xlarge, g3.4xlarge, g3.8xlarge, g4ad.16xlarge, g4ad.2xlarge, g4ad.4xlarge, g4ad.8xlarge, g4ad.xlarge, g4dn.12xlarge, g4dn.16xlarge, g4dn.2xlarge, g4dn.4xlarge, g4dn.8xlarge, g4dn.metal, g4dn.xlarge, g5.12xlarge, g5.16xlarge, g5.24xlarge, g5.2xlarge, g5.48xlarge, g5.4xlarge, g5.8xlarge, g5.xlarge, i3.16xlarge, i3.2xlarge, i3.4xlarge, i3.8xlarge, i3.large, i3.metal, i3.xlarge, i3en.12xlarge, i3en.24xlarge, i3en.2xlarge, i3en.3xlarge, i3en.6xlarge, i3en.large, i3en.metal, i3en.xlarge, i4i.16xlarge, i4i.2xlarge, i4i.32xlarge, i4i.4xlarge, i4i.8xlarge, i4i.large, i4i.metal, i4i.xlarge, im4gn.16xlarge, im4gn.2xlarge, im4gn.4xlarge, im4gn.8xlarge, im4gn.large, im4gn.xlarge, inf1.24xlarge, inf1.2xlarge, inf1.6xlarge, inf1.xlarge, is4gen.2xlarge, is4gen.4xlarge, is4gen.8xlarge, is4gen.large, is4gen.medium, is4gen.xlarge, m4.10xlarge, m4.16xlarge, m4.2xlarge, m4.4xlarge, m4.large, m4.xlarge, m5.12xlarge, m5.16xlarge, m5.24xlarge, m5.2xlarge, m5.4xlarge, m5.8xlarge, m5.large, m5.metal, m5.xlarge, m5a.12xlarge, m5a.16xlarge, m5a.24xlarge, m5a.2xlarge, m5a.4xlarge, m5a.8xlarge, m5a.large, m5a.xlarge, m5ad.12xlarge, m5ad.16xlarge, m5ad.24xlarge, m5ad.2xlarge, m5ad.4xlarge, m5ad.8xlarge, m5ad.large, m5ad.xlarge, m5d.12xlarge, m5d.16xlarge, m5d.24xlarge, m5d.2xlarge, m5d.4xlarge, m5d.8xlarge, m5d.large, m5d.metal, m5d.xlarge, m6g.12xlarge, m6g.16xlarge, m6g.2xlarge, m6g.4xlarge, m6g.8xlarge, m6g.large, m6g.medium, m6g.metal, m6g.xlarge, m6i.12xlarge, m6i.16xlarge, m6i.24xlarge, m6i.2xlarge, m6i.32xlarge, m6i.4xlarge, m6i.8xlarge, m6i.large, m6i.metal, m6i.xlarge, p3.16xlarge, p3.2xlarge, p3.8xlarge, r4.16xlarge, r4.2xlarge, r4.4xlarge, r4.8xlarge, r4.large, r4.xlarge, r5.12xlarge, r5.16xlarge, r5.24xlarge, r5.2xlarge, r5.4xlarge, r5.8xlarge, r5.large, r5.metal, r5.xlarge, r5a.12xlarge, r5a.16xlarge, r5a.24xlarge, r5a.2xlarge, r5a.4xlarge, r5a.8xlarge, r5a.large, r5a.xlarge, r5ad.12xlarge, r5ad.16xlarge, r5ad.24xlarge, r5ad.2xlarge, r5ad.4xlarge, r5ad.8xlarge, r5ad.large, r5ad.xlarge, r5b.12xlarge, r5b.16xlarge, r5b.24xlarge, r5b.2xlarge, r5b.4xlarge, r5b.8xlarge, r5b.large, r5b.metal, r5b.xlarge, r5d.12xlarge, r5d.16xlarge, r5d.24xlarge, r5d.2xlarge, r5d.4xlarge, r5d.8xlarge, r5d.large, r5d.metal, r5d.xlarge, r5n.12xlarge, r5n.16xlarge, r5n.24xlarge, r5n.2xlarge, r5n.4xlarge, r5n.8xlarge, r5n.large, r5n.metal, r5n.xlarge, r6g.12xlarge, r6g.16xlarge, r6g.2xlarge, r6g.4xlarge, r6g.8xlarge, r6g.large, r6g.medium, r6g.metal, r6g.xlarge, r6gd.12xlarge, r6gd.16xlarge, r6gd.2xlarge, r6gd.4xlarge, r6gd.8xlarge, r6gd.large, r6gd.medium, r6gd.metal, r6gd.xlarge, r6i.12xlarge, r6i.16xlarge, r6i.24xlarge, r6i.2xlarge, r6i.32xlarge, r6i.4xlarge, r6i.8xlarge, r6i.large, r6i.metal, r6i.xlarge, t2.2xlarge, t2.large, t2.medium, t2.micro, t2.nano, t2.small, t2.xlarge, t3.2xlarge, t3.large, t3.medium, t3.micro, t3.nano, t3.small, t3.xlarge, t3a.2xlarge, t3a.large, t3a.medium, t3a.micro, t3a.nano, t3a.small, t3a.xlarge, t4g.2xlarge, t4g.large, t4g.medium, t4g.micro, t4g.nano, t4g.small, t4g.xlarge, u-3tb1.56xlarge, u-6tb1.112xlarge, u-6tb1.56xlarge, x1.16xlarge, x1.32xlarge, x1e.16xlarge, x1e.2xlarge, x1e.32xlarge, x1e.4xlarge, x1e.8xlarge, x1e.xlarge, x2idn.16xlarge, x2idn.24xlarge, x2idn.32xlarge, x2idn.metal, x2iedn.16xlarge, x2iedn.24xlarge, x2iedn.2xlarge, x2iedn.32xlarge, x2iedn.4xlarge, x2iedn.8xlarge, x2iedn.metal, x2iedn.xlarge, c5ad.12xlarge, c5ad.16xlarge, c5ad.24xlarge, c5ad.2xlarge, c5ad.4xlarge, c5ad.8xlarge, c5ad.large, c5ad.xlarge, c6a.12xlarge, c6a.16xlarge, c6a.24xlarge, c6a.2xlarge, c6a.32xlarge, c6a.48xlarge, c6a.4xlarge, c6a.8xlarge, c6a.large, c6a.metal, c6a.xlarge, c6id.12xlarge, c6id.16xlarge, c6id.24xlarge, c6id.2xlarge, c6id.32xlarge, c6id.4xlarge, c6id.8xlarge, c6id.large, c6id.metal, c6id.xlarge, c6in.12xlarge, c6in.16xlarge, c6in.24xlarge, c6in.2xlarge, c6in.32xlarge, c6in.4xlarge, c6in.8xlarge, c6in.large, c6in.xlarge, c7g.12xlarge, c7g.16xlarge, c7g.2xlarge, c7g.4xlarge, c7g.8xlarge, c7g.large, c7g.medium, c7g.metal, c7g.xlarge, d3en.12xlarge, d3en.2xlarge, d3en.4xlarge, d3en.6xlarge, d3en.8xlarge, d3en.xlarge, dl1.24xlarge, f1.16xlarge, f1.2xlarge, f1.4xlarge, g3s.xlarge, g5g.16xlarge, g5g.2xlarge, g5g.4xlarge, g5g.8xlarge, g5g.metal, g5g.xlarge, h1.16xlarge, h1.2xlarge, h1.4xlarge, h1.8xlarge, m5dn.12xlarge, m5dn.16xlarge, m5dn.24xlarge, m5dn.2xlarge, m5dn.4xlarge, m5dn.8xlarge, m5dn.large, m5dn.metal, m5dn.xlarge, m5n.12xlarge, m5n.16xlarge, m5n.24xlarge, m5n.2xlarge, m5n.4xlarge, m5n.8xlarge, m5n.large, m5n.metal, m5n.xlarge, m5zn.12xlarge, m5zn.2xlarge, m5zn.3xlarge, m5zn.6xlarge, m5zn.large, m5zn.metal, m5zn.xlarge, m6a.12xlarge, m6a.16xlarge, m6a.24xlarge, m6a.2xlarge, m6a.32xlarge, m6a.48xlarge, m6a.4xlarge, m6a.8xlarge, m6a.large, m6a.metal, m6a.xlarge, m6gd.12xlarge, m6gd.16xlarge, m6gd.2xlarge, m6gd.4xlarge, m6gd.8xlarge, m6gd.large, m6gd.medium, m6gd.metal, m6gd.xlarge, m6id.12xlarge, m6id.16xlarge, m6id.24xlarge, m6id.2xlarge, m6id.32xlarge, m6id.4xlarge, m6id.8xlarge, m6id.large, m6id.metal, m6id.xlarge, m6idn.12xlarge, m6idn.16xlarge, m6idn.24xlarge, m6idn.2xlarge, m6idn.32xlarge, m6idn.4xlarge, m6idn.8xlarge, m6idn.large, m6idn.xlarge, m6in.12xlarge, m6in.16xlarge, m6in.24xlarge, m6in.2xlarge, m6in.32xlarge, m6in.4xlarge, m6in.8xlarge, m6in.large, m6in.xlarge, m7g.12xlarge, m7g.16xlarge, m7g.2xlarge, m7g.4xlarge, m7g.8xlarge, m7g.large, m7g.medium, m7g.metal, m7g.xlarge, mac1.metal, mac2.metal, p2.16xlarge, p2.8xlarge, p2.xlarge, p3dn.24xlarge, p4d.24xlarge, r5dn.12xlarge, r5dn.16xlarge, r5dn.24xlarge, r5dn.2xlarge, r5dn.4xlarge, r5dn.8xlarge, r5dn.large, r5dn.metal, r5dn.xlarge, r6a.12xlarge, r6a.16xlarge, r6a.24xlarge, r6a.2xlarge, r6a.32xlarge, r6a.48xlarge, r6a.4xlarge, r6a.8xlarge, r6a.large, r6a.metal, r6a.xlarge, r6id.12xlarge, r6id.16xlarge, r6id.24xlarge, r6id.2xlarge, r6id.32xlarge, r6id.4xlarge, r6id.8xlarge, r6id.large, r6id.metal, r6id.xlarge, r6idn.12xlarge, r6idn.16xlarge, r6idn.24xlarge, r6idn.2xlarge, r6idn.32xlarge, r6idn.4xlarge, r6idn.8xlarge, r6idn.large, r6idn.xlarge, r6in.12xlarge, r6in.16xlarge, r6in.24xlarge, r6in.2xlarge, r6in.32xlarge, r6in.4xlarge, r6in.8xlarge, r6in.large, r6in.xlarge, r7g.12xlarge, r7g.16xlarge, r7g.2xlarge, r7g.4xlarge, r7g.8xlarge, r7g.large, r7g.medium, r7g.metal, r7g.xlarge, trn1.2xlarge, trn1.32xlarge, u-12tb1.112xlarge, u-18tb1.112xlarge, u-24tb1.112xlarge, u-9tb1.112xlarge, vt1.24xlarge, vt1.3xlarge, vt1.6xlarge, x2gd.12xlarge, x2gd.16xlarge, x2gd.2xlarge, x2gd.4xlarge, x2gd.8xlarge, x2gd.large, x2gd.medium, x2gd.metal, x2gd.xlarge, x2iezn.12xlarge, x2iezn.2xlarge, x2iezn.4xlarge, x2iezn.6xlarge, x2iezn.8xlarge, x2iezn.metal, z1d.12xlarge, z1d.2xlarge, z1d.3xlarge, z1d.6xlarge, z1d.large, z1d.metal, z1d.xlarge, hpc6a.48xlarge, hpc6id.32xlarge]

  KeyPair:
    Description: Select the key pair 
    Type: AWS::EC2::KeyPair::KeyName

  VPC:
    Description: Please select if you want to use existing VPC
    Type: AWS::EC2::VPC::Id
  
  PrivateSubnetIDs: 
    Description: Private Subnet IDs for VPCE
    Type: ""List<AWS::EC2::Subnet::Id>""

  SecurityGroupIDsForNLBAndEC2: 
    Description: Security group IDs for NLB and EC2. Note - please make sure that the security group allows traffic on port 80 from VPC Cidr or 0.0.0.0
    Type: ""List<AWS::EC2::SecurityGroup::Id>""
  
  RouteTableId:
    Description: PrivateSubnets route table Id
    Type: String

Mappings:
  RegionMap:
    us-east-1:
      AMI: ami-0dfcb1ef8550277af
    us-east-2:
      AMI: ami-0cc87e5027adcdca8
    us-west-1:
      AMI: ami-00569e54da628d17c
    us-west-2:
      AMI: ami-0f1a5f5ada0e7da53
    ap-southeast-4:
      AMI: ami-0272ee0cbe63bb8e8
    ap-east-1:
      AMI: ami-0e679816c1d0be6df
    ap-south-2:
      AMI: ami-0155ae3341da656ae
    ap-south-1:
      AMI: ami-0e742cca61fb65051
    ap-northeast-3:
      AMI: ami-090ae0a4750988734
    ap-northeast-2:
      AMI: ami-0f6e451b865011317
    ca-central-1:
      AMI: ami-099effcf516c942b7
    eu-north-1:
      AMI: ami-0bb935e4614c12d86
    eu-west-1:
      AMI: ami-06e0ce9d3339cb039
    eu-west-2:
      AMI: ami-09ee0944866c73f62
    eu-west-3:
      AMI: ami-00575c0cbc20caf50
    eu-central-1:
      AMI: ami-0c0d3776ef525d5dd
    ap-southeast-1:
      AMI: ami-0f2eac25772cd4e36
    ap-southeast-2:
      AMI: ami-0692dea0a2f8a1b35
    ap-northeast-1:
      AMI: ami-0ffac3e16de16665e
    sa-east-1:
      AMI: ami-01fc9174dd9330556
    af-south-1:
      AMI: ami-0d4fd6ba7ffe8260e
    ap-southeast-3:
      AMI: ami-0ebaeda1c62cceddb
    eu-west-3:
      AMI: ami-00575c0cbc20caf50
    eu-south-2:
      AMI: ami-089ea1de61e0c9c18
    me-south-1:
      AMI: ami-06131a860e2930b5c
    me-central-1:
      AMI: ami-0c30c5d64bef7fade
    

Resources:
  VPCE:
    Type: AWS::EC2::VPCEndpoint
    Properties: 
      RouteTableIds: 
        - !Ref RouteTableId
      ServiceName: !Sub com.amazonaws.${AWS::Region}.s3
      VpcEndpointType: Gateway
      VpcId: !Ref VPC

  EC2:
    Type: AWS::EC2::Instance
    DependsOn: ApiGatewayModel
    Properties:
      InstanceType: !Ref InstanceType
      KeyName: !Ref KeyPair
      ImageId: !FindInMap [RegionMap, !Ref 'AWS::Region', AMI]
      SecurityGroupIds: !Ref SecurityGroupIDsForNLBAndEC2
      SubnetId: !Select [0, !Ref PrivateSubnetIDs]
      UserData:
        Fn::Base64:
          !Sub  |
            #!/bin/bash
            yum update -y
            sudo amazon-linux-extras install nginx1 -y
            sudo systemctl enable --now nginx
      Tags:
        - Key: Name
          Value: priv

  NetworkLoadBalancer:
    DependsOn:  EC2
    Type: AWS::ElasticLoadBalancingV2::LoadBalancer
    Properties: 
      Name: NLB
      Scheme: internal
      Subnets:
        - !Select [0, !Ref PrivateSubnetIDs]
        - !Select [1, !Ref PrivateSubnetIDs]
      Type: network
  
  NetworkLoadBalancerTargetGroup:
    DependsOn:  EC2
    Type: AWS::ElasticLoadBalancingV2::TargetGroup
    Properties:
      Port: 80
      Name: NLBTargetGroup
      HealthCheckEnabled: true
      Protocol: TCP
      VpcId: !Ref VPC
      Targets:
        - Id: !GetAtt EC2.PrivateIp
          Port: 80
      TargetType: ip
  
  NetworkLoadBalancerListener:
    DependsOn: NetworkLoadBalancerTargetGroup
    Type: AWS::ElasticLoadBalancingV2::Listener
    Properties:
      DefaultActions:
        - Type: forward
          TargetGroupArn: !Ref NetworkLoadBalancerTargetGroup
      LoadBalancerArn: !Ref NetworkLoadBalancer
      Port: '80'
      Protocol: TCP

  ApiGatewayRestApi:
    Type: 'AWS::ApiGateway::RestApi'
    DependsOn: VPCE
    Properties:
      ApiKeySourceType: HEADER
      Description: An API Gateway to connect to ec2 server
      Name: PublicApiViaCFN
      EndpointConfiguration:
        Types:
          - REGIONAL
  
  ApiGatewayGetMethod:
    DependsOn: VPCLink
    Type: AWS::ApiGateway::Method
    Properties:
      HttpMethod: GET
      AuthorizationType: NONE
      Integration:
        ConnectionType: VPC_LINK
        ConnectionId: ""${stageVariables.vpclink}""
        IntegrationHttpMethod: GET
        PassthroughBehavior: WHEN_NO_MATCH
        TimeoutInMillis: 10000
        Type: HTTP_PROXY
        Uri: !Sub 
              - ""http://${privateIP}""
              - privateIP: !GetAtt EC2.PrivateIp
      ResourceId: !GetAtt ApiGatewayRestApi.RootResourceId
      RestApiId: !Ref ApiGatewayRestApi
  
  ApiGatewayModel:
    DependsOn: ApiGatewayRestApi
    Type: AWS::ApiGateway::Model
    Properties:
      ContentType: 'application/json'
      RestApiId: !Ref ApiGatewayRestApi
      Schema: {}
  
  ApiGatewayStage:
    Type: AWS::ApiGateway::Stage
    DependsOn: ApiGatewayDeployment
    Properties:
      DeploymentId: !Ref ApiGatewayDeployment
      Description: API Stage v0
      RestApiId: !Ref ApiGatewayRestApi
      StageName: 'v0'
      Variables:
        vpclink: !Ref VPCLink
  
  ApiGatewayDeployment:
    Type: 'AWS::ApiGateway::Deployment'
    DependsOn: ApiGatewayGetMethod
    Properties:
      RestApiId: !Ref ApiGatewayRestApi
 
  VPCLink:
    Type: AWS::ApiGateway::VpcLink
    DependsOn: NetworkLoadBalancer
    Properties: 
      Name: NLB
      TargetArns:
        - !Join
            - ''
            - - 'arn:aws:elasticloadbalancing:'
              - !Ref AWS::Region
              - ':'
              - !Ref AWS::AccountId
              - ':loadbalancer/'
              - !GetAtt NetworkLoadBalancer.LoadBalancerFullName

Outputs:
  WebsiteURL:
    Value: !Sub 
            - ""curl https://${ApiId}.execute-api.${AWS::Region}.amazonaws.com/v0""
            - ApiId: !Ref ApiGatewayRestApi
    Description: ApiGateway URL
```",https://rattle-stock-d32.notion.site/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2Fe7472e42-7118-406f-8758-f9c76b1cf86a%2F0d9d865c-bff0-4639-baa6-2317db73ca43%2FUntitled.png?table=block&id=b23b6b3d-9068-49b9-a122-36fe48c614ab&spaceId=e7472e42-7118-406f-8758-f9c76b1cf86a&width=1340&userId=&cache=v2,Developing,Developer,Amazon EC2에서 호스팅되는 NGINX 서버를 위해 API Gateway를 사용해 안전한 REST API 프록시를 구축합니다.," EC2, API Gateway, Network Load Balancer, VPC, REST API, NGINX, Elastic Compute Cloud, Load Balancer"
37,효율적인 데이터 처리 시스템: EC2와 S3 Express One Zone 통합,"## **개요**

AWS SAM Template을 통해 Amazon EC2 인스턴스, Amazon S3 Express One Zone 디렉터리 버킷 및 해당 버킷에 접근하기 위한 IAM Role을 생성합니다. 이 패턴을 활용하면 S3 Express One Zone 스토리지 클래스를 통해 고성능 객체 스토리지와 AWS 컴퓨팅 자원을 단일 가용 영역에서 효과적으로 사용할 수 있습니다. 아래에서는 각 서비스의 역할과 통합 사용 시나리오에 대해 설명합니다.

## **서비스 소개**

### **AWS Serverless Application Model (SAM)**

AWS SAM은 서버리스 애플리케이션을 정의하고 배포하기 위한 오픈소스 프레임워크입니다. 간단한 템플릿을 통해 서버리스 리소스를 생성 및 관리할 수 있습니다.

### **Amazon Elastic Compute Cloud (Amazon EC2)**

Amazon EC2는 확장 가능하고 유연한 컴퓨팅 자원을 제공하는 서비스입니다. 이 패턴에서는 EC2 인스턴스에서 Amazon S3 Express One Zone 버킷에 저장된 데이터를 읽고 쓸 수 있습니다.

### **Amazon S3 Express One Zone**

Amazon S3 Express One Zone은 고성능 객체 스토리지를 컴퓨팅 자원과 동일한 가용 영역에서 사용할 수 있는 스토리지 클래스입니다. 단일 가용 영역에만 데이터를 저장하기 때문에 비용이 저렴하고 높은 성능을 제공합니다.

### **AWS Identity and Access Management (IAM) Role**

IAM Role은 EC2 인스턴스에서 S3 Express One Zone 버킷에 안전하게 접근할 수 있도록 권한을 부여합니다.

## **통합 사용 시나리오**

1. **고성능 컴퓨팅과 스토리지 통합**:
    - SAM 템플릿을 사용하여 EC2 인스턴스와 S3 Express One Zone 버킷을 생성합니다.
    - EC2 인스턴스는 버킷에 저장된 데이터를 고성능으로 읽고 쓸 수 있습니다.
    - IAM Role을 통해 EC2 인스턴스에 필요한 버킷 접근 권한을 제공합니다.
2. **비용 효율적인 데이터 저장 및 처리**:
    - S3 Express One Zone 버킷은 단일 가용 영역에만 데이터를 저장하여 저비용으로 고성능 객체 스토리지를 제공합니다.
    - EC2 인스턴스에서 버킷에 저장된 데이터를 사용하여 데이터 처리 작업을 수행할 수 있습니다.
3. **안전한 데이터 접근 관리**:
    - IAM Role을 사용하여 EC2 인스턴스에서 버킷에 안전하게 접근할 수 있도록 합니다.
    - EC2 인스턴스에서 실행되는 애플리케이션이 버킷에 저장된 데이터에만 접근하도록 권한을 제한합니다.

## 예제

### git

??Visit the?[GitHub repo for this pattern](https://github.com/aws-samples/serverless-patterns/tree/main/ec2-s3-express-one-zone-sam).

```java
git clone https://github.com/aws-samples/serverless-patterns/ 
cd serverless-patterns/ec2-s3-express-one-zone-sam
```

### 배포

```bash
sam deploy --guided
```

### 인프라 생성 코드

```bash
AWSTemplateFormatVersion: '2010-09-09' 
Transform: AWS::Serverless-2016-10-31
Description: SAM Template that creates an EC2 Instance, an Amazon S3 Express One Zone directory bucket and required IAM Role to access the bucket from the instance

# Get the required input parameters
Parameters:
  AvailabilityZoneName:
    Type: String
    Description: Please provide availability Zone Name (e.g. us-east-1a)
  AvailabilityZoneId:
    Type: String
    Description: Please enter the corresponding availability Zone Id (e.g. use1-az6) for your account
  ImageId:
    Type: String
    Description: Please enter the AMI Id for your account

 
Resources:
  # Create VPC and related resources 
  VPC: 
    Type: AWS::EC2::VPC
    Properties:
      CidrBlock: 10.0.0.0/16
      EnableDnsHostnames: true
      EnableDnsSupport: true
      InstanceTenancy: default

  Subnet:
    Type: AWS::EC2::Subnet
    Properties:
      VpcId: !Ref VPC
      CidrBlock: 10.0.0.0/24
      AvailabilityZone: !Sub ""${AvailabilityZoneName}""

  InternetGateway:
    Type: AWS::EC2::InternetGateway

  VPCGatewayAttachment:
    Type: AWS::EC2::VPCGatewayAttachment
    Properties:
      InternetGatewayId: !Ref InternetGateway
      VpcId: !Ref VPC

  RouteTable:
    Type: AWS::EC2::RouteTable
    Properties:
      VpcId: !Ref VPC

  Route:
    Type: AWS::EC2::Route
    DependsOn: VPCGatewayAttachment
    Properties:
      RouteTableId: !Ref RouteTable
      DestinationCidrBlock: 0.0.0.0/0
      GatewayId: !Ref InternetGateway

  SubnetRouteTableAssociation:
    Type: AWS::EC2::SubnetRouteTableAssociation  
    Properties:
      SubnetId: !Ref Subnet
      RouteTableId: !Ref RouteTable

  SecurityGroup:
    Type: AWS::EC2::SecurityGroup
    Properties:
      GroupDescription: Allow HTTP traffic
      VpcId: !Ref VPC
      SecurityGroupIngress:
        - IpProtocol: tcp
          FromPort: 80
          ToPort: 80
          CidrIp: 0.0.0.0/0
        - CidrIp: 0.0.0.0/0 
          IpProtocol: tcp
          FromPort: 22
          ToPort: 22
      SecurityGroupEgress:
        - IpProtocol: all
          CidrIp: 0.0.0.0/0
          

  # Create EC2 Instance Profile, Role  
  EC2InstanceProfile: 
    Type: AWS::IAM::InstanceProfile
    Properties: 
      Path: /
      Roles: 
        - !Ref EC2InstanceRole

  EC2InstanceRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service:
                - ec2.amazonaws.com
            Action:
              - sts:AssumeRole
      Path: /
      Policies:
        - PolicyName: logs
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - 'logs:CreateLogGroup'
                  - 'logs:CreateLogStream'
                  - 'logs:PutLogEvents'
                Resource:
                  - 'arn:aws:logs:*:*:*'
        - PolicyName: AllowAccessRegionalEndpointAPIs
          PolicyDocument: 
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - ""s3express:DeleteBucket""
                  - ""s3express:DeleteBucketPolicy""
                  - ""s3express:CreateBucket""
                  - ""s3express:PutBucketPolicy""
                  - ""s3express:GetBucketPolicy""
                  - ""s3express:ListAllMyDirectoryBuckets""
                Resource:
                  - !GetAtt BucketExpressOneZone.Arn
        - PolicyName: AllowCreateSession
          PolicyDocument: 
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - ""s3express:CreateSession""
                Resource:
                  - !GetAtt BucketExpressOneZone.Arn
                  # - ""*""
                  # - !Ref EC2Instance

# create key-pair
  EC2KeyPair:
    Type: AWS::EC2::KeyPair
    Properties:
      KeyName: ec2-keypair
      KeyType: rsa
      Tags:
        - Key: Name
          Value: ec2-keypair
  # Create EC2 Instance
  EC2Instance:
    Type: AWS::EC2::Instance
    Properties:
      ImageId: !Sub ""${ImageId}""
      InstanceType: t2.micro
      KeyName: !Ref EC2KeyPair
      IamInstanceProfile: !Ref EC2InstanceProfile
      NetworkInterfaces:
        - DeviceIndex: ""0""
          AssociatePublicIpAddress: true
          DeleteOnTermination: true
          SubnetId: !Ref Subnet
          GroupSet:
            - !Ref SecurityGroup
      Tags:
        - Key: Name
          Value: !Sub ""EC2-Instance-${AvailabilityZoneName}""

  # Create an Amazon S3 Express One Zone storage class bucket
  BucketExpressOneZone:
    Type: AWS::S3Express::DirectoryBucket
    Properties:
      # BucketName: input-bucket-express-one-zone
      DataRedundancy: SingleAvailabilityZone
      LocationName: !Sub ""${AvailabilityZoneId}""

# Output EC2 ARN, Bucket names
Outputs:
  EC2InstanceId:
    Value: !Ref EC2Instance
  BucketExpressOneZoneName:
    Value: !Ref BucketExpressOneZone

```",https://rattle-stock-d32.notion.site/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2Fe7472e42-7118-406f-8758-f9c76b1cf86a%2F0d9d865c-bff0-4639-baa6-2317db73ca43%2FUntitled.png?table=block&id=b23b6b3d-9068-49b9-a122-36fe48c614ab&spaceId=e7472e42-7118-406f-8758-f9c76b1cf86a&width=1340&userId=&cache=v2,Developing,Developer,"S3 Express One Zone 버킷과 EC2 인스턴스를 단일 가용 영역에서 통합하고, IAM Role을 통해 안전하게 데이터에 접근합니다."," EC2, S3 Express One Zone, SAM, Identity and Access Management, Serverless, High Performance Computing, Object Storage, Infrastructure as Code"
38,시간대와 요일에 따른 EC2 인스턴스 자동 제어 솔루션,"## **개요**

Amazon EventBridge Scheduler와 Amazon EC2를 함께 사용하여 시간대, 시간 및 요일에 따라 지정된 EC2 인스턴스를 자동으로 시작하고 중지하는 패턴을 구현합니다. 예를 들어, 미국 동부 표준시(US/Eastern) 기준 월요일부터 금요일까지 08:00에 인스턴스를 시작하고 17:00에 종료하는 스케줄을 생성합니다. 아래에서는 각 서비스의 역할과 통합 사용 시나리오에 대해 설명합니다.

## **서비스 소개**

### **Amazon EventBridge Scheduler**

EventBridge Scheduler는 이벤트 기반 스케줄링을 제공하는 완전 관리형 서비스입니다. 이를 통해 특정 시간에 맞춰 EC2 인스턴스를 시작하거나 중지하는 등의 자동화된 작업을 수행할 수 있습니다.

### **Amazon Elastic Compute Cloud (Amazon EC2)**

Amazon EC2는 다양한 컴퓨팅 인스턴스 유형을 제공하는 유연하고 확장 가능한 컴퓨팅 서비스입니다. 이 패턴에서는 EC2 인스턴스를 지정된 시간과 요일에 따라 시작 및 중지합니다.

### **AWS Identity and Access Management (IAM) Role**

IAM Role은 EventBridge Scheduler 및 EC2 인스턴스 간의 권한을 관리하여, EventBridge Scheduler가 EC2 인스턴스를 제어할 수 있도록 지원합니다.

## **통합 사용 시나리오**

1. **스케줄 기반 EC2 인스턴스 시작 및 중지**:
    - EventBridge Scheduler를 통해 월요일부터 금요일까지 08:00에 EC2 인스턴스를 시작하고 17:00에 종료하는 스케줄을 생성합니다.
    - EventBridge Scheduler는 IAM Role을 통해 EC2 인스턴스를 시작하거나 중지하는 권한을 갖습니다.
2. **비용 효율적인 컴퓨팅 자원 관리**:
    - 인스턴스가 필요한 시간대에만 작동하도록 하여 비용을 효율적으로 관리합니다.
    - 스케줄에 따라 EC2 인스턴스를 자동으로 중지하여 불필요한 리소스 사용을 줄입니다.
3. **시간대 및 요일 기반 제어**:
    - EventBridge Scheduler를 통해 다양한 지역 및 시간대에서 EC2 인스턴스를 효율적으로 관리할 수 있습니다.
    - 특정 요일에만 인스턴스를 작동시켜 개발 및 운영 환경을 효과적으로 구분할 수 있습니다.

## 예제

### git

??Visit the?[GitHub repo for this pattern](https://github.com/aws-samples/serverless-patterns/tree/main/eventbridge-schedule-to-ec2-terrafrom).

```java
git clone https://github.com/aws-samples/serverless-patterns/ 
cd serverless-patterns/eventbridge-schedule-to-ec2-terraform
```

### 배포

```bash
terraform apply
```

### 인프라 생성 코드

```bash
terraform {
  required_providers {
    aws = {
      source  = ""hashicorp/aws""
      version = "">= 4.64.0""
    }
  }
}

provider ""aws"" {
  region = var.region
}

locals {
  project_name = ""tf-test""
}

# This section creates VPC resources for the Amazon EC2 environment

resource ""aws_vpc"" ""vpc"" {
  cidr_block  = var.vpc_cidr
}

resource ""aws_subnet"" ""subnet"" {
  vpc_id      = aws_vpc.vpc.id
  cidr_block  = var.subnet_cidr
  tags        = {
    Name = ""private-subnet-1""
  }
}

# This section creates an Amazon EC2 instance using the latest Amazon Linux AMI

data ""aws_ami"" ""amazon-linux-2"" {
  most_recent = true

  filter {
    name = ""owner-alias""
    values = [""amazon""]
  }
  
  filter {
    name = ""name""
    values = [""amzn2-ami-hvm*""]
  }
}

resource ""aws_instance"" ""test-ec2"" {
  ami           = ""${data.aws_ami.amazon-linux-2.id}""
  instance_type = ""t3.micro""
  subnet_id     = aws_subnet.subnet.id
  tags = {
    Name = ""tf-test-ec2""
  }
}

# This section creates cron schedules using Amazon EventBridge Scheduler, as well as the required IAM roles to interact with EC2

resource ""aws_scheduler_schedule"" ""ec2-start-schedule"" {
  name = ""ec2-start-schedule""
  
  flexible_time_window {
    mode = ""OFF""
  }

  schedule_expression = ""cron(0 8 ? * MON-FRI *)"" # Scheduled startInstances at 8am EST Mon-Fri
  schedule_expression_timezone = ""US/Eastern"" # Default is UTC
  description = ""Start instances event""

  target {
    arn = ""arn:aws:scheduler:::aws-sdk:ec2:startInstances""
    role_arn = aws_iam_role.scheduler-ec2-role.arn
  
    input = jsonencode({
      ""InstanceIds"": [
        ""${aws_instance.test-ec2.id}""
      ]
    })
  }
}

resource ""aws_scheduler_schedule"" ""ec2-stop-schedule"" {
  name = ""ec2-stop-schedule""
  
  flexible_time_window {
    mode = ""OFF""
  }

  schedule_expression = ""cron(0 17 ? * MON-FRI *)"" # Scheduled stopinstances at 5pm EST Mon-Fri
  schedule_expression_timezone = ""US/Eastern"" # Default is UTC
  description = ""Stop instances event""

  target {
    arn = ""arn:aws:scheduler:::aws-sdk:ec2:stopInstances""
    role_arn = aws_iam_role.scheduler-ec2-role.arn
  
    input = jsonencode({
      ""InstanceIds"": [
        ""${aws_instance.test-ec2.id}""
      ]
    })
  }
}

resource ""aws_iam_policy"" ""scheduler_ec2_policy"" {
  name = ""scheduler_ec2_policy""

  policy = jsonencode(
    {
        ""Version"": ""2012-10-17"",
        ""Statement"": [
            {
                ""Sid"": ""VisualEditor0"",
                ""Effect"": ""Allow"",
                ""Action"": [
                    ""ec2:StartInstances"",
                    ""ec2:StopInstances""
                ],
                ""Resource"": [
                  ""${aws_instance.test-ec2.arn}:*"",
                  ""${aws_instance.test-ec2.arn}""
                ],
            }
        ]
    }
  )
}

resource ""aws_iam_role"" ""scheduler-ec2-role"" {
  name = ""scheduler-ec2-role""
  managed_policy_arns = [aws_iam_policy.scheduler_ec2_policy.arn]

  assume_role_policy = jsonencode({
    Version = ""2012-10-17""
    Statement = [
      {
        Action = ""sts:AssumeRole""
        Effect = ""Allow""
        Sid    = """"
        Principal = {
          Service = ""scheduler.amazonaws.com""
        }
      },
    ]
  })
}

```",https://rattle-stock-d32.notion.site/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2Fe7472e42-7118-406f-8758-f9c76b1cf86a%2F7ed4ad53-63d3-474e-bc4b-ff6ad19519f1%2FUntitled.png?table=block&id=d806769d-286c-4230-91eb-13b900e4f363&spaceId=e7472e42-7118-406f-8758-f9c76b1cf86a&width=1330&userId=&cache=v2,Cloud Operations (SysOps),Infrastructure Engineer,EventBridge Scheduler와 EC2를 사용해 특정 요일 및 시간대에 따라 EC2 인스턴스를 자동으로 시작하고 중지하여 비용을 효율적으로 관리합니다," EventBridge Scheduler, EC2, Identity and Access Management, Terraform, Event-driven architecture, Infrastructure as Code, Cron scheduling, Compute resources"
